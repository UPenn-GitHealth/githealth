{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here's an explanation of each column in the issues_2023_new.csv file:\n",
        "\n",
        "1. `issues_title`: Title of the GitHub issue. Each row represents an issue, and this column holds the title for each issue.\n",
        "\n",
        "2. `issues_created_at`: Timestamp indicating when the GitHub issue was created.\n",
        "issues_thread_id: Unique ID assigned to each GitHub issue. This ID helps in uniquely identifying and tracking each issue.\n",
        "\n",
        "3. `issues_comment_id`: Unique ID assigned to each comment in the GitHub issue. If there are no comments (i.e., issues_no_of_comments is 0), this field would be an empty string for threads without comments and the original comment ID for comments and replies.\n",
        "\n",
        "4. `issues_comment_type`: Indicates whether the comment is a top-level comment (\"questioned\") or a reply (\"answered\").\n",
        "\n",
        "5. `issues_comment_text`: The text of the comment or reply.\n",
        "\n",
        "6. `issues_comment_author`: User ID of the author who made the comment or reply.\n",
        "\n",
        "7. `issues_time_to_close`: Time taken to close the GitHub issue in seconds. If the issue is not closed, this field would be None.\n",
        "\n",
        "8. `issues_time_to_first_response`: Time taken for the first response in the GitHub issue in seconds. If there is no response, this field would be None.\n",
        "\n",
        "9. `issues_no_of_comments`: Number of comments in the GitHub issue. If there are no comments, it would be 0.\n",
        "\n",
        "10. `issues_commits`: Number of commits associated with a pull request (PR) linked to the issue. If the issue is not a PR, this field would be 0.\n",
        "\n",
        "11. `issues_checks`: Number of checks (e.g., CI/CD checks) associated with a PR linked to the issue. If the issue is not a PR, this field would be 0.\n",
        "\n",
        "12. `issues_files_changed`: Number of files changed in the PR linked to the issue. If the issue is not a PR, this field would be 0.\n",
        "\n",
        "13. `issues_lines_changed`: Number of lines changed in the PR linked to the issue. If the issue is not a PR, this field would be 0."
      ],
      "metadata": {
        "id": "Pn-OfnSVv8ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import time  # Import the time module for rate limiting"
      ],
      "metadata": {
        "id": "ywlFhbI5NJSw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your GitHub personal access token\n",
        "access_token = \"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\"\n",
        "\n",
        "# GitHub API endpoint\n",
        "base_url = \"https://api.github.com\"\n",
        "\n",
        "# Repository details\n",
        "owner = \"autowarefoundation\"\n",
        "repo_name = \"autoware\"\n",
        "\n",
        "# Define the year you want to filter discussions for\n",
        "year = \"2014\"\n",
        "\n",
        "# Initialize data containers\n",
        "issues_data = []\n",
        "\n",
        "# Prepare headers with authorization\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {access_token}\"\n",
        "}\n",
        "\n",
        "# Define the API endpoint for issues in the repository\n",
        "issues_endpoint = f\"/repos/{owner}/{repo_name}/issues\""
      ],
      "metadata": {
        "id": "gPAoqtoTNMn4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fetch comments for an issue\n",
        "def fetch_comments(issue_number):\n",
        "    comments_url = f\"{base_url}{issues_endpoint}/{issue_number}/comments\"\n",
        "    response = requests.get(comments_url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    return []\n",
        "\n",
        "# Function to fetch additional details for a pull request\n",
        "def fetch_pull_request_details(pr_number):\n",
        "    pr_details_url = f\"{base_url}/repos/{owner}/{repo_name}/pulls/{pr_number}\"\n",
        "    response = requests.get(pr_details_url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    return None\n",
        "\n",
        "# Function to calculate the time to close an issue\n",
        "def calculate_time_to_close(issue):\n",
        "    if \"closed_at\" in issue and \"created_at\" in issue and issue[\"closed_at\"] is not None and issue[\"created_at\"] is not None:\n",
        "        closed_at = datetime.strptime(issue[\"closed_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "        created_at = datetime.strptime(issue[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "        return (closed_at - created_at).total_seconds()\n",
        "    return None\n",
        "\n",
        "# Function to calculate the time to the first response in seconds\n",
        "def calculate_time_to_first_response(issue):\n",
        "    created_at = datetime.strptime(issue[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "    comments = fetch_comments(issue[\"number\"])\n",
        "    if comments:\n",
        "        first_comment = min(comments, key=lambda x: datetime.strptime(x[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\"))\n",
        "        first_response_at = datetime.strptime(first_comment[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "        return (first_response_at - created_at).total_seconds()\n",
        "    return None"
      ],
      "metadata": {
        "id": "d3LcQTh9NPyg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch all issues (discussions)\n",
        "page = 1\n",
        "while True:\n",
        "    params = {\n",
        "        \"state\": \"all\",\n",
        "        \"per_page\": 100,\n",
        "        \"page\": page\n",
        "    }\n",
        "    response = requests.get(base_url + issues_endpoint, headers=headers, params=params)\n",
        "\n",
        "    # Check for rate limit exceeded\n",
        "    if response.status_code == 403:\n",
        "        print(f\"Rate limit exceeded. Waiting for {response.headers['Retry-After']} seconds.\")\n",
        "        time.sleep(int(response.headers['Retry-After']) + 1)  # Wait for the specified seconds\n",
        "        continue\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        issues = response.json()\n",
        "        if not issues:\n",
        "            break\n",
        "        for issue in issues:\n",
        "            # Extract the year part from the created_at timestamp\n",
        "            created_at_year = issue[\"created_at\"][:4]\n",
        "            if created_at_year != year:\n",
        "                continue  # Skip the issue if it's not in the specified year\n",
        "\n",
        "            issue_data = {\n",
        "                \"issues_id\": issue[\"id\"],  # Save the original issue ID\n",
        "                \"issues_title\": issue[\"title\"],\n",
        "                \"issues_user_id\": issue[\"user\"][\"login\"],\n",
        "                \"issues_created_at\": issue[\"created_at\"],\n",
        "                \"issues_comments\": fetch_comments(issue[\"number\"]),\n",
        "                \"issues_time_to_close\": calculate_time_to_close(issue),\n",
        "                \"issues_time_to_first_response\": calculate_time_to_first_response(issue),\n",
        "                \"issues_no_of_comments\": len(fetch_comments(issue[\"number\"]))  # New column: number of comments\n",
        "            }\n",
        "\n",
        "            # Fetch additional details for PRs\n",
        "            if \"pull_request\" in issue:\n",
        "                pr_details = fetch_pull_request_details(issue[\"number\"])\n",
        "                if pr_details:\n",
        "                    issue_data[\"issues_commits\"] = pr_details.get(\"commits\", 0)\n",
        "                    issue_data[\"issues_checks\"] = pr_details.get(\"check_runs_count\", 0)\n",
        "                    issue_data[\"issues_files_changed\"] = pr_details.get(\"changed_files\", 0)\n",
        "                    issue_data[\"issues_lines_changed\"] = pr_details.get(\"additions\", 0) + pr_details.get(\"deletions\", 0)\n",
        "\n",
        "            issues_data.append(issue_data)\n",
        "        page += 1\n",
        "    else:\n",
        "        print(f\"Failed to fetch issues. Status code: {response.status_code}\")\n",
        "        break"
      ],
      "metadata": {
        "id": "OjJYorm6NU6A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new data structure with the desired format\n",
        "new_data = []\n",
        "\n",
        "for discussion in issues_data:\n",
        "    thread_id = discussion[\"issues_id\"]  # Use the original issue ID as thread_id\n",
        "    thread_creator = discussion[\"issues_user_id\"]  # Get the thread creator's username\n",
        "\n",
        "    # Create a placeholder for threads without comments\n",
        "    if not discussion[\"issues_comments\"]:\n",
        "        comment_data = {\n",
        "            \"issues_title\": discussion[\"issues_title\"],  # Include the title\n",
        "            \"issues_created_at\": discussion[\"issues_created_at\"],\n",
        "            \"issues_thread_id\": thread_id,\n",
        "            \"issues_comment_id\": \"\",  # Empty for threads without comments\n",
        "            \"issues_comment_type\": \"\",  # Empty for threads without comments\n",
        "            \"issues_comment_text\": \"\",  # Empty for threads without comments\n",
        "            \"issues_comment_author\": thread_creator,  # Include the thread creator\n",
        "            \"issues_time_to_close\": None,\n",
        "            \"issues_time_to_first_response\": None,\n",
        "            \"issues_no_of_comments\": discussion[\"issues_no_of_comments\"],  # Include the number of comments\n",
        "            \"issues_commits\": discussion.get(\"issues_commits\", 0),  # Include number of commits\n",
        "            \"issues_checks\": discussion.get(\"issues_checks\", 0),  # Include number of checks\n",
        "            \"issues_files_changed\": discussion.get(\"issues_files_changed\", 0),  # Include number of files changed\n",
        "            \"issues_lines_changed\": discussion.get(\"issues_lines_changed\", 0),  # Include number of lines changed\n",
        "        }\n",
        "        new_data.append(comment_data)\n",
        "    else:\n",
        "        time_to_close = None\n",
        "        time_to_first_response = None\n",
        "        # Calculate time to close and time to first response\n",
        "        comment_dates = [datetime.strptime(comment[\"created_at\"], \"%Y-%m-%dT%H:%M:%SZ\") for comment in discussion[\"issues_comments\"]]\n",
        "        if discussion[\"issues_time_to_close\"]:\n",
        "            time_to_close = discussion[\"issues_time_to_close\"]\n",
        "        if discussion[\"issues_time_to_first_response\"]:\n",
        "            time_to_first_response = discussion[\"issues_time_to_first_response\"]\n",
        "        for index, comment in enumerate(discussion[\"issues_comments\"], start=1):\n",
        "            comment_creator = comment[\"user\"][\"login\"]\n",
        "            if comment_creator == thread_creator:\n",
        "                comment_type = \"questioned\"\n",
        "            else:\n",
        "                comment_type = \"answered\"\n",
        "\n",
        "            comment_data = {\n",
        "                \"issues_title\": discussion[\"issues_title\"],  # Include the title\n",
        "                \"issues_created_at\": comment[\"created_at\"],\n",
        "                \"issues_thread_id\": thread_id,\n",
        "                \"issues_comment_id\": comment[\"id\"],  # Use the original comment ID as subtitle_id\n",
        "                \"issues_comment_type\": comment_type,\n",
        "                \"issues_comment_text\": comment[\"body\"],\n",
        "                \"issues_comment_author\": comment_creator,  # Include the comment creator\n",
        "                \"issues_time_to_close\": time_to_close,\n",
        "                \"issues_time_to_first_response\": time_to_first_response,\n",
        "                \"issues_no_of_comments\": discussion[\"issues_no_of_comments\"],  # Include the number of comments\n",
        "                \"issues_commits\": discussion.get(\"issues_commits\", 0),  # Include number of commits\n",
        "                \"issues_checks\": discussion.get(\"issues_checks\", 0),  # Include number of checks\n",
        "                \"issues_files_changed\": discussion.get(\"issues_files_changed\", 0),  # Include number of files changed\n",
        "                \"issues_lines_changed\": discussion.get(\"issues_lines_changed\", 0),  # Include number of lines changed\n",
        "            }\n",
        "            new_data.append(comment_data)\n",
        "\n",
        "            # Include replies as well\n",
        "            replies = fetch_comments(comment[\"id\"])\n",
        "            for reply in replies:\n",
        "                reply_creator = reply[\"user\"][\"login\"]\n",
        "                reply_type = \"answered\"\n",
        "\n",
        "                reply_data = {\n",
        "                    \"issues_title\": discussion[\"issues_title\"],  # Include the title\n",
        "                    \"issues_created_at\": reply[\"created_at\"],\n",
        "                    \"issues_thread_id\": thread_id,\n",
        "                    \"issues_comment_id\": reply[\"id\"],  # Use the original reply ID as subtitle_id\n",
        "                    \"issues_comment_type\": reply_type,\n",
        "                    \"issues_comment_text\": reply[\"body\"],\n",
        "                    \"issues_comment_author\": reply_creator,  # Include the reply creator\n",
        "                    \"issues_time_to_close\": time_to_close,\n",
        "                    \"issues_time_to_first_response\": time_to_first_response,\n",
        "                    \"issues_no_of_comments\": discussion[\"issues_no_of_comments\"],  # Include the number of comments\n",
        "                    \"issues_commits\": discussion.get(\"issues_commits\", 0),  # Include number of commits\n",
        "                    \"issues_checks\": discussion.get(\"issues_checks\", 0),  # Include number of checks\n",
        "                    \"issues_files_changed\": discussion.get(\"issues_files_changed\", 0),  # Include number of files changed\n",
        "                    \"issues_lines_changed\": discussion.get(\"issues_lines_changed\", 0),  # Include number of lines changed\n",
        "                }\n",
        "                new_data.append(reply_data)"
      ],
      "metadata": {
        "id": "ey8EZ2icNYQW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a CSV file with the new data structure\n",
        "csv_file_path = f\"issues_{year}_new.csv\"\n",
        "with open(csv_file_path, \"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
        "    fieldnames = [\n",
        "        \"issues_title\", \"issues_created_at\", \"issues_thread_id\", \"issues_comment_id\",\n",
        "        \"issues_comment_type\", \"issues_comment_text\", \"issues_comment_author\",\n",
        "        \"issues_time_to_close\", \"issues_time_to_first_response\", \"issues_no_of_comments\",\n",
        "        \"issues_commits\", \"issues_checks\", \"issues_files_changed\", \"issues_lines_changed\"\n",
        "    ]\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "    writer.writeheader()\n",
        "    for data in new_data:\n",
        "        writer.writerow(data)\n",
        "\n",
        "# Read the new CSV file into a DataFrame\n",
        "issues_new_df = pd.read_csv(csv_file_path)"
      ],
      "metadata": {
        "id": "9y8xIuv0Ncbf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first 5 rows of the new DataFrame\n",
        "print(issues_new_df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl_9AFFz3Ct_",
        "outputId": "bf2862c8-d5b1-4a19-9e7e-fcc536b5d2de"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [issues_title, issues_created_at, issues_thread_id, issues_comment_id, issues_comment_type, issues_comment_text, issues_comment_author, issues_time_to_close, issues_time_to_first_response, issues_no_of_comments, issues_commits, issues_checks, issues_files_changed, issues_lines_changed]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display information about the new DataFrame\n",
        "print(issues_new_df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rWaABNsNf7Z",
        "outputId": "f33b09f8-6b0a-4a02-bf9f-7c77a18f4e99"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 0 entries\n",
            "Data columns (total 14 columns):\n",
            " #   Column                         Non-Null Count  Dtype \n",
            "---  ------                         --------------  ----- \n",
            " 0   issues_title                   0 non-null      object\n",
            " 1   issues_created_at              0 non-null      object\n",
            " 2   issues_thread_id               0 non-null      object\n",
            " 3   issues_comment_id              0 non-null      object\n",
            " 4   issues_comment_type            0 non-null      object\n",
            " 5   issues_comment_text            0 non-null      object\n",
            " 6   issues_comment_author          0 non-null      object\n",
            " 7   issues_time_to_close           0 non-null      object\n",
            " 8   issues_time_to_first_response  0 non-null      object\n",
            " 9   issues_no_of_comments          0 non-null      object\n",
            " 10  issues_commits                 0 non-null      object\n",
            " 11  issues_checks                  0 non-null      object\n",
            " 12  issues_files_changed           0 non-null      object\n",
            " 13  issues_lines_changed           0 non-null      object\n",
            "dtypes: object(14)\n",
            "memory usage: 0.0+ bytes\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Data analysis and manipulation completed. New data saved to {csv_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7dRlSqrNhWQ",
        "outputId": "2020923f-67dc-425b-e121-1698b6506603"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data analysis and manipulation completed. New data saved to issues_2014_new.csv\n"
          ]
        }
      ]
    }
  ]
}