issues_title,issues_created_at,issues_thread_id,issues_comment_id,issues_comment_type,issues_comment_text,issues_comment_author,issues_time_to_close,issues_time_to_first_response,issues_no_of_comments,issues_commits,issues_checks,issues_files_changed,issues_lines_changed
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2022-12-27T04:19:06Z,1511417351,1365601221.0,reply,@shmpwk Could you tell me the right branch we should use for Humble?,kenji-miyake,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2022-12-27T05:17:42Z,1511417351,1365619592.0,reply,"@anilbommareddy 
Currently, the official support for AWSIM is only ROS2 Galactic, Ubuntu20.04.

For Ubuntu 22.04, try work in progress version which includes our individual repos but will be officially supported soon:
Autoware: https://github.com/shmpwk/autoware/tree/humble-awsim-stable
AWSIM: https://github.com/tier4/AWSIM/tree/humble

Try the following command
```
git clone https://github.com/shmpwk/autoware/
cd autoware
git checkout humble-awsim-stable
./setup-dev-env.sh  #*/enter Y and install cuda-Y.
mkdir src
vcs import src < autoware.repos
source /opt/ros/humble/setup.bash
rosdep update
rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO
colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=""-w""
source install/setup.bash
ros2 launch autoware_launch e2e_simulator.launch.xml vehicle_model:=sample_vehicle sensor_model:=awsim_sensor_kit map_path:=<your mapfile location>
```

Note that when launching AWSIM, you need its binary. But currently we have only Galactic version of binary.
You have to create AWSIM binary for Humble by yourself from https://github.com/tier4/AWSIM/tree/humble.",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T04:51:38Z,1511417351,1370485493.0,reply,"hii @shmpwk 
Shall we install autoware for AWSIM in ubuntu 22.04 by your above steps.",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T04:57:38Z,1511417351,1370488050.0,reply,"@patelabhay-12 
Still the above step is not official but now should work correctly in Ubuntu 22.04 from the success of my several co-workers  attempts.",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T05:03:21Z,1511417351,1370491224.0,reply,"
![Screenshot from 2023-01-04 10-30-12](https://user-images.githubusercontent.com/89857716/210487834-a489a689-053f-46bb-9f49-1f8e386ef9c9.png)
okay, But I got the error when giving the below command-
colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=""-w""
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T05:12:27Z,1511417351,1370497145.0,reply,"@patelabhay-12 
Let me check several points
- Did you succeeded following without any error:  `./setup-dev-env.sh`, `vcs import src < autoware.repos`, `rosdep update`, `rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO` ?
- Have you built the other Autoware branch under your `~/autoware` folder?",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T05:14:41Z,1511417351,1370498301.0,reply,I firstly doubted [this issue](https://github.com/autowarefoundation/autoware/issues/3119) but it seems you have different error :thinking: ,shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T05:25:02Z,1511417351,1370502799.0,reply,"> @patelabhay-12 Let me check several points
> 
>     * Did you succeeded following without any error:  `./setup-dev-env.sh`, `vcs import src < autoware.repos`, `rosdep update`, `rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO` ?
> 
>     * Have you built the other Autoware branch under your `~/autoware` folder?

yes I succeeded in following without any error.

Yes, I built the other Autoware branch under our ~/autoware folder
![image](https://user-images.githubusercontent.com/89857716/210490133-51c72c01-2700-4c10-871f-75c812d3afc7.png)
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T05:28:15Z,1511417351,1370504137.0,reply,"> Yes, I built the other Autoware branch under your ~/autoware folder

In that case you might mixed the previous build cache. Could you once `rm build install log  -f` under `~/autoware` ? and colcon build again?",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T05:37:21Z,1511417351,1370507853.0,reply,"> > Yes, I built the other Autoware branch under your ~/autoware folder
> 
> In that case you might mixed the previous build cache. Could you once `rm build install log` under `~/autoware` ? and colcon build again?

Did the same, & getting error again
![Screenshot from 2023-01-04 11-06-12](https://user-images.githubusercontent.com/89857716/210491017-f1e704da-0d27-4ec3-81ea-c9142e68da13.png)
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T05:49:49Z,1511417351,1370513026.0,reply,"@patelabhay-12 
According to [this issue](https://github.com/koide3/ndt_omp/issues/47), your PCL version is much newer than we expected? Could you share your PCL version? 

```
$ dpkg -l |grep pcl
```
Have you manually installed PCL in Ubuntu22.04? (should be automatically installed with our Autoware setup) ",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T06:49:59Z,1511417351,1370544247.0,reply,"![image](https://user-images.githubusercontent.com/89857716/210499461-71bcde79-11d5-484c-a4d4-bba0ea7db9c4.png)
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T07:01:59Z,1511417351,1370550843.0,reply,We don't use `pcl-tools` and `python3-pcl`. Could you remove these pakages by `sudo apt remove pcl-tools python3-pcl` ? ,shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T07:04:52Z,1511417351,1370552944.0,reply,"FYI, this is our environment. 
![image (4)](https://user-images.githubusercontent.com/42209144/210501342-8869bbe5-5517-4639-9d03-306a325b860e.png)

(We might also need `ros-humble-perception-pcl` which should be installed by `rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO`)",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T07:38:45Z,1511417351,1370575151.0,reply,"I did the same for installation of ros-humble-perception-pcl , but its not showing ??
![Screenshot from 2023-01-04 13-08-06](https://user-images.githubusercontent.com/89857716/210506189-665c1a10-2dce-454e-b0d7-4a1c96a457a0.png)
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T07:45:24Z,1511417351,1370579445.0,reply,"It seems `pcl-tools` and `python3-pcl` are succeeded to delete.
As for `ros-humble-perception-pcl `, it is not related to your error at least for now. (Perhaps it might cause the other perception pakage error later on.)

Could you try this under `~/autoware/`?
```
rm build/ndt_omp/ install/share/ndt_omp/ install/include/ndp_omp -rf 
```
and then colcon build again?",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T07:57:18Z,1511417351,1370587311.0,reply,"did the same & also getting same errors.
![Screenshot from 2023-01-04 13-26-45](https://user-images.githubusercontent.com/89857716/210509018-852643fa-7d42-4954-969b-646321751c1e.png)
![Screenshot from 2023-01-04 13-25-36](https://user-images.githubusercontent.com/89857716/210509052-17e03238-3394-4a5f-aea5-8fd50603e46f.png)
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T08:26:48Z,1511417351,1370612693.0,reply,"@patelabhay-12 
Could you try manually  `sudo apt install ros-humble-perception-pcl` ? (This is not good way but not harmful to your environment.)

(For my memo: the status looks good https://repo.ros2.org/status_page/ros_humble_default.html)",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T08:52:56Z,1511417351,1370634506.0,reply,"![Screenshot from 2023-01-04 14-19-41](https://user-images.githubusercontent.com/89857716/210517727-21bf6a17-4453-47b7-b7dd-f6b8e7ed8dbf.png)
![Screenshot from 2023-01-04 14-19-41](https://user-images.githubusercontent.com/89857716/210517760-e966d825-e410-4566-813f-1e7914b6c7ca.png)



![Screenshot from 2023-01-04 14-21-29](https://user-images.githubusercontent.com/89857716/210518036-f8c227b6-9ee9-4a75-8d02-6b1ae8646b0e.png)

ros-humble-perception-pcl is installed successfully, after that i try same and getting same errors

",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T08:54:41Z,1511417351,1370636130.0,reply,"same error

![image](https://user-images.githubusercontent.com/89857716/210518575-def76184-20eb-4690-a8bb-c9751b62a0fe.png)
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T08:58:15Z,1511417351,1370639389.0,reply,"@patelabhay-12 

In your error log, I found your build depends `/usr/local/include/pcl-1.13 ......` which is newer than we expected (we expect 1.12).
So you should remove it.  ~~Now I investigate how to remove it ....... or do you know it?~~",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:05:34Z,1511417351,1370647476.0,reply,"@patelabhay-12 
You can remove it directly by
```
sudo rm /usr/local/include/pcl-1.13/ -rf
```

FYI, I have experienced the similar situation and I was taught to do that before ([japanese issues](https://github.com/jsk-ros-pkg/jsk_recognition/issues/2505#issuecomment-633787027) ).


After remove it, be sure not to exist pcl-1.13. 
You can confirm it by
```
locate pcl_  |grep 1.13
locate libpcl_  |grep 1.13
```
without output.",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:16:54Z,1511417351,1370660653.0,reply,"I removed it by sudo rm /usr/local/include/pcl-1.13/ -rf
then try colcon build, now its showing that fatal error: pcl/point_types.h: No such file or directory



![error1](https://user-images.githubusercontent.com/89857716/210522641-b2c2042e-3d78-486a-8fd4-aa1770646e8a.png)
![error2](https://user-images.githubusercontent.com/89857716/210522679-7dfc4484-ee81-4063-8ca1-04268fc295b7.png)
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:20:10Z,1511417351,1370664636.0,reply,"OK, in that situation, you have to execute `rm build install log  -rf` under `~/autoware` to remove the previous pcl build dependency.",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:22:52Z,1511417351,1370670580.0,reply,"rm build install log  -rf 
after this, Shall I give colcon build",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:23:21Z,1511417351,1370671719.0,reply,YES!,shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:28:08Z,1511417351,1370681244.0,reply,"![image](https://user-images.githubusercontent.com/89857716/210524298-99930d87-348f-4275-8b92-e01c8c7f19a3.png)

now iot is showing error in Cmake list
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:29:34Z,1511417351,1370682708.0,reply,"You need ` sudo rm  /usr/share/pcl-1.13/  -rf` , `rm build install log  -rf`, colcon build

After remove it, be sure not to exist pcl-1.13.
You can confirm it by
```
locate pcl_  |grep 1.13
locate libpcl_  |grep 1.13
```
without any output.",shmpwk,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:41:48Z,1511417351,1370696053.0,reply,"after giving  sudo rm  /usr/share/pcl-1.13/  -rf
and rm build install log  -rf

and then i  locate pcl by locate libpcl_  |grep 1.13
it is showing PCL 1.13 , i think these are not removed so we got errors

![image](https://user-images.githubusercontent.com/89857716/210526703-d7dc1b09-163b-48fe-95c2-b8a9571f9fde.png)

![image](https://user-images.githubusercontent.com/89857716/210526779-dd3cba97-9660-42f9-be5a-6be4930d8987.png)
",patelabhay-12,1392336.0,297.0,30,0,0,0,0
No package mactching ros-galactic-desktop available  for AWSIM-stable branch in Ubuntu 22.04,2023-01-04T09:43:54Z,1511417351,1370698196.0,reply,Your pcl under home directory is basically not depended and do not have to remove them.,shmpwk,1392336.0,297.0,30,0,0,0,0
chore(pre-commit workflows): add comments to recommend using pre-commit.ci,2022-12-22T06:15:56Z,1507330575,,,,kenji-miyake,,,0,1,0,2,4
DevOps Dojo: ROS Node Documentation (Phase 1),2023-01-11T02:00:56Z,1506986879,1378146661.0,comment,Replaced with https://github.com/autowarefoundation/autoware.universe/issues/2630.,kaspermeck-arm,1740835.0,1740807.0,1,0,0,0,0
DevOps Dojo: ROS Node Configuration (Phase 1),2023-01-11T02:00:07Z,1506977684,1378146123.0,comment,Replaced with https://github.com/autowarefoundation/autoware.universe/issues/2631.,kaspermeck-arm,1741558.0,1741491.0,1,0,0,0,0
ci(pre-commit): autoupdate,2022-12-12T17:29:27Z,1492390081,,,,pre-commit-ci[bot],,,0,1,0,1,10
chore(release): update galactic branch,2022-12-19T10:52:57Z,1491559630,1357454712.0,comment,"All related PRs have been merged. 
Also, I tested this with AWSIM and works as I expected.",shmpwk,608906.0,605146.0,1,1,0,1,4
ci: add workaround for galactic eol,2022-12-12T08:39:16Z,1491279496,1346094381.0,reply,Related: https://github.com/autowarefoundation/autoware/discussions/2622#discussioncomment-4375825,kenji-miyake,8481980.0,1210.0,2,1,0,1,2
ci: add workaround for galactic eol,2022-12-12T08:40:27Z,1491279496,1346095619.0,reply,"In addition to `vcs-import`, there are some lines that use `rosdep update`.
https://github.com/autowarefoundation/autoware/blob/9da9b5e25d40b5c9d4d7141ef807325de2077bcf/.github/workflows/build-main.yaml#L41",kenji-miyake,8481980.0,1210.0,2,1,0,1,2
Source installation failed: ndt_omp ,2022-12-09T01:34:03Z,1485271028,1343720820.0,reply,"@cjffly Was your Ubuntu 22.04 clean-installed? Or was upgraded from 20.04? I guess there are some issues with your environment.
My gcc version is also `gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0`, but can successfully build ndt_omp.",kenji-miyake,210280.0,21972.0,4,0,0,0,0
Source installation failed: ndt_omp ,2022-12-09T18:07:25Z,1485271028,1344609245.0,comment,"> @cjffly Was your Ubuntu 22.04 clean-installed? Or was upgraded from 20.04? I guess there are some issues with your environment. My gcc version is also `gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0`, but can successfully build ndt_omp.

You are right, mine is upgraded from 20.04. Not sure if there is quick fix or I have to reinstall 22.04 from scratch.",cjffly,210280.0,21972.0,4,0,0,0,0
Source installation failed: ndt_omp ,2022-12-10T16:27:10Z,1485271028,1345299874.0,reply,"I guess there is some cache remaining, or your environment variable is wrong. Please check them.
@cjffly If it's not a bug, can I close this issue? Or can I convert this issue to a discussion thread?",kenji-miyake,210280.0,21972.0,4,0,0,0,0
Source installation failed: ndt_omp ,2022-12-10T17:17:54Z,1485271028,1345338786.0,comment,"> I guess there is some cache remaining, or your environment variable is wrong. Please check them.
> @cjffly If it's not a bug, can I close this issue? Or can I convert this issue to a discussion thread?

Maybe concert into issue would work. I will try to fix my environment and update here later",cjffly,210280.0,21972.0,4,0,0,0,0
fix(.webauto-ci): update Webauto CI for humble,2022-12-05T01:58:12Z,1475404658,1336623264.0,comment,"I'm testing this on TIER IV Evaluator before making it ""Ready for review"".",mitsudome-r,365667.0,47.0,2,1,0,1,2
fix(.webauto-ci): update Webauto CI for humble,2022-12-09T07:31:42Z,1475404658,1343953500.0,comment,I confirmed that the build is passing in evaluator so merging this PR.,mitsudome-r,365667.0,47.0,2,1,0,1,2
fix(.webauto-ci): update Webauto CI for humble,2022-12-05T01:55:09Z,1475402507,,,,mitsudome-r,,,0,1,0,1,2
ci(pre-commit-ansible): autoupdate,2022-12-04T00:10:46Z,1474287677,,,,awf-autoware-bot[bot],,,0,1,0,1,2
chore: update tool versions,2022-12-15T14:00:37Z,1473603040,1353136818.0,reply,"This issue was resolved.
https://github.com/autowarefoundation/autoware/pull/3099#discussion_r1038274845",kenji-miyake,9778543.0,1087020.0,2,1,0,2,4
chore: update tool versions,2022-12-15T14:01:40Z,1473603040,1353138278.0,reply,"CI for just in case: https://github.com/autowarefoundation/autoware/actions/runs/3704789294
-> Failed. :pleading_face: 

Will wait until aarch64.whl is available on https://pypi.org/project/clang-format/15.0.6/#files like https://pypi.org/project/clang-format/14.0.6/#files.
-> https://pypi.org/project/clang-format/16.0.0/#files",kenji-miyake,9778543.0,1087020.0,2,1,0,2,4
ci(update-tool-versions): update clang-format version check,2022-12-02T03:06:00Z,1472242213,1334705022.0,comment,https://github.com/autowarefoundation/autoware/actions/runs/3598504381,kenji-miyake,86419.0,29.0,2,2,0,3,11
ci(update-tool-versions): update clang-format version check,2022-12-02T03:07:40Z,1472242213,1334706275.0,comment,"Worked: https://github.com/autowarefoundation/autoware/compare/fd1e4cd6a7b03cfb5a80217b247e052d246272bb..e680f691835c33115ab3e62bc37ad7052e8da92b

![image](https://user-images.githubusercontent.com/31987104/205206176-8785e1da-c763-4378-a3bc-faa86559ced4.png)
",kenji-miyake,86419.0,29.0,2,2,0,3,11
ci(mirror-main-branch): add a new workflow to mirror the main branch to the main distro branch,2022-12-01T13:27:56Z,1471259379,1333771455.0,comment,"I've tested in another repository, and it worked.
![image](https://user-images.githubusercontent.com/31987104/205064751-6ad1789a-443f-42af-8fe5-f9e941eab5c6.png)
",kenji-miyake,46676.0,2359.0,1,1,0,1,15
Remove tier4_ad_api_adaptor,2022-12-01T08:43:46Z,1470908957,,,,isamu-takagi,,,0,0,0,0,0
ci(pre-commit): update commit message,2022-12-01T02:39:25Z,1470569342,,,,kenji-miyake,,,0,1,0,1,2
docs(ansible): simplify manual installation steps,2022-11-30T17:01:58Z,1469954901,,,,kenji-miyake,,,0,1,0,6,24
ci: refactor workflows to be OS/distro independent like #3087,2022-11-30T15:53:21Z,1469859292,,,,kenji-miyake,,,0,3,0,7,108
ci: remove Humble CI workflows,2022-11-30T14:36:18Z,1469741232,,,,kenji-miyake,,,0,1,0,4,210
ci(docker-build-and-push): fix the order of steps,2022-11-30T14:22:28Z,1469717817,,,,kenji-miyake,,,0,1,0,2,12
feat(ansible): verify OS before running playbooks,2022-11-30T13:16:19Z,1469616967,1332140595.0,comment,"Since it's a very simple implementation for now, any reviews are welcome!",kenji-miyake,51062.0,279.0,7,2,0,2,11
feat(ansible): verify OS before running playbooks,2022-11-30T14:07:43Z,1469616967,1332203796.0,reply,"How about using ansible_distribution_xxx variables?
```
❯ ansible -m setup localhost | grep distribution
/usr/lib/python3/dist-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated
  ""class"": algorithms.Blowfish,
[WARNING]: No inventory was parsed, only implicit localhost is available
        ""ansible_distribution"": ""Ubuntu"",
        ""ansible_distribution_file_parsed"": true,
        ""ansible_distribution_file_path"": ""/etc/os-release"",
        ""ansible_distribution_file_variety"": ""Debian"",
        ""ansible_distribution_major_version"": ""22"",
        ""ansible_distribution_release"": ""jammy"",
        ""ansible_distribution_version"": ""22.04"",
```",wep21,51062.0,279.0,7,2,0,2,11
feat(ansible): verify OS before running playbooks,2022-11-30T14:09:10Z,1469616967,1332205895.0,comment,"Oh, it's a good idea! Thanks.",kenji-miyake,51062.0,279.0,7,2,0,2,11
feat(ansible): verify OS before running playbooks,2022-11-30T14:13:20Z,1469616967,1332211357.0,reply,"I have never used it, but  ""ansible.builtin.meta: end_play"" might fit what you want to do.
https://docs.ansible.com/ansible/latest/collections/ansible/builtin/meta_module.html",0x126,51062.0,279.0,7,2,0,2,11
feat(ansible): verify OS before running playbooks,2022-11-30T15:35:12Z,1469616967,1332356048.0,comment,"Since `end_play` succeeds the play (and cannot set a message), `ansible.builtin.fail` would be better?

https://docs.ansible.com/ansible/latest/collections/ansible/builtin/fail_module.html#ansible-collections-ansible-builtin-fail-module

```
TASK [Verify OS] *********************************************************************************************************************************

PLAY RECAP ***************************************************************************************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Completed.
```",kenji-miyake,51062.0,279.0,7,2,0,2,11
feat(ansible): verify OS before running playbooks,2022-11-30T17:19:48Z,1469616967,1332494942.0,comment,I'll merge this tomorrow (after getting more feedback from my colleagues) and replace `20.04` with `22.04`.,kenji-miyake,51062.0,279.0,7,2,0,2,11
feat(ansible): verify OS before running playbooks,2022-12-01T01:00:25Z,1469616967,1332990994.0,reply,LGTM,yukkysaito,51062.0,279.0,7,2,0,2,11
ci(docker-build-and-push): use dpkg --print-architecture,2022-11-30T12:52:57Z,1469589594,,,,kenji-miyake,,,0,1,0,2,18
ci: refactor workflows,2022-11-30T12:10:32Z,1469532382,1332052868.0,comment,"Testing:
- https://github.com/autowarefoundation/autoware/actions/runs/3583297023

Worked.
![image](https://user-images.githubusercontent.com/31987104/204798151-d25b2727-b447-4a26-9639-505537bbabcb.png)
",kenji-miyake,7289.0,66.0,1,2,0,4,85
WIP: test Rolling,2022-11-30T14:00:33Z,1469516819,1332194158.0,comment,I'll replace `humble` with `rolling` after https://github.com/autowarefoundation/autoware/pull/2692 is merged.,kenji-miyake,18518625.0,7315.0,2,3,0,6,95
WIP: test Rolling,2022-11-30T14:20:17Z,1469516819,1332221118.0,comment,"Test results:
- https://github.com/autowarefoundation/autoware/actions/runs/3584095820
  - -> https://github.com/autowarefoundation/autoware/actions/runs/3584097375/jobs/6030331797

![image](https://user-images.githubusercontent.com/31987104/204825155-3e7b329e-2fb5-440a-9e77-8526bc1937c6.png)

- https://github.com/autowarefoundation/autoware/actions/runs/3584114516
  - -> https://github.com/autowarefoundation/autoware/actions/runs/3584115646/jobs/6030373665

![image](https://user-images.githubusercontent.com/31987104/204825230-e5ad7174-91ed-4c36-8229-4b1e9b98df99.png)

- https://github.com/autowarefoundation/autoware/actions/runs/3584419664
  - -> https://github.com/autowarefoundation/autoware/actions/runs/3584421257

![image](https://user-images.githubusercontent.com/31987104/204831861-1f5af495-dab8-459f-8183-650605ea2e5a.png)

- https://github.com/autowarefoundation/autoware/actions/runs/3584421405
  - -> https://github.com/autowarefoundation/autoware/actions/runs/3584422298

![image](https://user-images.githubusercontent.com/31987104/204831835-47aeae7f-19b4-4aa3-b1de-1de5d2bedd8e.png)
",kenji-miyake,18518625.0,7315.0,2,3,0,6,95
chore(.gitignore): ignore CodeChecker files,2022-11-30T11:04:19Z,1469447295,,,,kenji-miyake,,,0,1,0,1,3
build(CUDA): upgrade CUDA versions,2023-04-07T04:38:04Z,1469440019,1499926163.0,comment,"Docker CI:
- https://github.com/autowarefoundation/autoware/actions/runs/4635477344
- https://github.com/autowarefoundation/autoware/actions/runs/4635477685",kenji-miyake,18522215.0,11036342.0,2,3,0,3,33
build(CUDA): upgrade CUDA versions,2023-09-05T15:32:20Z,1469440019,1706847144.0,reply,"https://github.com/orgs/autowarefoundation/discussions/3651#discussioncomment-6897536

Finally

```console
mfc@mfc-leo:~$ find-cuda-versions --cuda 12.0 --os ubuntu2204
[cudnn x86_64]
8.8.0.121-1+cuda12.0
8.8.1.3-1+cuda12.0

[cudnn sbsa]
8.8.0.121-1+cuda12.0
8.8.1.3-1+cuda12.0

[nvinfer x86_64]
8.6.0.12-1+cuda12.0
8.6.1.6-1+cuda12.0

[nvinfer sbsa]
8.6.2.2-1+cuda12.0

[tensorrt x86_64]
8.6.0.12-1+cuda12.0
8.6.1.6-1+cuda12.0

[tensorrt sbsa]
8.6.2.2-1+cuda12.0

```",xmfcx,18522215.0,11036342.0,2,3,0,3,33
Transition to Humble,2022-11-30T10:22:40Z,1469273401,1331932180.0,comment,"I've heard that we would like to merge https://github.com/autowarefoundation/autoware.universe/pull/2370 before branching out galactic.
We will wait until tomorrow before starting the above tasks.",mitsudome-r,,5132.0,1,0,0,0,0
Rviz2 core dumped issue,2022-11-29T04:08:47Z,1467417160,,,,TZECHIN6,,,0,0,0,0,0
Create api for vehicle status,2023-01-27T07:14:48Z,1557557091,1406111586.0,reply,"For `target_velocity` and `target_acceleration`, It might be better to separate these as vehicle command message.
For `geo_point`, this cannot be provided if the map only has local coordinates.",isamu-takagi,19708387.0,5191083.0,5,0,0,0,0
Create api for vehicle status,2023-01-31T05:39:38Z,1557557091,1409793694.0,comment,"> For `target_velocity` and `target_acceleration`, It might be better to separate these as vehicle command message. For `geo_point`, this cannot be provided if the map only has local coordinates.

Sorry for late reply, I miss the message.
I agree that we should move the `target_velocity` and `target_acceleration` to vehicle_command.
We should just put in the current vehicle status data

For the `geo_point` I think we might able to convert from MGRS to the global longitude and latitude ",tkhmy,19708387.0,5191083.0,5,0,0,0,0
Create api for vehicle status,2023-02-01T04:39:49Z,1557557091,1411454155.0,comment,"I created the document for vehicle status
https://autowarefoundation.github.io/autoware-documentation/pr-312/design/autoware-interfaces/ad-api/list/api/vehicle/",tkhmy,19708387.0,5191083.0,5,0,0,0,0
Create api for vehicle status,2023-02-01T05:41:34Z,1557557091,1411496744.0,reply,"> For the geo_point I think we might able to convert from MGRS to the global longitude and latitude

According to [the lanelet2_extension documentation](https://github.com/autowarefoundation/autoware_common/tree/main/tmp/lanelet2_extension#io), Autoware works in a local coordinate system independent of MGRS by setting `local_x` and `local_y`.",isamu-takagi,19708387.0,5191083.0,5,0,0,0,0
Create api for vehicle status,2023-06-26T07:50:49Z,1557557091,1606904504.0,reply,"I forgot the API to control doors. I have three suggestions.

1. array command
```yaml
message:
  - NONE
  - CLOSE
  - CLOSE
  - NONE
```

2. index command
```yaml
message:
  - { index: 1, command: CLOSE }
  - { index: 2, command: CLOSE }
```

3. role command
```yaml
message:
  - { role: GET_ON, command: CLOSE }
```",isamu-takagi,19708387.0,5191083.0,5,0,0,0,0
feat(docker): add opencl vendor,2022-11-25T08:05:18Z,1464172580,,,,angry-crab,,,0,2,0,1,5
Rviz2 drops to 1-5fps when enabling pointcloud2 topic in planning simulation tutorial,2022-11-29T16:54:59Z,1463225925,1330959199.0,reply,@TZECHIN6 please post your question here https://github.com/orgs/autowarefoundation/discussions/categories/q-a for faster assistance,BonoloAWF,1318846.0,450235.0,3,0,0,0,0
Rviz2 drops to 1-5fps when enabling pointcloud2 topic in planning simulation tutorial,2022-11-30T01:42:47Z,1463225925,1331538360.0,comment,"@BonoloAWF Thanks for the advice, will do it now.",TZECHIN6,1318846.0,450235.0,3,0,0,0,0
Rviz2 drops to 1-5fps when enabling pointcloud2 topic in planning simulation tutorial,2022-12-09T18:11:24Z,1463225925,1344612640.0,comment,DDS Tuning fix the problem.,TZECHIN6,1318846.0,450235.0,3,0,0,0,0
using of road_edge in op_local_planner,2022-11-23T10:17:39Z,1461275197,1324827675.0,reply,"Seems to be duplicated.
https://github.com/autowarefoundation/autoware/discussions/3065

Please refrain from opening an issue if it's not a bug.",kenji-miyake,6287.0,6287.0,1,0,0,0,0
ci(pre-commit-ansible): autoupdate,2022-11-22T00:10:22Z,1458780554,,,,awf-autoware-bot[bot],,,0,1,0,1,2
"revert(autoware.repos): revert ""feat: add ament_cmake fork (#370)""",2022-11-21T05:43:22Z,1457341228,,,,kenji-miyake,,,0,1,0,1,4
ci(pre-commit-ansible): autoupdate,2022-11-18T10:02:40Z,1454653057,1319785835.0,reply,"I'm not sure why `pre-commit-ansible` is resolved, but since there is no problem now, I'll merge this.
https://github.com/autowarefoundation/autoware/pull/3032/commits/7528bd4bc8f1a58536c659e6509b7a6a3509f074",kenji-miyake,7335.0,7310.0,1,1,0,1,2
ci(pre-commit-optional): autoupdate,2022-11-18T08:00:46Z,1454652983,,,,awf-autoware-bot[bot],,,0,1,0,1,2
ci(pre-commit): add autoupdate workflow,2022-11-18T08:10:08Z,1454651882,1319674776.0,comment,"Worked:
https://github.com/autowarefoundation/autoware/pull/3051
https://github.com/autowarefoundation/autoware/pull/3052",kenji-miyake,966.0,617.0,3,1,0,3,112
ci(pre-commit): add autoupdate workflow,2022-11-18T08:15:14Z,1454651882,1319679275.0,comment,"Since these are just new CI workflows, I'll merge and test them.",kenji-miyake,966.0,617.0,3,1,0,3,112
ci(pre-commit): add autoupdate workflow,2022-11-18T08:15:38Z,1454651882,1319679611.0,comment,FYI @xmfcx ,kenji-miyake,966.0,617.0,3,1,0,3,112
chore(.clang-format): modify include order for srvs package,2022-11-16T07:18:55Z,1451017751,,,,isamu-takagi,,,0,1,0,1,3
ci(.pre-commit-config-ansible.yaml): update ansible-lint version,2022-11-17T09:58:17Z,1449717215,1318378422.0,comment,"<https://github.com/autowarefoundation/autoware/actions/runs/3470511085/jobs/5798798988>
There are three errors in v6.8.6:
1. name[play] All plays should be named.
2. name[template] Jinja templates should only be at the end of 'name'
3. risky-file-permissions File permissions unset or incorrect.

The 2nd error will be fixed but not merged yet. <https://github.com/osism/issues/issues/326>
So I tried to use v6.6.1 just before this feature was merged <https://github.com/ansible/ansible-lint/releases/tag/v6.7.0>, but another error appeared related to <https://github.com/ansible/ansible-lint/issues/1780>.

I decided to just update to pass [the CI error](https://github.com/autowarefoundation/autoware/actions/runs/3469781105/jobs/5797182594).",yukke42,239167.0,163225.0,2,3,0,1,2
ci(.pre-commit-config-ansible.yaml): update ansible-lint version,2022-11-17T10:31:13Z,1449717215,1318423904.0,comment,"@kenji-miyake 
Hello. Could you check this PR?",yukke42,239167.0,163225.0,2,3,0,1,2
fix(gitignore): add capture folder to gitignore,2022-11-17T07:18:45Z,1449684828,1318194894.0,reply,"@xmfcx cc: @kenji-miyake 
I think `log`  folder is automatically generated by ros but tier4_screen_capture_rviz_plugin intentionally generate  recorded video so I thought it would be better to generate folder explicitly.",taikitanaka3,5027.0,155192.0,1,1,0,1,3
fix(ansible/git_lfs): fix git lfs installation steps,2022-11-15T11:04:01Z,1449553640,1315148973.0,comment,"@kenji-miyake Can we update [.pre-commit-config-ansible.yaml](https://github.com/autowarefoundation/autoware/blob/ef48253ce76e855d6c08e70be6013733522805a3/.pre-commit-config-ansible.yaml#L3) to pass CI? 

[This CI error](https://github.com/autowarefoundation/autoware/actions/runs/3469781105/jobs/5797182594) is a bug and it has fixed in https://github.com/ansible/ansible-lint/pull/1859 and [v5.4.0](https://github.com/ansible/ansible-lint/releases/tag/v5.4.0)",yukke42,247483.0,1659.0,4,5,0,2,30
fix(ansible/git_lfs): fix git lfs installation steps,2022-11-15T12:38:22Z,1449553640,1315253520.0,comment,<https://github.com/autowarefoundation/autoware/pull/3032>,yukke42,247483.0,1659.0,4,5,0,2,30
fix(ansible/git_lfs): fix git lfs installation steps,2022-11-16T05:48:52Z,1449553640,1316400078.0,reply,"> Can we update [.pre-commit-config-ansible.yaml](https://github.com/autowarefoundation/autoware/blob/ef48253ce76e855d6c08e70be6013733522805a3/.pre-commit-config-ansible.yaml#L3) to pass CI?

@yukke42 Sure. Thank you for the PR. I'll check it later.
Seeing #3032, it seems that we need to change some configurations because several new checks are added.",kenji-miyake,247483.0,1659.0,4,5,0,2,30
fix(ansible/git_lfs): fix git lfs installation steps,2022-11-18T07:08:58Z,1449553640,1319628513.0,reply,@yukke42 Can I merge this? -> He said okay.,kenji-miyake,247483.0,1659.0,4,5,0,2,30
refactor(ansible/git_lfs): remove unnecessary installation steps,2022-11-15T10:54:19Z,1449445217,1315137319.0,comment,Move to #3029.,kenji-miyake,5562.0,5562.0,1,3,0,2,16
feat(ansible): add git-lfs role,2022-11-15T09:13:20Z,1449360988,1315011613.0,reply,@kenji-miyake @yukke42 why did you choose to not install with `sudo apt install git-lfs`?,xmfcx,3036.0,3365.0,3,2,0,5,33
feat(ansible): add git-lfs role,2022-11-15T09:20:03Z,1449360988,1315021361.0,reply,"@xmfcx Ah, did you mean the manual installation step? I'm sorry, I haven't checked it carefully. There were some missing commands.

I'll update it.

```console
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs
git lfs install
```
",kenji-miyake,3036.0,3365.0,3,2,0,5,33
feat(ansible): add git-lfs role,2022-11-15T09:21:44Z,1449360988,1315023332.0,reply,https://github.com/autowarefoundation/autoware/pull/3028,kenji-miyake,3036.0,3365.0,3,2,0,5,33
ci(docker-build-and-push): add release tag as docker build,2022-11-15T08:09:20Z,1449344401,1314939126.0,comment,Not yet.,mitsudome-r,1118727.0,292.0,3,1,0,5,7
ci(docker-build-and-push): add release tag as docker build,2022-11-16T05:50:23Z,1449344401,1316401610.0,reply,Related: https://github.com/autowarefoundation/autoware-documentation/pull/244,kenji-miyake,1118727.0,292.0,3,1,0,5,7
ci(docker-build-and-push): add release tag as docker build,2022-11-28T06:49:02Z,1449344401,1328617500.0,comment,"tested under my fork:
* https://github.com/mitsudome-r/autoware/actions/runs/3540495760
* Generated docker image: https://github.com/mitsudome-r/autoware/pkgs/container/autoware-universe/53403595?tag=galactic-2022.11-amd64",mitsudome-r,1118727.0,292.0,3,1,0,5,7
chore: add release scripts,2022-11-11T08:38:41Z,1445133456,,,,kenji-miyake,,,0,1,0,2,87
build(ansible/ros2_dev_tools):  follow updated humble documentation,2022-11-11T04:03:08Z,1444894442,,,,Shin-kyoto,,,0,1,0,2,40
feat(ansible): add option to install nvidia+cuda drivers with ansible,2022-12-07T06:45:55Z,1439543226,1340471946.0,comment,@kenji-miyake I tested this PR on a clean Ubuntu 22.04 install and there was no issue while following only the Docker installation instructions. This is ready to be merged.,maxime-clem,2508658.0,2508361.0,1,2,0,1,20
build(ansible/ros2_dev_tools): change ros2_dev_tools to follow humble documentation,2022-11-07T12:00:46Z,1438242324,,,,Shin-kyoto,,,0,1,0,2,55
chore(.markdownlint.yaml): use ordered style for MD029,2022-11-07T10:27:07Z,1438119547,1305399841.0,comment,"With this change, the following style isn't allowed.
![image](https://user-images.githubusercontent.com/31987104/200287406-c96bd4e5-4f2b-4514-bd05-9815deee043d.png)

We need to fix it to the following style. If you write `2.`, it will be automatically formatted.
![image](https://user-images.githubusercontent.com/31987104/200287454-52772ea7-422d-4471-a97c-77c7aec41043.png)
",kenji-miyake,929.0,120.0,2,1,0,1,2
chore(.markdownlint.yaml): use ordered style for MD029,2022-11-07T10:32:52Z,1438119547,1305405929.0,reply,"I agree with the `ordered` style as long as it is automatically enforced, fixed.",xmfcx,929.0,120.0,2,1,0,1,2
docs(ansible/cuda): fix outdated cuda version in README,2022-10-31T22:02:53Z,1430553689,,,,tleyden,,,0,1,0,1,2
chore(release): update awsim-stable branch,2022-10-28T12:01:20Z,1427158487,,,,shmpwk,,,0,4,0,4,25
fix(cuda): Update cuda-keyring installation url,2022-10-28T06:18:47Z,1426737848,1294513670.0,reply,"@YoshiRi Thank you for the PR, but we intentionally use `20.04` for now.

>     ""msg"": ""No package matching 'cuda-cudart-dev-11-6' is available""

https://github.com/autowarefoundation/autoware/actions/runs/3343222203/jobs/5536214854#step:4:14071",kenji-miyake,2990.0,484.0,2,1,0,1,2
fix(cuda): Update cuda-keyring installation url,2022-10-28T07:00:33Z,1426737848,1294548304.0,comment,"OK, I will retrieve it",YoshiRi,2990.0,484.0,2,1,0,1,2
feat: move ndt_omp into universe,2022-10-27T08:53:08Z,1425270649,,,,kminoda,,,0,1,0,1,4
chore(.markdown-link-check.json): ignore 127.0.0.1,2022-10-26T09:40:00Z,1423732932,,,,kenji-miyake,,,0,1,0,1,3
finding out a general informantion,2022-10-14T03:18:37Z,1408696075,,,,urbansound8K,,,0,0,0,0,0
chore(deps): bump styfle/cancel-workflow-action from 0.10.1 to 0.11.0,2022-10-13T11:44:15Z,1407655777,,,,dependabot[bot],,,0,1,0,1,2
chore(release): freeze repos files,2022-10-13T07:47:06Z,1407312582,,,,shmpwk,,,0,1,0,2,14
chore: update awsim-stable branch,2022-10-13T07:41:09Z,1407149622,1277170085.0,reply,I've manually merged this on my local machine.,kenji-miyake,9234.0,9394.0,1,0,0,0,0
chore: freeze repos files ,2022-10-13T05:07:45Z,1407144118,1277037376.0,comment,"To resolve conflict, I want to merge https://github.com/autowarefoundation/autoware/pull/2941 first.",shmpwk,10095.0,742.0,1,0,0,0,0
Running pre-commit on local machine gives error,2022-10-11T19:03:56Z,1404800700,1275146247.0,reply,"@xmfcx I think it's https://github.com/pre-commit/pre-commit/issues/2336. Could you try these commands?

```bash
rm -rf ~/.local/share/virtualenv/ && curl -fsSL https://raw.githubusercontent.com/deadsnakes/python3.10-jammy/ubuntu/jammy/debian/patches/venv-scheme.diff | sudo patch /usr/lib/python3.10/sysconfig.py
```",kenji-miyake,58698.0,14558.0,2,0,0,0,0
Running pre-commit on local machine gives error,2022-10-12T07:19:36Z,1404800700,1275703347.0,comment,"@kenji-miyake this fixed my problem, thanks!",xmfcx,58698.0,14558.0,2,0,0,0,0
fix(setup): fix pipx check,2022-10-07T08:49:59Z,1400839013,,,,kenji-miyake,,,0,1,0,1,2
refactor(ansible/docker_engine): updated docker installation,2022-10-07T07:59:00Z,1400716459,1271248996.0,reply,"@aaryanmurgunde Thanks! Could you keep the In-review/Post-review non-checked right after you create a PR, please? They will be checked later.
![image](https://user-images.githubusercontent.com/31987104/194502636-18572c54-d36e-4cf8-a051-cf548cdaab49.png)

Also, I've fixed the `task/main.yaml` to be the same as your change.",kenji-miyake,9966.0,3266.0,7,5,0,2,24
refactor(ansible/docker_engine): updated docker installation,2022-10-07T07:59:50Z,1400716459,1271250002.0,reply,"There was an error. I'll fix it.
https://github.com/autowarefoundation/autoware/actions/runs/3203155376/jobs/5232911541#step:4:1341",kenji-miyake,9966.0,3266.0,7,5,0,2,24
refactor(ansible/docker_engine): updated docker installation,2022-10-07T08:07:31Z,1400716459,1271262503.0,comment,"@kenji-miyake I am sorry, I'm new to contributing to open source. I'll make sure that I dont do that again 

",aaryanmurgunde,9966.0,3266.0,7,5,0,2,24
refactor(ansible/docker_engine): updated docker installation,2022-10-07T08:09:21Z,1400716459,1271264239.0,reply,"No problem! I'd appreciate it if you could read the guidelines. And if something isn't clear, please feel free to open a discussion thread.
https://autowarefoundation.github.io/autoware-documentation/main/contributing/",kenji-miyake,9966.0,3266.0,7,5,0,2,24
refactor(ansible/docker_engine): updated docker installation,2022-10-07T08:53:49Z,1400716459,1271311672.0,comment,"> There was an error. I'll fix it. https://github.com/autowarefoundation/autoware/actions/runs/3203155376/jobs/5232911541#step:4:1341

This was fixed right ? or you need me to make any changes ?",aaryanmurgunde,9966.0,3266.0,7,5,0,2,24
refactor(ansible/docker_engine): updated docker installation,2022-10-07T08:55:51Z,1400716459,1271313774.0,reply,"I'm not sure yet. Please wait for a while, sorry. :bow: ",kenji-miyake,9966.0,3266.0,7,5,0,2,24
refactor(ansible/docker_engine): updated docker installation,2022-10-07T09:26:39Z,1400716459,1271347408.0,reply,`ansible.builtin.apt_key` didn't create a directory automatically.,kenji-miyake,9966.0,3266.0,7,5,0,2,24
docs(ansible/nvidia_docker): update to new docker tag,2022-10-06T14:06:14Z,1399705812,,,,aaryanmurgunde,,,0,1,0,1,2
feat(setup): add an option to install dev packages,2022-10-06T10:16:33Z,1399288515,,,,Sharrrrk,,,0,2,0,4,36
perf(docker): reduce prebuilt docker image size,2022-10-06T09:42:13Z,1398933253,1269697623.0,reply,"@Sharrrrk Thank you so much for this improvement!
Would it be possible for you to split `install_devel`-related changes into a separate PR because it's `feat`?
Like `feat(setup): add an option to install dev packages`.",kenji-miyake,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-10-06T09:51:22Z,1398933253,1269712600.0,comment,"> @Sharrrrk Thank you so much for this improvement! Would it be possible for you to split `install_devel`-related changes into a separate PR because it's `feat`? Like `feat(setup): add an option to install dev packages`.

Sure, I'll create a separate PR.",Sharrrrk,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-10-06T10:53:15Z,1398933253,1269803383.0,comment,@kenji-miyake Would it be possible that you could do a test of this script before merging. Thanks.,Sharrrrk,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-10-06T10:54:20Z,1398933253,1269804924.0,reply,"@Sharrrrk Yes, I'll trigger GitHub Actions.",kenji-miyake,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-10-28T18:13:40Z,1398933253,1295310983.0,reply,Can we test this PR? What's the status?,doganulus,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-10-29T03:45:33Z,1398933253,1295715191.0,reply,"> Can we test this PR?

@doganulus What do you mean by the word ""test""?
To check the workflow, we can trigger it manually.
To try out the generated image, you can build it locally, or you can fork and try this PR.

> What's the status?

I'm waiting for the review comments to be applied.
And I'm planning to check this in more detail, but it's difficult for me to spare time for a while. I'm sorry for that, but please wait for a bit more.",kenji-miyake,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-10-29T08:09:19Z,1398933253,1295766153.0,reply,"By testing, I mean using the resulting image, for example, with the AWSIM simulator or the scenario simulator. I think a runtime image as in this PR would be an improvement for these use cases. Thank you for the explanation!",doganulus,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-12-13T13:58:48Z,1398933253,1348623397.0,reply,"~~Following the discussion here: https://github.com/autowarefoundation/autoware-documentation/issues/270~~

~~Is it possible to keep the prebuilt image as it is, and add this runtime/release image separately?~~",xmfcx,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-12-13T14:01:12Z,1398933253,1348628914.0,reply,"> Is it possible to keep the prebuilt image as it is, and add this runtime/release image separately?

@xmfcx Yes, it's possible. But could you explain some reasons/use cases for that, if possible?
Since Autoware changes every day, the prebuilt artifacts cannot be reused generally.",kenji-miyake,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2022-12-16T13:24:46Z,1398933253,1354762550.0,reply,"> > Is it possible to keep the prebuilt image as it is, and add this runtime/release image separately?
> 
> @xmfcx Yes, it's possible. But could you explain some reasons/use cases for that, if possible? Since Autoware changes every day, the prebuilt artifacts cannot be reused generally.

Ok, since @cyn-liu agreed to adapt the training video to take this into account in https://github.com/autowarefoundation/autoware-documentation/issues/270#issuecomment-1352822850

We don't need to include build artifacts in the new prebuilt image. I take back my request.",xmfcx,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2023-01-16T10:11:12Z,1398933253,1383801835.0,reply,"Hi, @kenji-miyake .
Can we merge this pr?",liuXinGangChina,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2023-01-17T11:37:02Z,1398933253,1385293842.0,reply,"@liuXinGangChina cc @Sharrrrk As we moved to Humble, there are conflicts. Could you fix them?
![image](https://user-images.githubusercontent.com/31987104/212887950-cf2fa0c6-9f3a-402b-9891-72942775e57c.png)

Also, I didn't notice that there were changes after my last review. I'm sorry for that, but I'd appreciate it if you re-request a review by clicking the button.
![image](https://user-images.githubusercontent.com/31987104/212888139-5d8ad0ea-42bb-489d-952e-7f2ff2014720.png)
![image](https://user-images.githubusercontent.com/31987104/212888372-a69ac80c-c252-4731-979c-91e5c90d4662.png)

So, now do you mean that you've addressed my comments and it's ready to merge?
In that case, I'm sorry for my late work, but I'll manage to make time for a review this week.",kenji-miyake,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2023-02-01T08:14:30Z,1398933253,1411632740.0,comment,"Hi, @kenji-miyake , the conflicts is about cuda_base_image, as it has been set to ubuntu:22.04 on main branch, but nvidia/cuda dit not has docker image match the cuda:11.6 + ubuntu22.04. Thank you so much if you could give some advice.

<<<<<<< 2840-reduce-prebuilt-docker-image-size
base_image=ubuntu:20.04
cuda_base_image=nvidia/cuda:11.6.2-runtime-ubuntu20.04
=======
base_image=ubuntu:22.04
cuda_base_image=ubuntu:22.04
>>>>>>> main
cuda_version=11.6
cudnn_version=8.4.1.50-1+cuda11.6
tensorrt_version=8.4.2-1+cuda11.6
",Sharrrrk,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2023-02-05T16:20:18Z,1398933253,1418108024.0,reply,"@Sharrrrk I'm sorry to be late.
We need to upgrade the CUDA version to 11.8 or 12.0 to use a CUDA image for the base image. However, since there is no arm64 (sbsa) version provided yet, we can't upgrade the version.
See also https://github.com/autowarefoundation/autoware/pull/3084#discussion_r1035826071.

So, until then, I think using `ubuntu:22.04` for the base image is okay.",kenji-miyake,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2023-02-08T02:20:39Z,1398933253,1421883888.0,comment,"> @Sharrrrk I'm sorry to be late. We need to upgrade the CUDA version to 11.8 or 12.0 to use a CUDA image for the base image. However, since there is no arm64 (sbsa) version provided yet, we can't upgrade the version. See also [#3084 (comment)](https://github.com/autowarefoundation/autoware/pull/3084#discussion_r1035826071).
> 
> So, until then, I think using `ubuntu:22.04` for the base image is okay.

Do you mean we should set both base_image and cuda_base_image to ubuntu:22.04 for now?",Sharrrrk,12705996.0,10409.0,16,11,0,6,65
perf(docker): reduce prebuilt docker image size,2023-02-08T03:51:50Z,1398933253,1421954597.0,reply,"@Sharrrrk Yes, exactly. It will be resolved in https://github.com/autowarefoundation/autoware/pull/3084, but arm64 TensorRT packages aren't released yet. We have to wait for that.",kenji-miyake,12705996.0,10409.0,16,11,0,6,65
feat(repos): add awsim_sensor_kit_launch,2022-10-03T09:44:07Z,1394444464,,,,shmpwk,,,0,1,0,1,4
chore: update awsim-stable branch,2022-10-04T01:29:42Z,1394357499,1266284931.0,comment,"Considering https://github.com/autowarefoundation/autoware/pull/2912, I updated this PR.",shmpwk,62016.0,60668.0,1,1,0,2,32
chore(deps): bump styfle/cancel-workflow-action from 0.10.0 to 0.10.1,2022-10-01T03:18:04Z,1393208970,1264218825.0,comment,The following labels could not be found: `github-actions`.,dependabot[bot],934.0,2.0,1,1,0,1,2
[CI] `pipx install ansible` fails on the self-hosted runner.,2022-10-27T20:44:01Z,1390094889,1294042398.0,comment,"Seeing the logs, it seems it fails if the OS version is different?
https://github.com/autowarefoundation/autoware/actions/workflows/build-humble-self-hosted.yaml
https://github.com/autowarefoundation/autoware/actions/workflows/build-main-self-hosted.yaml

Related: https://github.com/pypa/pipx/issues/278",kenji-miyake,2491947.0,2491594.0,2,0,0,0,0
[CI] `pipx install ansible` fails on the self-hosted runner.,2022-10-27T20:49:54Z,1390094889,1294047782.0,comment,"I guess it will be resolved if we move to Humble.
So, I'll stop `build-main-self-hosted` and mark this issue as not planned.",kenji-miyake,2491947.0,2491594.0,2,0,0,0,0
ci(backport): use generated token instead of GITHUB_TOKEN,2022-09-28T08:53:58Z,1388920408,1260594611.0,reply,"@h-ohta You've previously confirmed that `GITHUB_TOKEN` works. Could you clarify what the problem is?
https://github.com/h-ohta/autoware.universe/pull/4
https://github.com/h-ohta/autoware.universe/commit/0249db24ea6c8e52bd5bd06fa29bc45881b84645",kenji-miyake,70518.0,2667.0,4,1,0,1,9
ci(backport): use generated token instead of GITHUB_TOKEN,2022-09-29T03:09:33Z,1388920408,1261691212.0,comment,"@kenji-miyake 
Without same fix as this PR, I make a PR https://github.com/h-ohta/autoware/pull/3 , and make  a backport PR https://github.com/h-ohta/autoware/pull/5. Then git hub actions does not works.",h-ohta,70518.0,2667.0,4,1,0,1,9
ci(backport): use generated token instead of GITHUB_TOKEN,2022-09-29T03:44:05Z,1388920408,1261717235.0,reply,"Ah, I understand
If you don't use a technique like https://github.blog/changelog/2022-09-08-github-actions-use-github_token-with-workflow_dispatch-and-repository_dispatch/, `GITHUB_TOKEN` doesn't trigger other workflows recursively.
It's the same as this issue: https://github.com/tibdex/backport/issues/55

So it's reasonable to accept this change.",kenji-miyake,70518.0,2667.0,4,1,0,1,9
ci(backport): use generated token instead of GITHUB_TOKEN,2022-09-29T04:42:23Z,1388920408,1261746147.0,comment,@kenji-miyake I did not know same issue. Thank you for your information and review.,h-ohta,70518.0,2667.0,4,1,0,1,9
refactor(setup): use pipx for Ansible to avoid conflicts between pip and apt packages,2022-09-27T08:38:39Z,1387358132,,,,kenji-miyake,,,0,2,0,1,20
docs(ansible/tensorrt): update install instructions of tensorrt,2022-09-22T04:55:48Z,1381815750,1254528436.0,reply,@maxime-clem Could you merge this if everything is okay? :bow: ,kenji-miyake,9119.0,1408.0,3,1,0,1,8
docs(ansible/tensorrt): update install instructions of tensorrt,2022-09-22T05:00:46Z,1381815750,1254531252.0,comment,"> @maxime-clem Could you merge this if everything is okay? bow

Sorry I cannot merge this PR as  I do not have `write access` to this repository.",maxime-clem,9119.0,1408.0,3,1,0,1,8
docs(ansible/tensorrt): update install instructions of tensorrt,2022-09-22T07:04:11Z,1381815750,1254613887.0,reply,"@maxime-clem Ah, sorry. This is `autoware`, not `autoware-documentation`. So I'll merge it.",kenji-miyake,9119.0,1408.0,3,1,0,1,8
Autoware humble doesn't compile without CUDA,2022-09-21T13:03:45Z,1380882568,1253681279.0,reply,@xmfcx Could you rerun `rosdep install`? It seems new dependencies were added.,kenji-miyake,1190.0,771.0,3,0,0,0,0
Autoware humble doesn't compile without CUDA,2022-09-21T13:04:40Z,1380882568,1253682441.0,reply,"The no-CUDA build passes in CI.
https://github.com/autowarefoundation/autoware.universe/actions/workflows/build-and-test.yaml",kenji-miyake,1190.0,771.0,3,0,0,0,0
Autoware humble doesn't compile without CUDA,2022-09-21T13:10:44Z,1380882568,1253689540.0,comment,"Hmm it installed
```
executing command [sudo -H apt-get install -y ros-humble-cudnn-cmake-module]
executing command [sudo -H apt-get install -y ros-humble-tensorrt-cmake-module]
```

Now it seems to be working. Thanks for the help.",xmfcx,1190.0,771.0,3,0,0,0,0
chore: update PR template for private links,2022-09-20T09:42:17Z,1379052051,1252102356.0,reply,"@xmfcx We'd like to add a description for private links because TIER IV will add some private Jira ticket links for internal tracking.
The private links are just supplemental information, and the PR description should contain all necessary information.
Is that okay for you?",kenji-miyake,5256.0,3077.0,1,1,0,1,2
feat: add autoware adapi messages repository,2022-09-15T10:37:17Z,1374311395,,,,isamu-takagi,,,0,1,0,1,4
chore: remove grid_map from repos,2022-09-14T01:03:34Z,1372170030,1246105307.0,reply,"@wep21 Thank you so much! :smile: 
For future reference, would it be possible for you to add some links to the description?",kenji-miyake,1477362.0,799.0,2,1,0,1,4
chore: remove grid_map from repos,2022-10-01T02:12:24Z,1372170030,1264200417.0,comment,[Sync is out.](https://discourse.ros.org/t/new-packages-for-ros-2-humble-hawksbill-2022-09-30/27583),wep21,1477362.0,799.0,2,1,0,1,4
ci: add backport action,2022-09-12T06:24:48Z,1369315888,1243273214.0,comment,"@kenji-miyake I'm soorry to disable auto-merge due to do force push to resolve DCO...
Could you merge it if there are no problems ?",h-ohta,3042.0,2286.0,1,1,0,1,26
"ci(build, vcs-import): add vcs export --exact",2022-09-09T01:11:51Z,1367147900,1241390173.0,comment,"Test result:
![image](https://user-images.githubusercontent.com/31987104/189251570-30b35edc-d934-4a33-b603-27d758eef2f5.png)
",kenji-miyake,1145137.0,626.0,1,2,0,5,20
fix(ansible/plotjuggler): fix workaround of pyOpenSSL,2022-09-07T04:50:38Z,1364075975,1238905279.0,comment,"https://github.com/autowarefoundation/autoware/runs/8220901917?check_suite_focus=true#step:4:10948
![image](https://user-images.githubusercontent.com/31987104/188791308-9411db70-4487-4673-9da7-c341f44ceaac.png)
",kenji-miyake,12033.0,1009.0,4,1,0,2,9
fix(ansible/plotjuggler): fix workaround of pyOpenSSL,2022-09-07T05:43:44Z,1364075975,1238931930.0,comment,"It seems ROS breaks pip? :thinking: 
https://github.com/autowarefoundation/autoware/pull/2850/commits/5a7cd272faa821b8e47db7e75ba5cb03a752d943

```
TASK [autoware.dev_env.ros2 : tmp after] **************************************************************************************************************************************************************************
task path: /root/.ansible/collections/ansible_collections/autoware/dev_env/roles/ros2/tasks/main.yaml:49
<127.0.0.1> ESTABLISH LOCAL CONNECTION FOR USER: root
<127.0.0.1> EXEC /bin/sh -c 'echo ~root && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '( umask 77 && mkdir -p ""` echo /root/.ansible/tmp `""&& mkdir ""` echo /root/.ansible/tmp/ansible-tmp-1662529320.9488437-25055-147230121738848 `"" && echo ansible-tmp-1662529320.9488437-25055-147230121738848=""` echo /root/.ansible/tmp/ansible-tmp-1662529320.9488437-25055-147230121738848 `"" ) && sleep 0'
Using module file /usr/local/lib/python3.8/dist-packages/ansible/modules/command.py
<127.0.0.1> PUT /root/.ansible/tmp/ansible-local-45627ll1rh74/tmp38tkcga4 TO /root/.ansible/tmp/ansible-tmp-1662529320.9488437-25055-147230121738848/AnsiballZ_command.py
<127.0.0.1> EXEC /bin/sh -c 'chmod u+x /root/.ansible/tmp/ansible-tmp-1662529320.9488437-25055-147230121738848/ /root/.ansible/tmp/ansible-tmp-1662529320.9488437-25055-147230121738848/AnsiballZ_command.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c '/usr/bin/python3 /root/.ansible/tmp/ansible-tmp-1662529320.9488437-25055-147230121738848/AnsiballZ_command.py && sleep 0'
<127.0.0.1> EXEC /bin/sh -c 'rm -f -r /root/.ansible/tmp/ansible-tmp-1662529320.9488437-25055-147230121738848/ > /dev/null 2>&1 && sleep 0'
fatal: [localhost]: FAILED! => {
    ""changed"": false,
    ""cmd"": ""pip3 list\n"",
    ""delta"": ""0:00:00.327450"",
    ""end"": ""2022-09-07 05:42:01.365631"",
    ""invocation"": {
        ""module_args"": {
            ""_raw_params"": ""pip3 list\n"",
            ""_uses_shell"": true,
            ""argv"": null,
            ""chdir"": null,
            ""creates"": null,
            ""executable"": null,
            ""removes"": null,
            ""stdin"": null,
            ""stdin_add_newline"": true,
            ""strip_empty_ends"": true,
            ""warn"": false
        }
    },
    ""msg"": ""non-zero return code"",
    ""rc"": 1,
    ""start"": ""2022-09-07 05:42:01.038181"",
    ""stderr"": ""Traceback (most recent call last):\n  File \""/usr/bin/pip3\"", line 11, in <module>\n    load_entry_point('pip==20.0.2', 'console_scripts', 'pip3')()\n  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 490, in load_entry_point\n    return get_distribution(dist).load_entry_point(group, name)\n  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2854, in load_entry_point\n    return ep.load()\n  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2445, in load\n    return self.resolve()\n  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2451, in resolve\n    module = __import__(self.module_name, fromlist=['__name__'], level=0)\n  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/main.py\"", line 10, in <module>\n    from pip._internal.cli.autocompletion import autocomplete\n  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/autocompletion.py\"", line 9, in <module>\n    from pip._internal.cli.main_parser import create_main_parser\n  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/main_parser.py\"", line 7, in <module>\n    from pip._internal.cli import cmdoptions\n  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/cmdoptions.py\"", line 24, in <module>\n    from pip._internal.exceptions import CommandError\n  File \""/usr/lib/python3/dist-packages/pip/_internal/exceptions.py\"", line 10, in <module>\n    from pip._vendor.six import iteritems\n  File \""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py\"", line 65, in <module>\n    vendored(\""cachecontrol\"")\n  File \""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py\"", line 36, in vendored\n    __import__(modulename, globals(), locals(), level=0)\n  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load\n  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked\n  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked\n  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible\n  File \""<frozen zipimport>\"", line 259, in load_module\n  File \""/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/__init__.py\"", line 9, in <module>\n  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load\n  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked\n  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked\n  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible\n  File \""<frozen zipimport>\"", line 259, in load_module\n  File \""/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/wrapper.py\"", line 1, in <module>\n  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load\n  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked\n  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked\n  File \
    ""stderr_lines"": [
        ""Traceback (most recent call last):"",
        ""  File \""/usr/bin/pip3\"", line 11, in <module>"",
        ""    load_entry_point('pip==20.0.2', 'console_scripts', 'pip3')()"",
        ""  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 490, in load_entry_point"",
        ""    return get_distribution(dist).load_entry_point(group, name)"",
        ""  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2854, in load_entry_point"",
        ""    return ep.load()"",
        ""  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2445, in load"",
        ""    return self.resolve()"",
        ""  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2451, in resolve"",
        ""    module = __import__(self.module_name, fromlist=['__name__'], level=0)"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/main.py\"", line 10, in <module>"",
        ""    from pip._internal.cli.autocompletion import autocomplete"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/autocompletion.py\"", line 9, in <module>"",
        ""    from pip._internal.cli.main_parser import create_main_parser"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/main_parser.py\"", line 7, in <module>"",
        ""    from pip._internal.cli import cmdoptions"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/cmdoptions.py\"", line 24, in <module>"",
        ""    from pip._internal.exceptions import CommandError"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/exceptions.py\"", line 10, in <module>"",
        ""    from pip._vendor.six import iteritems"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py\"", line 65, in <module>"",
        ""    vendored(\""cachecontrol\"")"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py\"", line 36, in vendored"",
        ""    __import__(modulename, globals(), locals(), level=0)"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/__init__.py\"", line 9, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/wrapper.py\"", line 1, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/adapter.py\"", line 5, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/requests-2.22.0-py2.py3-none-any.whl/requests/__init__.py\"", line 95, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/contrib/pyopenssl.py\"", line 46, in <module>"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/__init__.py\"", line 8, in <module>"",
        ""    from OpenSSL import crypto, SSL"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/crypto.py\"", line 1553, in <module>"",
        ""    class X509StoreFlags(object):"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/crypto.py\"", line 1573, in X509StoreFlags"",
        ""    CB_ISSUER_CHECK = _lib.X509_V_FLAG_CB_ISSUER_CHECK"",
        ""AttributeError: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'"",
        ""Error in sys.excepthook:"",
        ""Traceback (most recent call last):"",
        ""  File \""/usr/lib/python3/dist-packages/apport_python_hook.py\"", line 72, in apport_excepthook"",
        ""    from apport.fileutils import likely_packaged, get_recent_crashes"",
        ""  File \""/usr/lib/python3/dist-packages/apport/__init__.py\"", line 5, in <module>"",
        ""    from apport.report import Report"",
        ""  File \""/usr/lib/python3/dist-packages/apport/report.py\"", line 32, in <module>"",
        ""    import apport.fileutils"",
        ""  File \""/usr/lib/python3/dist-packages/apport/fileutils.py\"", line 12, in <module>"",
        ""    import os, glob, subprocess, os.path, time, pwd, sys, requests_unixsocket"",
        ""  File \""/usr/lib/python3/dist-packages/requests_unixsocket/__init__.py\"", line 1, in <module>"",
        ""    import requests"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/requests-2.22.0-py2.py3-none-any.whl/requests/__init__.py\"", line 95, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/contrib/pyopenssl.py\"", line 46, in <module>"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/__init__.py\"", line 8, in <module>"",
        ""    from OpenSSL import crypto, SSL"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/crypto.py\"", line 1553, in <module>"",
        ""    class X509StoreFlags(object):"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/crypto.py\"", line 1573, in X509StoreFlags"",
        ""    CB_ISSUER_CHECK = _lib.X509_V_FLAG_CB_ISSUER_CHECK"",
        ""AttributeError: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'"",
        """",
        ""Original exception was:"",
        ""Traceback (most recent call last):"",
        ""  File \""/usr/bin/pip3\"", line 11, in <module>"",
        ""    load_entry_point('pip==20.0.2', 'console_scripts', 'pip3')()"",
        ""  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 490, in load_entry_point"",
        ""    return get_distribution(dist).load_entry_point(group, name)"",
        ""  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2854, in load_entry_point"",
        ""    return ep.load()"",
        ""  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2445, in load"",
        ""    return self.resolve()"",
        ""  File \""/usr/lib/python3/dist-packages/pkg_resources/__init__.py\"", line 2451, in resolve"",
        ""    module = __import__(self.module_name, fromlist=['__name__'], level=0)"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/main.py\"", line 10, in <module>"",
        ""    from pip._internal.cli.autocompletion import autocomplete"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/autocompletion.py\"", line 9, in <module>"",
        ""    from pip._internal.cli.main_parser import create_main_parser"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/main_parser.py\"", line 7, in <module>"",
        ""    from pip._internal.cli import cmdoptions"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/cli/cmdoptions.py\"", line 24, in <module>"",
        ""    from pip._internal.exceptions import CommandError"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_internal/exceptions.py\"", line 10, in <module>"",
        ""    from pip._vendor.six import iteritems"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py\"", line 65, in <module>"",
        ""    vendored(\""cachecontrol\"")"",
        ""  File \""/usr/lib/python3/dist-packages/pip/_vendor/__init__.py\"", line 36, in vendored"",
        ""    __import__(modulename, globals(), locals(), level=0)"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/__init__.py\"", line 9, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/wrapper.py\"", line 1, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/CacheControl-0.12.6-py2.py3-none-any.whl/cachecontrol/adapter.py\"", line 5, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/requests-2.22.0-py2.py3-none-any.whl/requests/__init__.py\"", line 95, in <module>"",
        ""  File \""<frozen importlib._bootstrap>\"", line 991, in _find_and_load"",
        ""  File \""<frozen importlib._bootstrap>\"", line 975, in _find_and_load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 655, in _load_unlocked"",
        ""  File \""<frozen importlib._bootstrap>\"", line 618, in _load_backward_compatible"",
        ""  File \""<frozen zipimport>\"", line 259, in load_module"",
        ""  File \""/usr/share/python-wheels/urllib3-1.25.8-py2.py3-none-any.whl/urllib3/contrib/pyopenssl.py\"", line 46, in <module>"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/__init__.py\"", line 8, in <module>"",
        ""    from OpenSSL import crypto, SSL"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/crypto.py\"", line 1553, in <module>"",
        ""    class X509StoreFlags(object):"",
        ""  File \""/usr/lib/python3/dist-packages/OpenSSL/crypto.py\"", line 1573, in X509StoreFlags"",
        ""    CB_ISSUER_CHECK = _lib.X509_V_FLAG_CB_ISSUER_CHECK"",
        ""AttributeError: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'""
    ],
    ""stdout"": """",
    ""stdout_lines"": []
}

PLAY RECAP ********************************************************************************************************************************************************************************************************
localhost                  : ok=11   changed=6    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0

Failed.
```",kenji-miyake,12033.0,1009.0,4,1,0,2,9
fix(ansible/plotjuggler): fix workaround of pyOpenSSL,2022-09-07T06:38:45Z,1364075975,1238969958.0,comment,"`pip3 install ansible` in the container (root) is probably the problem.
https://github.com/autowarefoundation/autoware/issues/2849#issuecomment-1238964827
https://github.com/autowarefoundation/autoware/issues/2849#issuecomment-1238966584",kenji-miyake,12033.0,1009.0,4,1,0,2,9
fix(ansible/plotjuggler): fix workaround of pyOpenSSL,2022-09-07T07:36:57Z,1364075975,1239021645.0,comment,Summary: https://github.com/autowarefoundation/autoware/issues/2849#issuecomment-1239001602,kenji-miyake,12033.0,1009.0,4,1,0,2,9
"[ansible/plotjuggler] ""AttributeError: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'""",2022-09-07T05:17:53Z,1364034898,1238918103.0,comment,"https://hub.docker.com/_/ubuntu

Old

```
ubuntu                                                                                20.04                                                                         53df61775e88   4 months ago    72.8MB
```

New

```
ubuntu                                                                                20.04                                                                         a0ce5a295b63   5 days ago      72.8MB
```",kenji-miyake,16272.0,6882.0,4,0,0,0,0
"[ansible/plotjuggler] ""AttributeError: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'""",2022-09-07T06:31:55Z,1364034898,1238964827.0,comment,"minimal code to reproduce this problem:

```bash
docker run --rm -it ubuntu:20.04 /bin/bash
apt update && apt -y install python3-pip
pip3 install ansible
apt -y install python3-openssl
pip
```",kenji-miyake,16272.0,6882.0,4,0,0,0,0
"[ansible/plotjuggler] ""AttributeError: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'""",2022-09-07T06:34:06Z,1364034898,1238966584.0,comment,"This is okay, so some necessary files for ansible are overwritten by python3-openssl (which is installed by ROS).

```
docker run --rm -it ubuntu:20.04 /bin/bash
apt update && apt -y install python3-pip
apt -y install python3-openssl
pip3 install ansible
pip
```",kenji-miyake,16272.0,6882.0,4,0,0,0,0
"[ansible/plotjuggler] ""AttributeError: module 'lib' has no attribute 'X509_V_FLAG_CB_ISSUER_CHECK'""",2022-09-07T07:16:00Z,1364034898,1239001602.0,comment,"This was okay.

```
docker run --rm -it ubuntu:20.04 /bin/bash
apt update && apt -y install python3-pip
apt -y install python3-openssl
pip3 install ansible
apt -y purge python3-openssl
apt autoremove
apt -y install python3-openssl
pip
```

Considering the following result, the problem is:
- If `python3-openssl` is installed before Ansible, Ansible won't install `cryptography`.
- If `python3-openssl` isn't installed before Ansible, Ansible will install `cryptography`.
  - And if we install `python3-openssl` after that, the APT version of `cryptography` is newly installed and referenced from `pip`, which causes an error.

```console
$ docker run --rm -it ubuntu:20.04 /bin/bash
$ apt update && apt -y install python3-pip
$ apt -y install python3-openssl
$ pip3 install ansible
$ apt -y purge python3-openssl
$ apt autoremove
$ pip3 install ansible
Requirement already satisfied: ansible in /usr/local/lib/python3.8/dist-packages (6.3.0)
Requirement already satisfied: ansible-core~=2.13.3 in /usr/local/lib/python3.8/dist-packages (from ansible) (2.13.3)
Requirement already satisfied: jinja2>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from ansible-core~=2.13.3->ansible) (3.1.2)
Collecting cryptography
  Downloading cryptography-38.0.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)
     |████████████████████████████████| 4.1 MB 17.7 MB/s
Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.8/dist-packages (from ansible-core~=2.13.3->ansible) (6.0)
Requirement already satisfied: resolvelib<0.9.0,>=0.5.3 in /usr/local/lib/python3.8/dist-packages (from ansible-core~=2.13.3->ansible) (0.8.1)
Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from ansible-core~=2.13.3->ansible) (21.3)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2>=3.0.0->ansible-core~=2.13.3->ansible) (2.1.1)
Collecting cffi>=1.12
  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)
     |████████████████████████████████| 442 kB 141.7 MB/s
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->ansible-core~=2.13.3->ansible) (3.0.9)
Collecting pycparser
  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)
     |████████████████████████████████| 118 kB 141.8 MB/s
Installing collected packages: pycparser, cffi, cryptography
Successfully installed cffi-1.15.1 cryptography-38.0.0 pycparser-2.21
```",kenji-miyake,16272.0,6882.0,4,0,0,0,0
chore: update tool versions,2022-09-07T00:04:03Z,1363929414,,,,awf-autoware-bot[bot],,,0,1,0,2,4
Reduce docker image size for runtime usages,2022-09-10T01:56:28Z,1361360793,1242592960.0,comment,"With docker image built from nvidia/cuda:11.4.0-runtime-ubuntu20.04, and runtime dependencies installed for autoware, the disk usage of `/usr/local/cuda-11.4` folder could be reduced by 2.2GB.

Original:   `4.0G    /usr/local/cuda-11.4`
New:        `1.8G    /usr/local/cuda-11.4`

DNN related runtime dependencies:
- `libcudnn8`
- `libnvinfer8`
- `libnvinfer-plugin8`
- `libnvonnxparsers8`
- `libnvparsers8`",Sharrrrk,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2022-09-10T10:06:47Z,1361360793,1242691746.0,comment,"Currently I'm thinking of two approaches of this work:

- Reduce size of `prebuilt` image
  Considering the prebuilt images is for users to try out Autoware quickly, dev environment could be remove from it. 

- Keep current `prebuilt` image and build another `runtime` image
  This allows users to rebuild partial of Autoware, not the whole project using prebuilt image, then runtime image may be provided just for execution. 

The main concept of size reducing:
- Only use runtime libraries for CUDA/TensorRT (This could save ~2.2GB)
- Only copy the `install` folder or maybe also keep `src` folder (This could save up to ~3.3GB)

@kenji-miyake, what's your opinion about it ?",Sharrrrk,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2022-09-10T10:22:40Z,1361360793,1242695424.0,reply,"@Sharrrrk Thank you for investigating this issue!
I totally agree with you, and either option seems okay. The first option would be better as a first step because it's simpler.",kenji-miyake,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2022-09-11T21:32:03Z,1361360793,1243047241.0,reply,"@Sharrrrk thanks for taking this on!

For inspiration, you could take a look at the images layers which ROS and NVIDIA have used to create their Docker images. See
* https://github.com/osrf/docker_images/blob/3f4fbca923d80f834f3a89b5960bad5582652519/ros/galactic/ubuntu/focal/ros-core/Dockerfile
* https://hub.docker.com/layers/nvidia/cuda/11.4.2-runtime-ubuntu18.04/images/sha256-9fd4770341bd8f2cd754b70d552dfd0cc5e6e3ed1406449f00b1c5bb944133b0?context=explore

I'd recommend building up a new container and not removing from an existing one.",kaspermeck-arm,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2022-09-14T13:43:05Z,1361360793,1246785972.0,comment,"Hi @kasperornmeck, I looked into the docker file of Nvidia and ROS, Nvidia used a script from outside to install all the packages, and for ROS, it's just like what have been implented in current ansible script. So I would say that use nvidia runtime docker image as base would be a good and neat approach. I will modify the ansible srcipts (add a variant that only installs runtime dependencies) and the Docker file (use mutlti stage build) of course, so that the `prebuilt` image could reduce it's size in later build. ",Sharrrrk,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2022-09-15T03:03:47Z,1361360793,1247522393.0,comment,"Hi @kasperornmeck, I looked into the docker file of Nvidia and ROS, Nvidia used a script from outside to install all the packages, and for ROS, it's just like what have been implented in current ansible script. So I would say that use nvidia runtime docker image as base would be a good and neat approach. I will modify the ansible srcipts (add a variant that only installs runtime dependencies) and the Docker file (use mutlti stage build) of course, so that the `prebuilt` image could reduce it's size in later build. ",Sharrrrk,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2022-09-19T15:09:41Z,1361360793,1251157068.0,reply,"Hi @Sharrrrk 
I was installing the NVIDIA driver using the runfile (local) method. You might already be aware of this but you can install only the driver, or any of the other software by selecting/deselecting, e.g., all the runtime dependencies.

```
lqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqk
x CUDA Installer                                                               x
x - [X] Driver                                                                 x
x      [X] 515.65.01                                                           x
x - [ ] CUDA Toolkit 11.7                                                      x
x    - [ ] CUDA Libraries 11.7                                                 x
x       + [ ] CUDA Development 11.7                                            x
x       - [ ] CUDA Runtime 11.7                                                x
x            [ ] cuda-cudart                                                   x
x            [ ] cuda-nvrtc                                                    x
x            [ ] libcublas11                                                   x
x            [ ] libcufft                                                      x
x            [ ] libcurand                                                     x
x            [ ] libcusolver                                                   x
x            [ ] libcusparse                                                   x
x            [ ] libnpp                                                        x
x            [ ] libnvjpeg                                                     x
x    - [ ] CUDA Tools 11.7                                                     x
x       + [ ] CUDA Command Line Tools 11.7                                     x
x       + [ ] CUDA Visual Tools 11.7                                           x
x    - [ ] CUDA Compiler 11.7                                                  x
x         [ ] cuda-cuobjdump                                                   x
x                                                                              x
x Up/Down: Move | Left/Right: Expand | 'Enter': Select | 'A': Advanced options x
```
",kaspermeck-arm,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2022-09-20T07:57:10Z,1361360793,1251981318.0,comment,"Hi @kasperornmeck  thanks for the information, I will compare the docker size between manually install and cuda-runtime.",Sharrrrk,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2022-09-20T07:58:07Z,1361360793,1251982250.0,comment,"Currently I have started to change Dockerfile and ansible scripts, the main ideas:
-  Use cuda runtime images as base
-  Only runtime packages of TensorRT are installed
-  Only minimal set of ROS packages are installed
-  Multistage image build, copy install folder",Sharrrrk,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2023-01-18T13:11:36Z,1361360793,1387051734.0,reply,"@Sharrrrk have you created a PR for these changes? If so, please link it to the Issue. ",BonoloAWF,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2023-04-28T13:42:52Z,1361360793,1527584774.0,reply,"I've created this discussion on re-layering of the dockerfile/image:

https://github.com/orgs/autowarefoundation/discussions/3469",xmfcx,,427421.0,12,0,0,0,0
Reduce docker image size for runtime usages,2023-07-06T13:47:08Z,1361360793,1623712796.0,reply,Merge this issue with https://github.com/autowarefoundation/autoware.universe/issues/4111.,kaspermeck-arm,,427421.0,12,0,0,0,0
docs(ansible/pre_commit): remove adding golang repository for humble,2022-09-02T17:39:00Z,1360458699,,,,xmfcx,,,0,1,0,1,2
ci: add cancel-previous-workflows.yaml,2022-09-02T00:53:28Z,1359581031,,,,kenji-miyake,,,0,1,0,1,14
feat(ansible/tensorrt): add allow_change_held_packages option,2022-09-01T06:27:20Z,1358319228,1233802690.0,comment,"My test results:

[Installed version]

```
cuda_version=11.6
cudnn_version=8.4.1.50-1+cuda11.6
tensorrt_version=8.4.2-1+cuda11.6
```

[Installing version]

```
cuda_version=11.4
cudnn_version=8.2.4.15-1+cuda11.4
tensorrt_version=8.2.4-1+cuda11.4
```

[Without this PR]

```
TASK [autoware.dev_env.tensorrt : Install cuDNN and TensorRT] ****************************************************************************************************
fatal: [localhost]: FAILED! => {""cache_update_time"": 1662012785, ""cache_updated"": true, ""changed"": false, ""msg"": ""'/usr/bin/apt-get -y -o \""Dpkg::Options::=--force-confdef\"" -o \""Dpkg::Options::=--force-confold\""       install 'libcudnn8=8.2.4.15-1+cuda11.4' 'libcudnn8-dev=8.2.4.15-1+cuda11.4' 'libnvinfer8=8.2.4-1+cuda11.4' 'libnvinfer-plugin8=8.2.4-1+cuda11.4' 'libnvparsers8=8.2.4-1+cuda11.4' 'libnvonnxparsers8=8.2.4-1+cuda11.4' 'libnvinfer-dev=8.2.4-1+cuda11.4' 'libnvinfer-plugin-dev=8.2.4-1+cuda11.4' 'libnvparsers-dev=8.2.4-1+cuda11.4' 'libnvonnxparsers-dev=8.2.4-1+cuda11.4' --allow-downgrades' failed: E: Held packages were changed and -y was used without --allow-change-held-packages.\n"", ""rc"": 100, ""stderr"": ""E: Held packages were changed and -y was used without --allow-change-held-packages.\n"", ""stderr_lines"": [""E: Held packages were changed and -y was used without --allow-change-held-packages.""], ""stdout"": ""Reading package lists...\nBuilding dependency tree...\nReading state information...\nThe following held packages will be changed:\n  libcudnn8 libcudnn8-dev libnvinfer-dev libnvinfer-plugin-dev\n  libnvinfer-plugin8 libnvinfer8 libnvonnxparsers-dev libnvonnxparsers8\n  libnvparsers-dev libnvparsers8\nThe following packages will be DOWNGRADED:\n  libcudnn8 libcudnn8-dev libnvinfer-dev libnvinfer-plugin-dev\n  libnvinfer-plugin8 libnvinfer8 libnvonnxparsers-dev libnvonnxparsers8\n  libnvparsers-dev libnvparsers8\n0 upgraded, 0 newly installed, 10 downgraded, 0 to remove and 25 not upgraded.\n"", ""stdout_lines"": [""Reading package lists..."", ""Building dependency tree..."", ""Reading state information..."", ""The following held packages will be changed:"", ""  libcudnn8 libcudnn8-dev libnvinfer-dev libnvinfer-plugin-dev"", ""  libnvinfer-plugin8 libnvinfer8 libnvonnxparsers-dev libnvonnxparsers8"", ""  libnvparsers-dev libnvparsers8"", ""The following packages will be DOWNGRADED:"", ""  libcudnn8 libcudnn8-dev libnvinfer-dev libnvinfer-plugin-dev"", ""  libnvinfer-plugin8 libnvinfer8 libnvonnxparsers-dev libnvonnxparsers8"", ""  libnvparsers-dev libnvparsers8"", ""0 upgraded, 0 newly installed, 10 downgraded, 0 to remove and 25 not upgraded.""]}

PLAY RECAP *******************************************************************************************************************************************************
localhost                  : ok=46   changed=0    unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   

Failed.
```

[With this PR]

```
TASK [autoware.dev_env.tensorrt : Install cuDNN and TensorRT] ****************************************************************************************************
changed: [localhost]

TASK [autoware.dev_env.tensorrt : Prevent CUDA-related packages from upgrading] **********************************************************************************
changed: [localhost] => (item=libcudnn8)
changed: [localhost] => (item=libcudnn8-dev)
changed: [localhost] => (item=libnvinfer8)
changed: [localhost] => (item=libnvinfer-plugin8)
changed: [localhost] => (item=libnvparsers8)
changed: [localhost] => (item=libnvonnxparsers8)
changed: [localhost] => (item=libnvinfer-dev)
changed: [localhost] => (item=libnvinfer-plugin-dev)
changed: [localhost] => (item=libnvparsers-dev)
changed: [localhost] => (item=libnvonnxparsers-dev)

PLAY RECAP *******************************************************************************************************************************************************
localhost                  : ok=48   changed=2    unreachable=0    failed=0    skipped=3    rescued=0    ignored=0   

Completed.
```",kenji-miyake,2321.0,103.0,1,1,0,1,1
chore(ansible): upgrade version from 5 to 6,2022-09-01T05:27:21Z,1358271206,1233758216.0,comment,Build CI: https://github.com/autowarefoundation/autoware/runs/8128283921?check_suite_focus=true,kenji-miyake,4134.0,50.0,1,1,0,1,4
chore(.clang-tidy): apply yamllint,2022-08-29T10:38:16Z,1354075254,,,,kenji-miyake,,,0,1,0,2,44
chore(.clang-tidy): fix settings of readability-identifier-naming,2022-08-29T09:16:30Z,1353935562,1230000720.0,reply,"> Use lower_case for ConstexprVariableCase.

For message type, the rosidl disallows the use of constant names other than `UPPER_CASE`. Can this pass the check? And the google guideline says to use `kConstatntName`. So is this Autoware's own rule?",isamu-takagi,80925.0,1221.0,2,1,0,1,10
chore(.clang-tidy): fix settings of readability-identifier-naming,2022-08-29T10:16:04Z,1353935562,1230086046.0,comment,"> For message type, the rosidl disallows the use of constant names other than UPPER_CASE. Can this pass the check?

I've confirmed this behavior. `clang-tidy` didn't raise warnings unless we intentionally add `-system-headers` and `-header-fileter=.*`.
Since it only affects to user code, I think it's acceptable.

> And the google guideline says to use kConstatntName. So is this Autoware's own rule?

Yes. I personally think it's acceptable considering one of the rationales `consistency across languages` in ROS 2 Docs.

As you write [here](https://github.com/autowarefoundation/autoware.universe/blob/3cae6eca45b36b75c696780e67aabaee05330629/common/autoware_ad_api_specs/include/autoware_ad_api_specs/routing.hpp#L50-L53), it is natural that we use lower_case for `constexpr` variables.

@isamu-takagi What do you think?",kenji-miyake,80925.0,1221.0,2,1,0,1,10
Autoware.Universe Docker Installation Procedures are wrong,2022-08-28T22:35:00Z,1353476435,1229568395.0,reply,"Thank you for opening this issue.
I found 2 different instruction pages about running Autoware with Docker:
- Documentation repository: https://github.com/autowarefoundation/autoware-documentation/blob/main/docs/installation/autoware/docker-installation.md
- Autoware repository: https://github.com/autowarefoundation/autoware/blob/main/docker/README.md

~Your issue seems to be that the instructions on the Autoware repository are wrong~. Is my understanding correct ? **EDIT: both instructions page are apparently wrong**

To avoid future confusion, I propose to only maintain one page of documentation on the Documentation repository.
The one on the Autoware repository can then be deleted or modified to simply link to the page on the Documentation repository.",maxime-clem,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-08-29T13:23:35Z,1353476435,1230300999.0,comment,"Hi Max,

Both of these documentations are wrong. They have the wrong option for rocker and the wrong Autoware docker image.

The part to verify that docker is installed correctly is also wrong because NVIDIA changed their wording recently.

Yes, I think there should only be 1 installation documentation to avoid confusion.",Croquembouche,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-08-31T03:10:16Z,1353476435,1232404409.0,reply,"Can you please post more details about the issues you had and how you fixed them ?

The images were recently updated and now need to be suffixed with `-cuda` (you can find the list of images here: https://github.com/autowarefoundation/autoware/pkgs/container/autoware-universe/versions?filters%5Bversion_type%5D=tagged). Could it have been the cause of some of your issues ?

Once you share more details I will try to reproduce the issues.",maxime-clem,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-09-05T10:04:25Z,1353476435,1236797926.0,reply,"Hi @maxime-clem @Croquembouche , 

could you finally find a way to correctly install Autoware?

Thanks",msanchezvicom,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-09-05T10:58:18Z,1353476435,1236848179.0,reply,"I followed the instructions from https://github.com/autowarefoundation/autoware-documentation/blob/main/docs/installation/autoware/docker-installation.md with a fresh clone. I installed the dependencies using Ansible and ran in a amd64 architecture with a NVIDIA GPU.

I had no issue until building Autoware where I had the following error caused by missing dependencies:
```
--- stderr: tier4_pcl_extensions                                                  
In file included from /home/mclement/autoware/test_docker/src/universe/autoware.universe/sensing/tier4_pcl_extensions/src/voxel_grid_nearest_centroid.cpp:52:
/home/mclement/autoware/test_docker/src/universe/autoware.universe/sensing/tier4_pcl_extensions/include/tier4_pcl_extensions/voxel_grid_nearest_centroid_impl.hpp:66:10: fatal error: range/v3/all.hpp: No such file or directory
   66 | #include <range/v3/all.hpp>
      |          ^~~~~~~~~~~~~~~~~~
```
I installed the missing dependencies using the following commands.
```
sudo apt update
source /opt/ros/galactic/setup.bash
rosdep update
rosdep install --from-paths . --ignore-src --rosdistro $ROS_DISTRO
```
After that I could build without error and could run Autoware without any problem.

@Croquembouche please share more details about the issues you encountered.
It is possible that there are issues when installing dependencies without Ansible, when running without NVIDIA GPU, or when using an arm64 architecture.

For now I will open a PR to add the commands needed to install missing dependencies.",maxime-clem,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-09-06T23:46:20Z,1353476435,1238756260.0,comment,"Hi,

Sorry for the late response. I tried the same instructions. But updating dependencies gave me ""invalid-cross device id"" when installing nvidia, cuda, and tensorrt. Manual install also resulted in this error.

The reason I discovered was that rocker's --cuda option is not available for 0.2.10 version.

I'll upload the instructions that worked for me tomorrow when I get to the lab.

Best,
William",Croquembouche,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-09-07T00:35:27Z,1353476435,1238780269.0,reply,"You are right `rocker` does not support option `--cuda` but I am also using version `0.2.10` and I did not have issue.
I cannot find any use of the option `--cuda` in the commands listed in the instructions but maybe it was recently changed.
I am not sure what the `invalid-cross device id` could be. I will wait for more details.",maxime-clem,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-09-07T17:02:00Z,1353476435,1239653968.0,comment,"> You are right `rocker` does not support option `--cuda` but I am also using version `0.2.10` and I did not have issue. I cannot find any use of the option `--cuda` in the commands listed in the instructions but maybe it was recently changed. I am not sure what the `invalid-cross device id` could be. I will wait for more details.

Hi,

The invalid cross device id comes when you update the nvidia drivers within the docker. Because rocker uses the gpu data from the host pc, and the autoware docker uses cuda 10.1 (latest cuda version is 11.7) and needs to be updated, the installer will try to update the driver on the host pc, resulting in invalid cross device id. 

This issue has been solved in another issue. 

I'll attach the docker image that worked for me and the steps. 

",Croquembouche,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-09-07T17:06:43Z,1353476435,1239658242.0,comment,"Steps to use Autoware.Universe in Docker(Rocker):

1. Use this image ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda. This image includes cuda 11.6, TensorRT, and CudaDNN.
2. start rocker using this command, ""rocker --nvidia --x11 --user --env NVIDIA_DRIVER_CAPABILITIES="""" -- ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda"". This will allow the host gpu to be used in the docker.
3. You need at least 64GB free RAM to colcon build the project. Having less free memory might result in random CPP error. ""colcon build"" will throw error and terminate the build if the pc runs out of memory. The ""Add SWAP memory"" section in the documentation can be used to solve this issue.
",Croquembouche,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-09-07T17:08:10Z,1353476435,1239659599.0,comment,"I tried installing the dependencies with ANSIBLE. With the current listed docker image, I still receive an invalid cross device id when it tries to install/update cuda and the relevant nvidia drivers.",Croquembouche,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-09-09T09:29:52Z,1353476435,1241735639.0,reply,"After some offline discussion, I was able to better understand the issue.
- Installation of the **CUDA drivers on the host machine is missing** from the Docker installation instructions and from the Ansible playbook.

Currently, if someone starts from a fresh install of Ubuntu 20.04 and simply follows the Docker installation instruction, the CUDA drivers will be missing.
This can be solved by installing all dependencies (`./setup-dev-env.sh`) but it would be better if this was included in the Docker dependencies (`./setup-dev-env.sh docker`).",maxime-clem,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-10-04T15:35:44Z,1353476435,1267194116.0,reply,"Hi,
I install autoware via rocker following the instructions from [https://github.com/autowarefoundation/autoware-documentation/blob/main/docs/installation/autoware/docker-installation.md]. When I `colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release` </br> I meet a problem </br> 
```
--- stderr: trtexec_vendor
CMake Error at CMakeLists.txt:15 (find_package):
  By not providing ""Findcudnn_cmake_module.cmake"" in CMAKE_MODULE_PATH this
  project has asked CMake to find a package configuration file provided by
  ""cudnn_cmake_module"", but CMake did not find one.

  Could not find a package configuration file provided by
  ""cudnn_cmake_module"" with any of the following names:

    cudnn_cmake_moduleConfig.cmake
    cudnn_cmake_module-config.cmake
```
what should i do to fix this problem? </br>
I find the cudnn and tensorrt files (.h .so) in the docker container.",jfkkf123,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-10-04T16:30:56Z,1353476435,1267264752.0,reply,"If you followed the instructions I am not sure what could be the issue.
- Do you run `colcon build` _inside_ the Docker container ?
- Did you install the dependencies with `./setup-dev-env.sh` on the _host_ (not inside the Docker container) ?
- Are you using a AMD64 architecture with a NVIDIA GPU ?",maxime-clem,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-10-06T04:23:32Z,1353476435,1269291710.0,reply,"> what should i do to fix this problem? I find the cudnn and tensorrt files (.h .so) in the docker container.

This error is probably caused by the following missing package: `ros-galactic-tensorrt-cmake-module`.
Missing packages can be installed with the following command:
```console
rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO
```",maxime-clem,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-10-07T14:26:48Z,1353476435,1271669371.0,reply,"> > what should i do to fix this problem? I find the cudnn and tensorrt files (.h .so) in the docker container.
> 
> This error is probably caused by the following missing package: `ros-galactic-tensorrt-cmake-module`. Missing packages can be installed with the following command:
> 
> ```
> rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO
> ```

I update the docker image autoware-universe:latest-cuda and dependent ROS packages. Now everything is OK. Thank you.",jfkkf123,8675516.0,3316.0,16,0,0,0,0
Autoware.Universe Docker Installation Procedures are wrong,2022-12-07T07:31:40Z,1353476435,1340515959.0,reply,"The documentation and the ansible script have been updated.
I followed the Docker installation instructions from a fresh Ubuntu 22.04 install and had no issue.",maxime-clem,8675516.0,3316.0,16,0,0,0,0
sending output via udp,2022-09-15T07:45:49Z,1352134191,1247710216.0,reply,"As mentioned in the [support guideline](https://autowarefoundation.github.io/autoware-documentation/main/support/support-guidelines/#github-issues), we are using Github issue as a place to track bugs and tasks. If you have question, GitHub Discussions is a better place. 
https://github.com/autowarefoundation/autoware/discussions/categories/q-a

As a short answer to your question, if you want to see the LiDAR data, ROS2 natively supports communication between multiple machines by setting the same [ROS_DOMAIN_ID](https://docs.ros.org/en/foxy/Concepts/About-Domain-ID.html)",mitsudome-r,4477083.0,1714971.0,3,0,0,0,0
sending output via udp,2022-09-15T12:18:56Z,1352134191,1248025018.0,comment,"I opened it the same day I posted this issue!
https://github.com/autowarefoundation/autoware/discussions/2818

could that happned with ROS1?",urbansound8K,4477083.0,1714971.0,3,0,0,0,0
sending output via udp,2022-09-20T16:27:57Z,1352134191,1252601994.0,reply,Checkout http://wiki.ros.org/ROS/Tutorials/MultipleMachines,mitsudome-r,4477083.0,1714971.0,3,0,0,0,0
fix: remove bin and samples to keep backward compatibility,2022-08-19T07:52:11Z,1344080343,,,,wep21,,,0,1,0,1,4
ci(build): enable daily build,2022-08-18T07:03:56Z,1342649743,,,,kenji-miyake,,,0,1,0,4,8
ci(setup-universe): remove --no-nvidia,2022-08-18T06:57:10Z,1342640171,1219107460.0,comment,I guess CI will fail because https://github.com/autowarefoundation/autoware/pull/2807 isn't merged yet. I'll wait for that.,kenji-miyake,2270.0,207.0,3,1,0,1,2
ci(setup-universe): remove --no-nvidia,2022-08-18T07:27:53Z,1342640171,1219131199.0,comment,"Failed as expected.
https://github.com/autowarefoundation/autoware/runs/7893336027?check_suite_focus=true#step:4:17160",kenji-miyake,2270.0,207.0,3,1,0,1,2
ci(setup-universe): remove --no-nvidia,2022-08-18T07:31:29Z,1342640171,1219134383.0,comment,I'll merge this and test #2807.,kenji-miyake,2270.0,207.0,3,1,0,1,2
revert: install each package of tensorrt,2022-08-18T05:46:04Z,1342562459,1219062734.0,reply,"Memo: How to test this. cc @xmfcx 

## Set up CUDA

```bash
docker run --rm -it ubuntu:22.04 # Please use 20.04 if you test Galactic

# only humble
echo ""deb http://archive.ubuntu.com/ubuntu focal main restricted"" > /etc/apt/sources.list.d/focal.list

apt update && apt -y install curl wget
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
dpkg -i cuda-keyring_1.0-1_all.deb
apt update
DEBIAN_FRONTEND=noninteractive apt -y install cuda-11-6
```

## Optional steps to save the intermediate image

```console
$ docker ps
$ docker commit 1a7d8855713d # Please use your own hash
sha256:b10bc67c457927004bf200344651675aee3e2260c69ff0101ca8098495f2c13e
```

## Test apt install

```console
$ docker run --rm -it b10bc67c457927004bf200344651675aee3e2260c69ff0101ca8098495f2c13e

$ apt depends tensorrt=8.4.2.4-1+cuda11.6
tensorrt
  Depends: libnvinfer8 (= 8.4.2-1+cuda11.6)
  Depends: libnvinfer-plugin8 (= 8.4.2-1+cuda11.6)
  Depends: libnvparsers8 (= 8.4.2-1+cuda11.6)
  Depends: libnvonnxparsers8 (= 8.4.2-1+cuda11.6)
  Depends: libnvinfer-bin (= 8.4.2-1+cuda11.6)
  Depends: libnvinfer-dev (= 8.4.2-1+cuda11.6)
  Depends: libnvinfer-plugin-dev (= 8.4.2-1+cuda11.6)
  Depends: libnvparsers-dev (= 8.4.2-1+cuda11.6)
  Depends: libnvonnxparsers-dev (= 8.4.2-1+cuda11.6)
  Depends: libnvinfer-samples (= 8.4.2-1+cuda11.6)

$ apt install tensorrt=8.4.2.4-1+cuda11.6                                                                                                                                                       Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
Some packages could not be installed. This may mean that you have
requested an impossible situation or if you are using the unstable
distribution that some required packages have not yet been created
or been moved out of Incoming.
The following information may help to resolve the situation:

The following packages have unmet dependencies:
 tensorrt : Depends: libnvinfer8 (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvinfer-plugin8 (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvparsers8 (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvonnxparsers8 (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvinfer-bin (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvinfer-dev (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvinfer-plugin-dev (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvparsers-dev (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvonnxparsers-dev (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
            Depends: libnvinfer-samples (= 8.4.2-1+cuda11.6) but 8.4.3-1+cuda11.6 is to be installed
E: Unable to correct problems, you have held broken packages.

$ apt install libnvinfer8=8.4.2-1+cuda11.6 libnvinfer-plugin8=8.4.2-1+cuda11.6 libnvparsers8=8.4.2-1+cuda11.6 libnvonnxparsers8=8.4.2-1+cuda11.6 libnvinfer-bin=8.4.2-1+cuda11.6 libnvinfer-dev=8.4.2-1+cuda11.6 libnvinfer-plugin-dev=8.4.2-1+cuda11.6 libnvparsers-dev=8.4.2-1+cuda11.6 libnvonnxparsers-dev=8.4.2-1+cuda11.6 libnvinfer-samples=8.4.2-1+cuda11.6
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following additional packages will be installed:
  libcudnn8 libcudnn8-dev
The following NEW packages will be installed:
  libcudnn8 libcudnn8-dev libnvinfer-bin libnvinfer-dev libnvinfer-plugin-dev libnvinfer-plugin8 libnvinfer-samples libnvinfer8 libnvonnxparsers-dev libnvonnxparsers8 libnvparsers-dev libnvparsers8
0 upgraded, 12 newly installed, 0 to remove and 12 not upgraded.
Need to get 1525 MB of archives.
After this operation, 3854 MB of additional disk space will be used.
Do you want to continue? [Y/n]
```

Related links:
- https://itsfoss.com/apt-install-specific-version/
- https://askubuntu.com/questions/1343938/how-to-install-a-specific-version-of-a-metapackage-and-its-dependencies
- https://askubuntu.com/questions/154044/installing-particular-versions-when-repo-has-newer-versions",kenji-miyake,10228.0,2761.0,1,4,0,2,24
ci(docker-build-and-push): use tentative if-condition for scheduled events,2022-08-16T08:12:25Z,1339978624,,,,kenji-miyake,,,0,1,0,1,3
Installation of ros-humble-desktop fails,2022-08-16T05:32:59Z,1339835013,1216167708.0,comment,"I'll wait for tomorrow's sync.
https://discourse.ros.org/t/preparing-for-humble-sync-2022-08-17/26882",kenji-miyake,71182.0,121.0,2,0,0,0,0
Installation of ros-humble-desktop fails,2022-08-17T01:17:20Z,1339835013,1217347263.0,comment,I think it's resolved now.,kenji-miyake,71182.0,121.0,2,0,0,0,0
Docker images aren't pushed from scheduled jobs,2022-08-16T07:36:32Z,1339822752,1216259800.0,comment,"`github.event.repository.default_branch` is missing in scheduled events.
https://github.com/kenji-miyake/test-scheduled-event/runs/7852886603?check_suite_focus=true#step:2:1
https://github.com/kenji-miyake/test-scheduled-event/blob/24a7d885dade873eeea05bb8cc6e483e3389c0f7/.github/workflows/test.yaml#L13",kenji-miyake,15048.0,8584.0,3,0,0,0,0
Docker images aren't pushed from scheduled jobs,2022-08-16T07:49:47Z,1339822752,1216272465.0,comment,"Maybe this? https://github.com/community/community/discussions/12269
-> Seems resolved: https://github.blog/changelog/2022-09-27-github-actions-additional-information-available-in-github-event-payload-for-scheduled-workflow-runs/",kenji-miyake,15048.0,8584.0,3,0,0,0,0
Docker images aren't pushed from scheduled jobs,2022-08-16T08:08:23Z,1339822752,1216290132.0,comment,"Tentative if-condition: https://github.com/kenji-miyake/test-scheduled-event/blob/5cb9ce073e7f781c600baa425a8bc87e6002658b/.github/workflows/test.yaml#L20

Test results:
- workflow_dispatch: https://github.com/kenji-miyake/test-scheduled-event/runs/7853325421?check_suite_focus=true
- schedule: https://github.com/kenji-miyake/test-scheduled-event/runs/7853359987?check_suite_focus=true",kenji-miyake,15048.0,8584.0,3,0,0,0,0
chore(clang-tidy): add SharedFuture in performance-unnecessary-value-param.AllowedTypes,2022-08-15T09:40:58Z,1338761641,1214825980.0,reply,"Since it's not a feature of this repository, please let me use `chore`. :bow: ",kenji-miyake,1306.0,241.0,1,2,0,1,2
chore(.clang-tidy): set readability-inconsistent-declaration-parameter-name.IgnoreMacros to true,2022-08-02T14:41:06Z,1325962052,,,,kenji-miyake,,,0,1,0,1,2
feat: update cuda version,2022-08-03T01:25:09Z,1325490278,1203378875.0,reply,"There aren't any concerns, but cloud you give us time to check to be sure?",yukke42,702476.0,60333.0,8,5,0,3,27
feat: update cuda version,2022-08-03T09:40:22Z,1325490278,1203720547.0,reply,"I failed to build the docker image with cuda. Ansible task `autoware.dev_env.tensorrt` isn't found in [CI](https://github.com/autowarefoundation/autoware/runs/7628275557?check_suite_focus=true). 

command:
```
./docker/build.sh --platform linux/amd64
```

error log:
```
#17 1324.2 TASK [autoware.dev_env.tensorrt : Install cuDNN and TensorRT] ******************
#17 1328.7 fatal: [localhost]: FAILED! => {""cache_update_time"": 1659513313, ""cache_updated"": false, ""changed"": false, ""msg"": ""'/usr/bin/apt-get -y -o \""Dpkg::Options::=--force-confdef\"" -o \""Dpkg::Options::=--force-confold\""       install 'libcudnn8=8.4.1.50-1+cuda11.6' 'libcudnn8-dev=8.4.1.50-1+cuda11.6' 'tensorrt=8.4.1.5-1+cuda11.6' --allow-downgrades' failed: E: Unable to correct problems, you have held broken packages.\n"", ""rc"": 100, ""stderr"": ""E: Unable to correct problems, you have held broken packages.\n"", ""stderr_lines"": [""E: Unable to correct problems, you have held broken packages.""], ""stdout"": ""Reading package lists...\nBuilding dependency tree...\nReading state information...\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n tensorrt : Depends: libnvinfer8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-plugin8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvparsers8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvonnxparsers8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-bin (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-plugin-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvparsers-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvonnxparsers-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-samples (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n"", ""stdout_lines"": [""Reading package lists..."", ""Building dependency tree..."", ""Reading state information..."", ""Some packages could not be installed. This may mean that you have"", ""requested an impossible situation or if you are using the unstable"", ""distribution that some required packages have not yet been created"", ""or been moved out of Incoming."", ""The following information may help to resolve the situation:"", """", ""The following packages have unmet dependencies:"", "" tensorrt : Depends: libnvinfer8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-plugin8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvparsers8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvonnxparsers8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-bin (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-plugin-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvparsers-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvonnxparsers-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-samples (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed""]}
#17 1328.7 
#17 1328.7 PLAY RECAP *********************************************************************
#17 1328.7 localhost                  : ok=43   changed=26   unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
#17 1328.7 
#17 1328.7 Failed.
#17 ERROR: executor failed running [/bin/bash -o pipefail -c ./setup-dev-env.sh -y $SETUP_ARGS universe   && pip uninstall -y ansible ansible-core   && mkdir src   && vcs import src < autoware.repos   && rosdep update   && DEBIAN_FRONTEND=noninteractive rosdep install -y --ignore-src --from-paths src --rosdistro ""$ROS_DISTRO""   && apt-get clean   && rm -rf /var/lib/apt/lists/*]: exit code: 1
------
 > [prebuilt devel  8/14] RUN --mount=type=ssh   ./setup-dev-env.sh -y --no-cuda-drivers universe   && pip uninstall -y ansible ansible-core   && mkdir src   && vcs import src < autoware.repos   && rosdep update   && DEBIAN_FRONTEND=noninteractive rosdep install -y --ignore-src --from-paths src --rosdistro ""galactic""   && apt-get clean   && rm -rf /var/lib/apt/lists/*:
#17 1324.1 TASK [autoware.dev_env.cuda : Add LD_LIBRARY_PATH to bashrc] *******************
#17 1324.2 ok: [localhost]
#17 1324.2 
#17 1324.2 TASK [autoware.dev_env.tensorrt : Install cuDNN and TensorRT] ******************
#17 1328.7 fatal: [localhost]: FAILED! => {""cache_update_time"": 1659513313, ""cache_updated"": false, ""changed"": false, ""msg"": ""'/usr/bin/apt-get -y -o \""Dpkg::Options::=--force-confdef\"" -o \""Dpkg::Options::=--force-confold\""       install 'libcudnn8=8.4.1.50-1+cuda11.6' 'libcudnn8-dev=8.4.1.50-1+cuda11.6' 'tensorrt=8.4.1.5-1+cuda11.6' --allow-downgrades' failed: E: Unable to correct problems, you have held broken packages.\n"", ""rc"": 100, ""stderr"": ""E: Unable to correct problems, you have held broken packages.\n"", ""stderr_lines"": [""E: Unable to correct problems, you have held broken packages.""], ""stdout"": ""Reading package lists...\nBuilding dependency tree...\nReading state information...\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\n\nThe following packages have unmet dependencies:\n tensorrt : Depends: libnvinfer8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-plugin8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvparsers8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvonnxparsers8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-bin (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-plugin-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvparsers-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvonnxparsers-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n            Depends: libnvinfer-samples (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed\n"", ""stdout_lines"": [""Reading package lists..."", ""Building dependency tree..."", ""Reading state information..."", ""Some packages could not be installed. This may mean that you have"", ""requested an impossible situation or if you are using the unstable"", ""distribution that some required packages have not yet been created"", ""or been moved out of Incoming."", ""The following information may help to resolve the situation:"", """", ""The following packages have unmet dependencies:"", "" tensorrt : Depends: libnvinfer8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-plugin8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvparsers8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvonnxparsers8 (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-bin (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-plugin-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvparsers-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvonnxparsers-dev (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed"", ""            Depends: libnvinfer-samples (= 8.4.1-1+cuda11.6) but 8.4.2-1+cuda11.6 is to be installed""]}
#17 1328.7 
#17 1328.7 PLAY RECAP *********************************************************************
#17 1328.7 localhost                  : ok=43   changed=26   unreachable=0    failed=1    skipped=3    rescued=0    ignored=0   
#17 1328.7 
#17 1328.7 Failed.
------
```

",yukke42,702476.0,60333.0,8,5,0,3,27
feat: update cuda version,2022-08-03T09:50:17Z,1325490278,1203730525.0,reply,"@yukke42 Have you tried `apt-mark unhold`?
https://autowarefoundation.github.io/autoware-documentation/main/support/troubleshooting/#setup-issues",kenji-miyake,702476.0,60333.0,8,5,0,3,27
feat: update cuda version,2022-08-03T10:01:31Z,1325490278,1203741845.0,reply,"> @yukke42 Have you tried `apt-mark unhold`? https://autowarefoundation.github.io/autoware-documentation/main/support/troubleshooting/#setup-issues

@kenji-miyake Does it need to build docker images? I just follow [this instruction](https://github.com/autowarefoundation/autoware/tree/update-cuda-version/docker#building-docker-images-on-your-local-machine).",yukke42,702476.0,60333.0,8,5,0,3,27
feat: update cuda version,2022-08-03T10:03:00Z,1325490278,1203743343.0,reply,Hmm? I'm sorry I misunderstood. I'll try to reproduce the problem.,kenji-miyake,702476.0,60333.0,8,5,0,3,27
feat: update cuda version,2022-08-03T10:04:46Z,1325490278,1203745116.0,reply,"CI:
- https://github.com/autowarefoundation/autoware/actions/runs/2788563361
- https://github.com/autowarefoundation/autoware/actions/runs/2788566418
",kenji-miyake,702476.0,60333.0,8,5,0,3,27
feat: update cuda version,2022-08-03T12:11:54Z,1325490278,1203867795.0,reply,"CI (Galactic):
- https://github.com/autowarefoundation/autoware/actions/runs/2789297131
- https://github.com/autowarefoundation/autoware/actions/runs/2789297583

CI (Humble):
- https://github.com/autowarefoundation/autoware/runs/7651666402?check_suite_focus=true
- https://github.com/autowarefoundation/autoware/runs/7651667565?check_suite_focus=true",kenji-miyake,702476.0,60333.0,8,5,0,3,27
feat: update cuda version,2022-08-04T13:52:01Z,1325490278,1205288614.0,reply,I checked the lidar_centerpoint package runs successfully with <https://github.com/autowarefoundation/autoware.universe/pull/1472>.,yukke42,702476.0,60333.0,8,5,0,3,27
chore(.clang-tidy): add readability-identifier-naming,2022-08-02T04:23:24Z,1323596554,1202000464.0,reply,"Sounds good, can't wait to try it!",xmfcx,107104.0,107083.0,1,1,0,1,15
feat(morai_msgs): appending a message package for MORAI SIM: Drive ,2022-07-15T09:17:43Z,1305767394,1185349865.0,comment,"@mitsudome-r @WjaworskiRobotec @sglee-morai
Hi, Mitsudome san and Wojciech Jaworski. As discussed earlier in the simulation working group, I made a distinct issue and pull request for appending morai_msgs to autoware.repos. please review this. 
Thanks in advance for your help.",SoohyeokPark-MORAI,259051.0,1399.0,1,2,0,1,4
Append morai_msgs package related to testing codes about checking simulator compatibility,2022-07-15T07:50:02Z,1305703547,,,,Soohyeok-Park,,,0,0,0,0,0
fix(docker): register Vulkan GPU vendors,2022-07-20T23:36:41Z,1304479103,1190872919.0,reply,"@ambroise-arm Here are my test results. It seems to be working correctly. :+1: 

Up: With this PR
Down: Without this PR
![image](https://user-images.githubusercontent.com/31987104/180099528-152e839c-6017-4bba-9b35-508c9027860b.png)

Without this PR, `vkcube` moves extremely fast.
https://user-images.githubusercontent.com/31987104/180100117-afcd5521-8ad9-4c20-8805-8a737cd9e6b0.mp4

```dockerfile
from ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda

## Register Vulkan GPU vendors
ADD ""https://gitlab.com/nvidia/container-images/vulkan/raw/dc389b0445c788901fda1d85be96fd1cb9410164/nvidia_icd.json"" /etc/vulkan/icd.d/nvidia_icd.json
RUN chmod 644 /etc/vulkan/icd.d/nvidia_icd.json
ADD ""https://gitlab.com/nvidia/container-images/opengl/raw/ubuntu20.04/glvnd/runtime/10_nvidia.json"" /etc/glvnd/egl_vendor.d/10_nvidia.json
RUN chmod 644 /etc/glvnd/egl_vendor.d/10_nvidia.json
```

With this PR:
```bash
docker build . -t autoware-pr-2736
docker run --rm -it --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all -e DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix:rw -v $HOME/.Xauthority:$HOME/.Xauthority:rw -e XAUTHORITY=$HOME/.Xauthority --net=host autoware-pr-2736:latest
apt update && apt install vulkan-tools
vulkaninfo | grep NVIDIA
vkcube
```

Without this PR:
```bash
docker run --rm -it --gpus all -e NVIDIA_DRIVER_CAPABILITIES=all -e DISPLAY -v /tmp/.X11-unix:/tmp/.X11-unix:rw -v $HOME/.Xauthority:$HOME/.Xauthority:rw -e XAUTHORITY=$HOME/.Xauthority --net=host ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda
apt update && apt install vulkan-tools
vulkaninfo | grep NVIDIA
vkcube
```
",kenji-miyake,948759.0,571095.0,4,1,0,1,6
fix(docker): register Vulkan GPU vendors,2022-07-24T08:17:01Z,1304479103,1193270198.0,reply,"From original [vulkan readme](https://gitlab.com/nvidia/container-images/vulkan/-/blob/master/README.md#headless-vulkaninfo):
```bash
docker run --gpus all \
   -e NVIDIA_DISABLE_REQUIRE=1 \
   -e NVIDIA_DRIVER_CAPABILITIES=all --device /dev/dri \
   -v /etc/vulkan/icd.d/nvidia_icd.json:/etc/vulkan/icd.d/nvidia_icd.json \
   -v /etc/vulkan/implicit_layer.d/nvidia_layers.json:/etc/vulkan/implicit_layer.d/nvidia_layers.json \
   -v /usr/share/glvnd/egl_vendor.d/10_nvidia.json:/usr/share/glvnd/egl_vendor.d/10_nvidia.json \
   -it nvidia/vulkan:1.3-470 \
    bash
```

**My answered questions:**
- Should we put a copy of the `nvidia_icd.json` and the `10_nvidia.json` instead of recommended mounting recommendations?
  - This was also asked by @kenji-miyake and answered by you [in here](https://github.com/autowarefoundation/autoware/pull/2736/files#discussion_r923171341).
  - I am ok with your reasoning/solution.
- I couldn't find where the `https://gitlab.com/nvidia/container-images/vulkan/raw/dc389b0445c788901fda1d85be96fd1cb9410164/nvidia_icd.json` file was directing to in the [vulkan repository](https://gitlab.com/nvidia/container-images/vulkan) so I was going to ask where it is from.
  - You discussed this [in above here](https://github.com/autowarefoundation/autoware/pull/2736#discussion_r922863077)
  - I still don't like that we are downloading these files instead of mounting them from the host, because it is not the recommended way.
  - But I understand your concerns for ease of use and simplicity of the implementation. So let's make it like this as long as things work.


**Small question:**
- Why did we not include `nvidia_layers.json` file from [the same readme](https://gitlab.com/nvidia/container-images/vulkan/-/blob/master/README.md#headless-vulkaninfo)? (not that I know what it does🤷‍♂️)",xmfcx,948759.0,571095.0,4,1,0,1,6
fix(docker): register Vulkan GPU vendors,2022-07-24T21:01:33Z,1304479103,1193393555.0,reply,"@xmfcx Thank you for your review!

> Why did we not include nvidia_layers.json file from [the same readme](https://gitlab.com/nvidia/container-images/vulkan/-/blob/master/README.md#headless-vulkaninfo)? (not that I know what it doesman_shrugging)

@ambroise-arm Could you answer this question? :pray: ",kenji-miyake,948759.0,571095.0,4,1,0,1,6
fix(docker): register Vulkan GPU vendors,2022-07-25T08:14:55Z,1304479103,1193730495.0,comment,"@kenji-miyake @xmfcx Thanks for the review.

From [nvidia documentation](https://download.nvidia.com/XFree86/Linux-aarch64/455.45.01/README/installedcomponents.html):
> An additional Vulkan layer configuration file is installed as /etc/vulkan/implicit_layer.d/nvidia_layers.json. These layers add functionality to the Vulkan loader.

I'm not sure what that implies, but it seems to work fine without it. And I hadn't come across that file before reading the vulkan readme, which is why it isn't part of the commit. We can add it if someone finds a usecase where it is needed.",ambroise-arm,948759.0,571095.0,4,1,0,1,6
docs: add note to use rocker without the CUDA environment error,2022-07-13T07:13:01Z,1302791939,1182851554.0,reply,Resolves #2452.,kenji-miyake,21671.0,20121.0,1,2,0,1,2
fix(docker): remove all CUDA apt repositories not to cause errors during apt update,2022-07-12T02:02:13Z,1301436499,1181227757.0,comment,"My test result:

```console
❯ docker run --rm -it ghcr.io/autowarefoundation/autoware-universe:humble-latest-cuda
root@8ad7017eb740:/autoware# rm -rf /etc/apt/sources.list.d/cuda*.list
root@8ad7017eb740:/autoware# apt update
Get:1 http://packages.ros.org/ros2/ubuntu jammy InRelease [4670 B]
Get:2 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]
Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]
Get:4 http://packages.ros.org/ros2/ubuntu jammy/main amd64 Packages [643 kB]
Ign:5 https://s3.amazonaws.com/autonomoustuff-repo jammy InRelease
Get:6 https://s3.amazonaws.com/autonomoustuff-repo jammy Release [2922 B]
Ign:7 https://s3.amazonaws.com/autonomoustuff-repo jammy Release.gpg
Get:8 https://s3.amazonaws.com/autonomoustuff-repo jammy/main amd64 Packages [1363 B]
Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [114 kB]
Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [99.8 kB]
Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [101 kB]
Get:12 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]
Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]
Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [226 kB]
Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [248 kB]
Get:16 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]
Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]
Get:18 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [4648 B]
Get:19 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]
Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [7804 B]
Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [441 kB]
Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [184 kB]
Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [292 kB]
Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [5798 B]
Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]
Get:26 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]
Fetched 24.0 MB in 4s (6117 kB/s)
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
37 packages can be upgraded. Run 'apt list --upgradable' to see them.
```

For the NVIDIA image:

```console
❯ docker run --rm -it nvidia/cuda:11.6.2-devel-ubuntu20.04
root@0a271e2940e9:/# apt update
Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1581 B]
Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [580 kB]
Err:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages
  File has unexpected size (580845 != 580040). Mirror sync in progress? [IP: 152.199.39.144 443]
  Hashes of expected file:
   - Filesize:580040 [weak]
   - SHA256:dc8abbaf470d3ee626f4f1f4d2871a98d8dc8f770bc592676f0d1f60637e0c2d
   - SHA1:109bfa4e5c415731aa44b1c1caae3f19754c5406 [weak]
   - MD5Sum:bf8f928cb55b1c9e4c158a69ee52b5d8 [weak]
  Release file created at: Mon, 11 Jul 2022 19:01:54 +0000
Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]
Get:4 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]
Get:5 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]
Get:6 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1351 kB]
Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]
Get:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]
Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]
Get:10 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [883 kB]
Get:11 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [1990 kB]
Get:12 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]
Get:13 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]
Get:14 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]
Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1161 kB]
Get:16 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1483 kB]
Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2454 kB]
Get:18 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]
Get:19 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [54.2 kB]
Get:20 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.1 kB]
Fetched 22.9 MB in 5s (4890 kB/s)
Reading package lists... Done
E: Failed to fetch https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/Packages.gz  File has unexpected size (580845 != 580040). Mirror sync in progress? [IP: 152.199.39.144 443]
   Hashes of expected file:
    - Filesize:580040 [weak]
    - SHA256:dc8abbaf470d3ee626f4f1f4d2871a98d8dc8f770bc592676f0d1f60637e0c2d
    - SHA1:109bfa4e5c415731aa44b1c1caae3f19754c5406 [weak]
    - MD5Sum:bf8f928cb55b1c9e4c158a69ee52b5d8 [weak]
   Release file created at: Mon, 11 Jul 2022 19:01:54 +0000
E: Some index files failed to download. They have been ignored, or old ones used instead.

root@6d296926d132:/# rm -rf /etc/apt/sources.list.d/cuda*.list
root@6d296926d132:/# apt update
Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]
Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]
Get:3 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [883 kB]
Get:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]
Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]
Get:6 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]
Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]
Get:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [1990 kB]
Get:9 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]
Get:10 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1351 kB]
Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]
Get:12 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]
Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1161 kB]
Get:14 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1483 kB]
Get:15 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.2 kB]
Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2454 kB]
Get:17 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [54.2 kB]
Get:18 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.1 kB]
Fetched 22.8 MB in 4s (5266 kB/s)
Reading package lists... Done
Building dependency tree
Reading state information... Done
33 packages can be upgraded. Run 'apt list --upgradable' to see them.
```",kenji-miyake,537.0,16.0,1,1,0,1,2
ci(pre-commit): autoupdate,2022-07-12T02:23:55Z,1300980445,1181240142.0,reply,"It seems some new features are introduced in `yamllint`.
https://github.com/adrienverge/yamllint/commits/master
![image](https://user-images.githubusercontent.com/31987104/178394868-b22b8e66-e139-4bd5-8877-96d21f8db260.png)
",kenji-miyake,12390511.0,33786.0,1,1,0,1,8
ci(docker-build-and-push): remove a workaround for docker/bake-action,2022-07-04T08:33:40Z,1292821725,1173521608.0,comment,"CI (maybe it will fail): https://github.com/autowarefoundation/autoware/actions/runs/2608777798

Retry on 08/19: https://github.com/autowarefoundation/autoware/actions/runs/2886298463
Retry on 09/22: https://github.com/autowarefoundation/autoware/actions/runs/3103478267",kenji-miyake,6909503.0,46.0,3,1,0,1,12
ci(docker-build-and-push): remove a workaround for docker/bake-action,2022-09-22T07:18:46Z,1292821725,1254626658.0,comment,"It seems fixed.

Before
```
Buildx version
  /usr/bin/docker buildx version
  github.com/docker/buildx 0.8.2+azure-1 6224def4dd2c3d347eee19db595348c50d7cb491
```

After
```
Buildx version
  /usr/bin/docker buildx version
  github.com/docker/buildx 0.9.1+azure-1 ed00243a0ce2a0aee75311b06e32d33b44729689
```
",kenji-miyake,6909503.0,46.0,3,1,0,1,12
ci(docker-build-and-push): remove a workaround for docker/bake-action,2022-09-22T07:27:09Z,1292821725,1254634613.0,comment,Probably it's thanks to https://github.com/actions/runner-images/releases/tag/ubuntu20%2F20220828.1.,kenji-miyake,6909503.0,46.0,3,1,0,1,12
refactor: refactor Docker build script,2022-07-04T06:51:10Z,1292707057,1173419975.0,comment,"I've tested the following commands locally and it seems working well.

```console
❯ ./docker/build.sh
+ docker buildx bake --load --progress=plain -f /home/kenji/autoware/docker/autoware-universe/docker-bake.hcl --set '*.context=/home/kenji/autoware/docker/../' --set '*.ssh=default' --set '*.platform=linux/amd64' --set '*.args.ROS_DISTRO=galactic' --set '*.args.BASE_IMAGE=ubuntu:20.04' --set '*.args.SETUP_ARGS=--no-cuda-drivers' --set devel.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda --set prebuilt.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest-prebuilt-cuda
```

```console
❯ ./docker/build.sh --no-cuda
+ docker buildx bake --load --progress=plain -f /home/kenji/autoware/docker/autoware-universe/docker-bake.hcl --set '*.context=/home/kenji/autoware/docker/../' --set '*.ssh=default' --set '*.platform=linux/amd64' --set '*.args.ROS_DISTRO=galactic' --set '*.args.BASE_IMAGE=ubuntu:20.04' --set '*.args.SETUP_ARGS=--no-nvidia' --set devel.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest --set prebuilt.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest-prebuilt
```

```console
❯ ./docker/build.sh --platform linux/amd64
+ docker buildx bake --load --progress=plain -f /home/kenji/autoware/docker/autoware-universe/docker-bake.hcl --set '*.context=/home/kenji/autoware/docker/../' --set '*.ssh=default' --set '*.platform=linux/amd64' --set '*.args.ROS_DISTRO=galactic' --set '*.args.BASE_IMAGE=ubuntu:20.04' --set '*.args.SETUP_ARGS=--no-cuda-drivers' --set devel.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda --set prebuilt.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest-prebuilt-cuda
```

```console
❯ ./docker/build.sh --platform linux/arm64
+ docker buildx bake --load --progress=plain -f /home/kenji/autoware/docker/autoware-universe/docker-bake.hcl --set '*.context=/home/kenji/autoware/docker/../' --set '*.ssh=default' --set '*.platform=linux/arm64' --set '*.args.ROS_DISTRO=galactic' --set '*.args.BASE_IMAGE=ubuntu:20.04' --set '*.args.SETUP_ARGS=--no-cuda-drivers' --set devel.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest-cuda --set prebuilt.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest-prebuilt-cuda
```

```console
❯ ./docker/build.sh --platform linux/arm64 --no-cuda
+ docker buildx bake --load --progress=plain -f /home/kenji/autoware/docker/autoware-universe/docker-bake.hcl --set '*.context=/home/kenji/autoware/docker/../' --set '*.ssh=default' --set '*.platform=linux/arm64' --set '*.args.ROS_DISTRO=galactic' --set '*.args.BASE_IMAGE=ubuntu:20.04' --set '*.args.SETUP_ARGS=--no-nvidia' --set devel.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest --set prebuilt.tags=ghcr.io/autowarefoundation/autoware-universe:galactic-latest-prebuilt
```",kenji-miyake,6311.0,277.0,1,1,0,2,61
feat(docker_image): add cuda_base_image,2022-07-04T05:33:46Z,1292647186,1173369063.0,comment,"CI:
- https://github.com/autowarefoundation/autoware/actions/runs/2607914613
- https://github.com/autowarefoundation/autoware/actions/runs/2607914888
- https://github.com/autowarefoundation/autoware/actions/runs/2607915195
- https://github.com/autowarefoundation/autoware/actions/runs/2607915456",kenji-miyake,10291.0,138.0,1,1,0,6,15
refactor: refactor scripts,2022-07-04T03:06:25Z,1292551653,1173288082.0,comment,"CI:
- https://github.com/autowarefoundation/autoware/actions/runs/2607417259
- https://github.com/autowarefoundation/autoware/actions/runs/2607417552
- https://github.com/autowarefoundation/autoware/actions/runs/2607417650
- https://github.com/autowarefoundation/autoware/actions/runs/2607417961",kenji-miyake,13245.0,203.0,1,6,0,13,81
build(ROS distribution)!: transition to ROS 2 Humble,2022-11-30T15:39:27Z,1286762287,1332361818.0,comment,"If https://github.com/autowarefoundation/autoware/pull/3089 is merged to `main`, the version `20.04`should be replaced by `22.04`.",kenji-miyake,13505328.0,13431390.0,3,13,0,12,149
build(ROS distribution)!: transition to ROS 2 Humble,2022-11-30T17:06:16Z,1286762287,1332477155.0,comment,"@xmfcx Regarding build, we should manually trigger workflows because it's not triggered by the `pull_request` event due to the execution costs. So I'll check it tomorrow.

But before that, can I merge https://github.com/autowarefoundation/autoware/pull/3092 and https://github.com/autowarefoundation/autoware/pull/3093? They can reduce the diff of this PR.",kenji-miyake,13505328.0,13431390.0,3,13,0,12,149
build(ROS distribution)!: transition to ROS 2 Humble,2022-11-30T17:35:08Z,1286762287,1332513307.0,comment,"CI:
- https://github.com/autowarefoundation/autoware/actions/runs/3585679053
- https://github.com/autowarefoundation/autoware/actions/runs/3585680170
- https://github.com/autowarefoundation/autoware/actions/runs/3585680750
- https://github.com/autowarefoundation/autoware/actions/runs/3585681610",kenji-miyake,13505328.0,13431390.0,3,13,0,12,149
ci(pre-commit): autoupdate,2022-06-27T16:53:36Z,1286083273,,,,pre-commit-ci[bot],,,0,1,0,1,2
chore: update tool versions,2022-06-26T00:04:43Z,1284749625,,,,awf-autoware-bot[bot],,,0,1,0,2,4
docs: fix links to autoware.ai wiki,2022-06-24T06:03:07Z,1283300731,,,,mitsudome-r,,,0,1,0,1,36
docs(README): add guide for Autoware.AI users,2022-06-24T05:26:54Z,1283278695,,,,mitsudome-r,,,0,3,0,1,4
Create separate containers for testing Open AD Kit,2022-06-21T14:55:53Z,1284821478,1166428590.0,comment,"Created branch https://github.com/autowarefoundation/autoware/tree/openadkit-containers to work on this, will create a PR when I start making changes.",xmfcx,3815595.0,5578.0,9,0,0,0,0
Create separate containers for testing Open AD Kit,2022-06-22T06:23:22Z,1284821478,1166428591.0,reply,"The original issues created for this work are below:
- https://github.com/autowarefoundation/autoware.ai/issues/2447
- https://github.com/autowarefoundation/autoware-documentation/issues/101
- https://github.com/autowarefoundation/autoware-projects/issues/36
- https://github.com/autowarefoundation/autoware-projects/issues/37

The top two issues relate to creating some kind of automated build process for Autoware as a microservices architecture, and then the bottom two issues are for the initial microservices PoC work, that assumed that we would be splitting Perception into its own container.",ghost,3815595.0,5578.0,9,0,0,0,0
Create separate containers for testing Open AD Kit,2022-07-06T06:36:05Z,1284821478,1175836554.0,reply,"@xmfcx Once the containers have been created, I am happy to help out with the testing part of this issue.",ghost,3815595.0,5578.0,9,0,0,0,0
Create separate containers for testing Open AD Kit,2022-07-06T22:15:29Z,1284821478,1176804152.0,comment,"# Required nodes

In order to list the required nodes for the containers, I am trying to use @kenji-miyake -san's tool from https://github.com/orgs/autowarefoundation/discussions/2581

The tool is private for now but I'm working in cooperation with him to resolve some [issues](https://github.com/kenji-miyake/ros_component_diagram_generator/issues/6) on the package.

With the tool, I will hopefully have a list of all the nodes that are launched with the main launch files.

# Building the docker image manually

Right now I am trying to use this [build.sh](https://github.com/autowarefoundation/autoware/blob/main/docker/build.sh) to build the docker image but every time I tried, I got some connectivity issues and every time I restarted, it failed at some point and takes a very long time to retry. I will investigate this further.

I will try to build the container without buildx thingy, maybe add more layers to the image, also will consult to @kenji-miyake on this.",xmfcx,3815595.0,5578.0,9,0,0,0,0
Create separate containers for testing Open AD Kit,2022-07-19T22:21:00Z,1284821478,1189608403.0,reply,@xmfcx Hi Fatih. Would it be possible to update this issue with your current progress please? 😄 ,ghost,3815595.0,5578.0,9,0,0,0,0
Create separate containers for testing Open AD Kit,2022-08-03T13:16:43Z,1284821478,1203937809.0,reply,"@xmfcx Hi Fatih. Based on the conversation last week, it seems as if this issue is no longer considered to beneficial towards developing a microservices architecture for Autoware and the CI/CD infrastructure changes that would need to be made to support that architecture. If so, could you please add a short summary note and close the issue please.  ",ghost,3815595.0,5578.0,9,0,0,0,0
Create separate containers for testing Open AD Kit,2022-08-04T17:16:10Z,1284821478,1205544361.0,comment,"Hello @LalithVipulananthan,

Yeah, like you've said, this issue wouldn't achieve much. What we really need is to have a solid package release process based on [bloom](https://docs.ros.org/en/galactic/How-To-Guides/Releasing/Releasing-a-Package.html).",xmfcx,3815595.0,5578.0,9,0,0,0,0
Create separate containers for testing Open AD Kit,2022-08-04T21:32:12Z,1284821478,1205790087.0,reply,"I wonder what prevents to build containers as specified in this discussion.

Honestly speaking, it is hard to argue that ROS tooling is modern by current standards. I am afraid of relying more on that would bring more headache. Containers seemed like a good solution to me. What went wrong exactly?",doganulus,3815595.0,5578.0,9,0,0,0,0
Create separate containers for testing Open AD Kit,2022-08-04T22:03:58Z,1284821478,1205814232.0,comment,"@doganulus Autoware Universe currently provides several docker containers in https://github.com/autowarefoundation/autoware/pkgs/container/autoware-universe and you can follow the [instructions from the documentation](https://autowarefoundation.github.io/autoware-documentation/main/installation/autoware/docker-installation/) to run Autoware using them.

These containers are built as artifacts of the [Autoware CI workflows](https://github.com/autowarefoundation/autoware/tree/main/.github/workflows),   [twice in a month](https://github.com/autowarefoundation/autoware/blob/main/.github/workflows/docker-build-and-push-humble-self-hosted.yaml#L8).

Also the plan is create our own debian repository for Autoware ROS packages' releases. This way if we want to create containers from select few packages, we can install them into the container using `apt`. Any other ROS package is released/installed that way, including many dependencies of the Autoware.",xmfcx,3815595.0,5578.0,9,0,0,0,0
add manual triggering for workflows,2022-06-13T15:53:23Z,1269642735,,,,mitsudome-r,,,0,1,0,3,3
CUDA environment is broken when I run a docker container with rocker,2022-06-20T03:29:06Z,1284821470,1166428567.0,reply,I get the same problem,LevieSun,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-20T03:37:40Z,1284821470,1166428568.0,reply,"I think this will be resolved after we change the base image to [11.7.0-devel-ubuntu22.04](https://hub.docker.com/layers/cuda/nvidia/cuda/11.7.0-devel-ubuntu22.04/images/sha256-16c790bc3349d70a0416cf8bf1eef9b40433ee907018b5ea32bdbddf75433a9d?context=explore).

But to do that, the network installation packages of cuDNN and TensorRT should be released.
https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/

I'm waiting for that.
Or if there is another better approach, I can try it out.",kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-20T03:54:40Z,1284821470,1166428570.0,reply,"> I think this will be resolved after we change the base image to [11.7.0-devel-ubuntu22.04](https://hub.docker.com/layers/cuda/nvidia/cuda/11.7.0-devel-ubuntu22.04/images/sha256-16c790bc3349d70a0416cf8bf1eef9b40433ee907018b5ea32bdbddf75433a9d?context=explore).
> 
> But to do that, the network installation packages of cuDNN and TensorRT should be released. https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/
> 
> I'm waiting for that. Or if there is another better approach, I can try it out.

Do you have any other method to solve this problem? ",LevieSun,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-20T04:47:31Z,1284821470,1166428573.0,reply,"Regarding `nvidia-smi`, I guess it's fixed by installing `nvidia-utils`.

```sh-session
$ apt-file search $(which nvidia-smi)
nvidia-340: /usr/bin/nvidia-smi
nvidia-utils-390: /usr/bin/nvidia-smi
nvidia-utils-418-server: /usr/bin/nvidia-smi
nvidia-utils-435: /usr/bin/nvidia-smi
nvidia-utils-440: /usr/bin/nvidia-smi
nvidia-utils-450-server: /usr/bin/nvidia-smi
nvidia-utils-460-server: /usr/bin/nvidia-smi
nvidia-utils-470: /usr/bin/nvidia-smi
nvidia-utils-470-server: /usr/bin/nvidia-smi
nvidia-utils-510: /usr/bin/nvidia-smi
nvidia-utils-510-server: /usr/bin/nvidia-smi
```

Regarding `cudaErrorInsufficientDriver`, I'm sorry but I'm not sure. :pleading_face: 
I need to investigate the issue to catch up.",kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-20T06:10:50Z,1284821470,1166428574.0,reply,"> Regarding `nvidia-smi`, I guess it's fixed by installing `nvidia-utils`.
> 
> ```
> $ apt-file search $(which nvidia-smi)
> nvidia-340: /usr/bin/nvidia-smi
> nvidia-utils-390: /usr/bin/nvidia-smi
> nvidia-utils-418-server: /usr/bin/nvidia-smi
> nvidia-utils-435: /usr/bin/nvidia-smi
> nvidia-utils-440: /usr/bin/nvidia-smi
> nvidia-utils-450-server: /usr/bin/nvidia-smi
> nvidia-utils-460-server: /usr/bin/nvidia-smi
> nvidia-utils-470: /usr/bin/nvidia-smi
> nvidia-utils-470-server: /usr/bin/nvidia-smi
> nvidia-utils-510: /usr/bin/nvidia-smi
> nvidia-utils-510-server: /usr/bin/nvidia-smi
> ```
> 
> Regarding `cudaErrorInsufficientDriver`, I'm sorry but I'm not sure. 🥺 I need to investigate the issue to catch up.

I also encontered the similar problem. When I run ""colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release"" in the container of ""ghcr.io/autowarefoundation/autoware-universe:latest"" image , I found ""CUDA_TOOLKIT_ROOT_DIR not found or specified
CUDA NOT FOUND
TensorRT is NOT Available
CUDNN is NOT Available"" error. It seems the container could not find CUDA. How do I fix this problem? Do I need to install autoware from the source instead of the docker?",may012345,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-20T06:16:54Z,1284821470,1166428577.0,reply,"@may012345 Seeing @yukke42 -san's comment, I guess you can run Autoware using pure `Docker`, not `rocker`.",kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-20T06:25:11Z,1284821470,1166428579.0,comment,"Yes. I could run autoware with a`docker run` command and a image built locally following the official tutorial.

```
docker run --rm -it --gpus all -e DISPLAY -e TERM -e QT_X11_NO_MITSHM=1 -v /tmp/.X11-unix:/tmp/.X11-unix -v /etc/localtime:/etc/localtime:ro ghcr.io/autowarefoundation/autoware-universe:humble-latest
```",yukke42,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-20T06:26:33Z,1284821470,1166428580.0,reply,"> @may012345 Seeing @yukke42 -san's comment, I guess you can run Autoware using pure `Docker`, not `rocker`.

I run with ""rocker --nvidia --x11 --user --volume $HOME/autoware -- ghcr.io/autowarefoundation/autoware-universe:latest"" and met the problem.",may012345,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-28T06:57:57Z,1284821470,1168310489.0,reply,I've also met the same problem. I'm using `rocker --nvidia --x11 --user --volume $HOME/autoware -- ghcr.io/autowarefoundation/autoware-universe:latest`. ,angry-crab,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-28T07:38:19Z,1284821470,1168351145.0,reply,I have the problem with `rocker --nvidia --x11 --user --volume $HOME/autoware -- ghcr.io/autowarefoundation/autoware-universe:galactic-latest` but not with `rocker --nvidia --x11 --user --volume $HOME/autoware -- ghcr.io/autowarefoundation/autoware-universe:latest`,VRichardJP,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-28T08:29:22Z,1284821470,1168404580.0,reply,"> but not with rocker --nvidia --x11 --user --volume $HOME/autoware -- ghcr.io/autowarefoundation/autoware-universe:latest

@VRichardJP Could you tell me the hash of your images like this? I guess one is old (and based on CUDA image).

```sh-session
$ docker images | grep autoware-universe | grep "" latest ""
ghcr.io/autowarefoundation/autoware-universe                                          latest                                                                       5fdadcabfe9c   5 weeks ago     5.73GB
```",kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-29T02:21:44Z,1284821470,1169462051.0,reply,"Yes indeed, my `latest` is older than `galactic-latest`:
```
ghcr.io/autowarefoundation/autoware-universe               galactic-latest                                                          ea6b0e03f964   5 weeks ago     5.74GB
ghcr.io/autowarefoundation/autoware-universe               latest                                                                   35694ec40e8f   8 weeks ago     16.2GB
```",VRichardJP,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-29T05:42:43Z,1284821470,1169556755.0,reply,"`docker run --rm -it --gpus all -e DISPLAY -e TERM -e QT_X11_NO_MITSHM=1 -v /tmp/.X11-unix:/tmp/.X11-unix -v /etc/localtime:/etc/localtime:ro -v $HOME/adehome:/home/adehome [ghcr.io/autowarefoundation/autoware-universe:humble-latest](http://ghcr.io/autowarefoundation/autoware-universe:humble-latest)`
Using `docker` instead of `rocker` does not solve the problem. CUDA, TensorRT, and cuDNN could not be found. ",angry-crab,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-06-29T09:29:23Z,1284821470,1169752072.0,reply,"@angry-crab `humble-latest` doesn't contain CUDA now. Please use `humble-latest-cuda` instead.
https://github.com/autowarefoundation/autoware/pkgs/container/autoware-universe/26944787?tag=humble-latest-cuda",kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-07-04T09:23:50Z,1284821470,1173576697.0,reply,"I found the problem is because of the env `NVIDIA_DRIVER_CAPABILITIES`.

To confirm that, run the following command.

```bash
rocker --nvidia --x11 --user --env NVIDIA_DRIVER_CAPABILITIES="""" -- ghcr.io/autowarefoundation/autoware-universe:humble-latest-cuda

# Or
rocker --nvidia --x11 --user --env NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics -- ghcr.io/autowarefoundation/autoware-universe:humble-latest-cuda
```

I'll investigate this behavior more in detail and fix it.",kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-07-04T11:05:33Z,1284821470,1173684270.0,reply,"Sent a PR: https://github.com/osrf/rocker/pull/182

If it's not accepted, I'll add the following block in the Dockerfile.

```dockerfile

## Set env for nvidia-container-runtime
ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES compute,utility
```",kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-07-08T02:10:38Z,1284821470,1178459561.0,reply,"@yukke42 My PR to `rocker` is merged. Do you think we can close this issue?
We can set `NVIDIA_DRIVER_CAPABILITIES` manually until the new `rocker` is released.",kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-07-12T01:29:58Z,1284821470,1181212502.0,comment,"@kenji-miyake 
I'm sorry for the late replay. AND thank you for identifying the cause of this issue!
I will close this issue after creating a PR to add your suggestion into the document.
 ",yukke42,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-07-12T08:02:55Z,1284821470,1181448176.0,comment,"> @.kenji-miyake I'm sorry for the late replay. AND thank you for identifying the cause of this issue! I will close this issue after creating a PR to add your suggestion into the document.

I will do after [this related issue](https://github.com/autowarefoundation/autoware.universe/issues/1311) is closed.
",yukke42,3048282.0,1046079.0,20,0,0,0,0
CUDA environment is broken when I run a docker container with rocker,2022-07-13T07:39:09Z,1284821470,1182874273.0,reply,Resolved by #2732 ,kenji-miyake,3048282.0,1046079.0,20,0,0,0,0
Add configuration file for TIER IV CI/CD Pipeline,2022-06-06T07:44:06Z,1284821464,,,,vios-fish,,,0,0,0,0,0
Move external repositories to src/external in the .repos file,2022-05-27T13:05:29Z,1284821463,,,,esteve,,,0,0,0,0,0
Add announcements for EOL and fix some of the broken links,2022-05-27T09:53:04Z,1250422273,1139464146.0,reply,@mitsudome-r can you change from slack to discord in the readme?,yukkysaito,464138.0,10073.0,2,2,0,2,17
Add announcements for EOL and fix some of the broken links,2022-05-31T14:46:34Z,1250422273,1142234105.0,comment,"CI is failing, but it is mainly due to old GPG key which is irrelevant from the change in this PR. The error should be fixed in another PR.",mitsudome-r,464138.0,10073.0,2,2,0,2,17
Analyze the execution time of the function nodes,2022-06-01T07:05:46Z,1284821460,1166428555.0,reply,"For the control module, I focus on two controllers (MPC for lateral and PID for longitudinal). These data were collected under two different status. See following for details:

![statistics_tracing_control](https://user-images.githubusercontent.com/87111711/171346894-625b7c1a-36f4-40d9-b43e-3433572e00dd.png)

![still](https://user-images.githubusercontent.com/87111711/171346919-d183c145-6a37-42b2-92a4-4340d09b4de0.png)

",JianKangEgon,4476611.0,436066.0,4,0,0,0,0
Analyze the execution time of the function nodes,2022-06-17T09:17:25Z,1284821460,1166428558.0,reply,"
For the localization module, we analyzed the running time of multiple nodes and container such as pose_initializer, ndt_scan_matche, ekf_localizer, etc., and specific results are as follows:
![image](https://user-images.githubusercontent.com/104069308/174268153-0c352075-d4fc-4716-9dc1-6697ddec14c5.png)
",cyn-liu,4476611.0,436066.0,4,0,0,0,0
Analyze the execution time of the function nodes,2022-06-17T10:02:59Z,1284821460,1166428559.0,reply,"perspection:
mode=lidar
![110](https://user-images.githubusercontent.com/103237402/174276527-5900dd2e-d641-4a13-9140-ae80f01783b3.png)


mode=camera_lidar_fusion
![111](https://user-images.githubusercontent.com/103237402/174276554-cbe2203d-820d-42bd-9f9c-e8d5f1c0fbac.png)


",beginningfan,4476611.0,436066.0,4,0,0,0,0
Analyze the execution time of the function nodes,2022-07-18T01:28:11Z,1284821460,1186670491.0,reply,Refer to [Analysis of execution delay of Autoware Nodes](https://github.com/autowarefoundation/autoware/files/9128996/Analysis.of.execution.delay.of.Autoware.Nodes.pdf),Sharrrrk,4476611.0,436066.0,4,0,0,0,0
[Humble] arm64 build fails,2022-05-24T11:16:13Z,1284821450,1166428547.0,reply,I've reproduced this and now working on it.,xmfcx,7966.0,3297.0,6,0,0,0,0
[Humble] arm64 build fails,2022-05-24T11:48:01Z,1284821450,1166428549.0,reply,"I've applied change from https://gitlab.com/autowarefoundation/autoware.auto/AutowareAuto/-/merge_requests/1357/diffs#76174e89c5600d934d9dd62a01ca0159e7e0d42a_35_38 and it compiled fine.

created pr in the package: https://github.com/tier4/grid_map/pull/2",xmfcx,7966.0,3297.0,6,0,0,0,0
[Humble] arm64 build fails,2022-05-24T11:48:58Z,1284821450,1166428550.0,reply,"Once the PR is merged, we can close this issue.",xmfcx,7966.0,3297.0,6,0,0,0,0
[Humble] arm64 build fails,2022-05-24T12:00:31Z,1284821450,1166428551.0,comment,"https://github.com/tier4/grid_map/pull/2#pullrequestreview-983084399
> @xmfcx Thank you!
Could you submit a PR to https://github.com/ANYbotics/grid_map/tree/ros2 as well?
We're temporarily using TIER IV's fork.",kenji-miyake,7966.0,3297.0,6,0,0,0,0
[Humble] arm64 build fails,2022-05-24T12:22:40Z,1284821450,1166428553.0,reply,Created https://github.com/ANYbotics/grid_map/pull/349,xmfcx,7966.0,3297.0,6,0,0,0,0
[Humble] arm64 build fails,2022-05-24T12:34:02Z,1284821450,1166428554.0,comment,I've confirmed it's resolved. Thanks!,kenji-miyake,7966.0,3297.0,6,0,0,0,0
Use a common base image for CUDA libraries,2022-07-04T06:00:34Z,1284821440,1173383750.0,comment,"For Galactic, it will be resolved by https://github.com/autowarefoundation/autoware/pull/2703.",kenji-miyake,,3541338.0,1,0,0,0,0
resolve libzmqpp-dev package in Ubuntu 22.04,2022-06-22T17:33:45Z,1284821432,1166428533.0,reply,I think we can close this issue now that autowarefoundation/autoware#350 is closed.,wep21,2577461.0,2550627.0,1,0,0,0,0
Make the Docker image size smaller,2022-05-23T17:25:21Z,1284821426,1166428529.0,comment,"Related:
- https://docs.nvidia.com/cuda/eula/index.html#attachment-a
- https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-metas
- https://github.com/Autoware-AI/docker/blob/0d808605034faf5470b00e9a1db73307c400111b/generic/Dockerfile.cuda.melodic
- https://github.com/NVIDIA/TensorRT/blob/main/docker/ubuntu-20.04.Dockerfile
- https://gitlab.com/nvidia/container-images/cuda/-/blob/master/dist/11.6.2/ubuntu2004/devel/Dockerfile

Thank you for your support @wep21!",kenji-miyake,36738.0,1874.0,3,0,0,0,0
Make the Docker image size smaller,2022-05-24T02:40:12Z,1284821426,1166428530.0,comment,I'll apply https://gitlab.com/nvidia/container-images/cuda/-/blob/master/dist/11.6.2/ubuntu2004/devel/Dockerfile#L56.,kenji-miyake,36738.0,1874.0,3,0,0,0,0
Make the Docker image size smaller,2022-05-24T03:33:27Z,1284821426,1166428531.0,comment,"Actually, the image size wasn't such a big problem. It's important to have a common base for CUDA libraries.
I'll create another issue.",kenji-miyake,36738.0,1874.0,3,0,0,0,0
Support ROS 2 Humble,2022-07-04T17:02:49Z,1284821424,1174008936.0,comment,Resolved by https://github.com/autowarefoundation/autoware/pull/2692.,kenji-miyake,3715798.0,3715798.0,1,0,0,0,0
Add Ccache into docker image to speed up recompilation,2022-05-21T01:00:16Z,1284821419,1166428521.0,comment,@kenji-miyake Should we add Ccache into docker image? What do you think?,brkay54,63895.0,238.0,2,0,0,0,0
Add Ccache into docker image to speed up recompilation,2022-05-21T16:59:09Z,1284821419,1166428523.0,reply,"@brkay54 Yes, I think it's possible. Could you send a PR like plotjuggler?",kenji-miyake,63895.0,238.0,2,0,0,0,0
build faild,2022-05-12T10:10:25Z,1284821415,1166428518.0,reply,"If you can describe 
- your version of OS , cuda version, cudnn, TensorRT and etc,
- the command the error reproduced
we are very helpful since we can share the problem.",shmpwk,33.0,273790.0,1,0,0,0,0
Run setup-dev-env.sh docker failed,2022-05-06T08:41:53Z,1284821408,1166428510.0,reply,"@Sharrrrk Thank you for reporting this.
- What's your Ansible version?
https://github.com/autowarefoundation/autoware/blob/af25faddd16bf8f9a1bace814b0f82e020803f5b/setup-dev-env.sh#L98-L99
- Is `$HOME/.local/bin` in your PATH?",kenji-miyake,2300.0,475.0,5,0,0,0,0
Run setup-dev-env.sh docker failed,2022-05-06T08:48:21Z,1284821408,1166428512.0,comment,">What's your Ansible version?

ansible                5.7.1

>Is $HOME/.local/bin in your PATH?

For my current user, `ansible-galaxy` is available, but under root accout not. The script runs with sudo, so this error occurs.

@kenji-miyake I was just updating my description, yes you are right, ansible is installed by a user account, not root account. But the version check passes.",Sharrrrk,2300.0,475.0,5,0,0,0,0
Run setup-dev-env.sh docker failed,2022-05-06T09:07:39Z,1284821408,1166428514.0,reply,"@Sharrrrk I see, thank you. Could you update the script to work in your environment? Or should I help something?",kenji-miyake,2300.0,475.0,5,0,0,0,0
Run setup-dev-env.sh docker failed,2022-05-06T09:08:59Z,1284821408,1166428515.0,reply,"By the way, I'm thinking of removing `sudo` from `pip` install. 92c356754133b8414d5a0feef04fb51227547bda
Is that related to this issue?",kenji-miyake,2300.0,475.0,5,0,0,0,0
Run setup-dev-env.sh docker failed,2022-05-06T09:12:18Z,1284821408,1166428516.0,comment,"> 

I can quick fix it with `sudo pip3 install ansible`. 

>By the way, I'm thinking of removing sudo from pip install. 

This definitely would solve this issue. Thank you.",Sharrrrk,2300.0,475.0,5,0,0,0,0
Fail to update a workspace,2022-05-02T09:20:24Z,1284821405,1166428500.0,reply,"@shmpwk Ah, yeah exactly. I'm sorry for my mistake. :bow: 
Could you fix send a PR to fix this? :pray: 

> because of .gitignore.

Strictly speaking, I believe `.gitignore` isn't related. It's because `~/autoware` is a Git repository. So you can also use `vcs pull --nested` to update the workspace.",kenji-miyake,1216.0,438.0,4,0,0,0,0
Fail to update a workspace,2022-05-02T09:30:00Z,1284821405,1166428501.0,comment,"Thank you, I see.
Which do you lilke `vcs pull src` or `vcs pull --nested`? ",shmpwk,1216.0,438.0,4,0,0,0,0
Fail to update a workspace,2022-05-02T09:33:22Z,1284821405,1166428502.0,comment,"I've use former.
Close by https://github.com/autowarefoundation/autoware-documentation/pull/95",shmpwk,1216.0,438.0,4,0,0,0,0
Fail to update a workspace,2022-05-02T09:40:47Z,1284821405,1166428505.0,reply,"Thank you for your PR!
I personally prefer `vcs pull src` because I've never used the `--nested` option.",kenji-miyake,1216.0,438.0,4,0,0,0,0
CUDA GPG causes an error,2022-04-30T07:21:19Z,1284821397,1166428493.0,comment,"The commands users should run are:

```bash
sudo apt-key del 7fa2af80
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub
```

https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=deb_network

Or,

```bash
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
# wget https://developer.download.nvidia.com/compute/cuda/repos/$distro/$arch/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
```

https://forums.developer.nvidia.com/t/notice-cuda-linux-repository-key-rotation/212772/1",kenji-miyake,104813.0,103772.0,2,0,0,0,0
CUDA GPG causes an error,2022-04-30T07:41:22Z,1284821397,1166428494.0,comment,"CI:
- https://github.com/autowarefoundation/autoware/runs/6238798725?check_suite_focus=true
- https://github.com/autowarefoundation/autoware/runs/6238798979?check_suite_focus=true",kenji-miyake,104813.0,103772.0,2,0,0,0,0
CUDA installation for ARM64 is broken for some reasons,2022-04-30T15:37:01Z,1284821394,1166428486.0,comment,"Now it seems fixed.
https://github.com/autowarefoundation/autoware/runs/6238798979?check_suite_focus=true
https://github.com/autowarefoundation/autoware/runs/6238801834?check_suite_focus=true",kenji-miyake,176991.0,176991.0,1,0,0,0,0
Improve PlotJugger installation,2022-05-14T09:42:36Z,1284821385,1166428481.0,comment,"I'll add an `exec_depend` after autowarefoundation/autoware#300 is merged.
-> Since it's released, I'll cancel this.",kenji-miyake,5758951.0,1365703.0,2,0,0,0,0
Improve PlotJugger installation,2022-07-04T06:03:24Z,1284821385,1173385770.0,comment,"Since PlotJuggler was released both in Galactic and Humble, there is no need to improve the installation method anymore.",kenji-miyake,5758951.0,1365703.0,2,0,0,0,0
Enable multi-stage builds for Autoware,2022-05-10T17:32:55Z,1284821446,1166428540.0,comment,"@LalithVipulananthan 
We would need a volunteer who could do the work for this issue, I'll be able to assist of course. From my knowledge, there's only one script which build the actual container image. The files can be found here:
- /home/ubuntu/autoware/docker/build.sh
- /home/ubuntu/autoware/docker/autoware-universe/Dockerfile
- /home/ubuntu/autoware/docker/autoware-universe/docker-bake.hcl

Replacing the _build.sh_ file would be the first step.",kaspermeck-arm,23291362.0,1080613.0,7,0,0,0,0
Enable multi-stage builds for Autoware,2022-05-10T19:37:59Z,1284821446,1166428541.0,reply,"@kasperornmeck cc @LalithVipulananthan 
FYI, as written in https://github.com/autowarefoundation/autoware/blob/main/docker/README.md, `build.sh` is for the local build.

The actual images hosted on https://github.com/autowarefoundation/autoware/pkgs/container/autoware-universe are created by these workflows and actions.
- https://github.com/autowarefoundation/autoware/blob/main/.github/workflows/build.yaml
- https://github.com/autowarefoundation/autoware/blob/main/.github/workflows/build-self-hosted.yaml
- https://github.com/autowarefoundation/autoware/blob/main/.github/actions/docker-build-and-push/action.yaml

> Replacing the build.sh file would be the first step.

Regarding this part, could you first start with creating it as another script like `build-compose.sh`?
And after checking the behavior and reviewing it, I'd like to consider replacing it.",kenji-miyake,23291362.0,1080613.0,7,0,0,0,0
Enable multi-stage builds for Autoware,2022-05-18T14:50:26Z,1284821446,1166428543.0,comment,"@kenji-miyake 
Thanks for sharing these links. I'll have to look more into these to understand the workflow in GitHub.",kaspermeck-arm,23291362.0,1080613.0,7,0,0,0,0
Enable multi-stage builds for Autoware,2022-05-18T15:05:21Z,1284821446,1166428544.0,comment,"@kenji-miyake 
Does this mean that the developer environment container used in the cloud on GitHub is different from the developer container which would be used locally?",kaspermeck-arm,23291362.0,1080613.0,7,0,0,0,0
Enable multi-stage builds for Autoware,2022-05-18T15:23:40Z,1284821446,1166428545.0,reply,"@kasperornmeck No, they are not so different. The differences are just some settings.
To build Docker images with GitHub Actions, it's better to use useful third-party actions. But they can't be used in our local, so we need to change some settings to handle the differences.",kenji-miyake,23291362.0,1080613.0,7,0,0,0,0
Enable multi-stage builds for Autoware,2022-06-15T23:38:41Z,1284821446,1166428546.0,reply,"For the Perception PoC, to build all dependent components for perception, use the following command:
`colcon build --packages-up-to tier4_perception_launch`",ghost,23291362.0,1080613.0,7,0,0,0,0
Enable multi-stage builds for Autoware,2023-01-20T22:56:35Z,1284821446,1399047467.0,comment,@BonoloAWF - I suggest we close this issue as it won't go anywhere and the issues this issue tries to solve is addressed in the DevOps Dojos.,kaspermeck-arm,23291362.0,1080613.0,7,0,0,0,0
Support ROS 2 Rolling on Ubuntu 22.04,2022-04-27T04:54:04Z,1284821374,1166428475.0,comment,"@xmfcx @mitsudome-r @esteve I'll work on this with the help of @wep21.

I'll keep the work logs in https://github.com/orgs/autowarefoundation/discussions/2566.",kenji-miyake,2198868.0,43.0,4,0,0,0,0
Support ROS 2 Rolling on Ubuntu 22.04,2022-04-27T09:58:55Z,1284821374,1166428476.0,reply,"@kenji-miyake let me if there's anything I can help with, I'm happy to contribute code and review PRs.",esteve,2198868.0,43.0,4,0,0,0,0
Support ROS 2 Rolling on Ubuntu 22.04,2022-04-28T15:12:59Z,1284821374,1166428477.0,comment,"Since Humble is already available with `ros2-testing`, I'll test it, too.
https://docs.ros.org/en/humble/Installation/Ubuntu-Install-Debians.html",kenji-miyake,2198868.0,43.0,4,0,0,0,0
Support ROS 2 Rolling on Ubuntu 22.04,2022-05-22T15:41:09Z,1284821374,1166428478.0,comment,I'll support Humble in another branch/PR.,kenji-miyake,2198868.0,43.0,4,0,0,0,0
[CI] github-release creates multiple releases for the same branch,2022-04-27T04:11:14Z,1284821366,1166428467.0,comment,"The `edit` command is introduced in v2.8.0 and the default version installed is v2.7.0. :pleading_face: 
https://github.com/cli/cli/releases/tag/v2.8.0
https://github.com/kenji-miyake/autoware/runs/6187394858?check_suite_focus=true#step:8:4

Seeing the release cycle, I guess it's released this week.",kenji-miyake,457504.0,1809.0,1,0,0,0,0
Permission denied errors occur when building perception packages that require trained model ONNX files to be downloaded from Google Drive,2022-04-20T11:34:32Z,1284821360,1166428459.0,reply,Can i assign @eratostennis? :pray: ,yukkysaito,4388391.0,1183.0,4,0,0,0,0
Permission denied errors occur when building perception packages that require trained model ONNX files to be downloaded from Google Drive,2022-04-20T11:37:02Z,1284821360,1166428461.0,reply,"**Cause:** 
If there are too many downloads, Google drive will limit the downloads with gdown.

**Temporary solution:**
 download manually the weight files from download links
",yukkysaito,4388391.0,1183.0,4,0,0,0,0
Permission denied errors occur when building perception packages that require trained model ONNX files to be downloaded from Google Drive,2022-04-26T01:12:19Z,1284821360,1166428464.0,reply,I will store the model on another storage this week to avoid the limitation of google drive.,eratostennis,4388391.0,1183.0,4,0,0,0,0
Permission denied errors occur when building perception packages that require trained model ONNX files to be downloaded from Google Drive,2022-05-27T09:08:00Z,1284821360,1166428466.0,reply,"@LalithVipulananthan 

In this pull request I moved ml models to another storage.
I don't think the same problem will occur.

If it's good for you, please close this issue.",eratostennis,4388391.0,1183.0,4,0,0,0,0
Autoware.universe install fail on Jetson Xavier platform,2022-04-19T14:29:03Z,1284821353,1166428448.0,comment,"According to https://forums.developer.nvidia.com/t/mounting-of-img-file/128257/8 it should be possible to mount the Jetson image as a loopback device, but so far I haven't succeeded. `fdisk` reports an offset of `1187840`, but neither `losetup` or `mount` seem to like it:

```
sudo mount -o loop,offset=$((512 * 1187840)) sd-blob-b01.img /home/esteve/Downloads/jetson/mnt/
mount: /home/esteve/Downloads/jetson/mnt/: failed to setup loop device for sd-blob-b01.img.
```

I'll see if I can extract the image via `dd` and mount it without offset.",esteve,12869297.0,19155.0,6,0,0,0,0
Autoware.universe install fail on Jetson Xavier platform,2022-04-21T11:21:00Z,1284821353,1166428449.0,comment,"More progress, I managed to use `kpartx` to mount the first partition in the image and `chroot`ed in to inspect the `/` filesystem. However, running Docker from inside the `chroot` is not as easy, but I'll continue trying.",esteve,12869297.0,19155.0,6,0,0,0,0
Autoware.universe install fail on Jetson Xavier platform,2022-05-02T13:27:33Z,1284821353,1166428450.0,comment,According to https://github.com/orgs/autowarefoundation/discussions/255#discussioncomment-2664151 upgrading to Jetpack 5.0 fixes any CUDA-related issues. @jason914 could you try upgrading to Jetpack 5.0 and see if you can run Autoware? Thanks.,esteve,12869297.0,19155.0,6,0,0,0,0
Autoware.universe install fail on Jetson Xavier platform,2022-05-09T04:54:17Z,1284821353,1166428453.0,reply,"@esteve I just tested using Jetson AGX Xavier with JetPack 5.0 (Ubuntu 20.04) and latest arm64 docker image, after a minor fix [869](https://github.com/autowarefoundation/autoware.universe/pull/869), build success without errors.
`Summary: 195 packages finished [1h 54min 26s]Summary: 195 packages finished [1h 54min 26s]`

CUDA and OS version as below:
```
nv@xavier-5:~$ uname -a
Linux xavier-5 5.10.65-tegra #1 SMP PREEMPT Wed Apr 6 11:45:49 PDT 2022 aarch64 aarch64 aarch64 GNU/Linux
nv@xavier-5:~$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Thu_Nov_11_23:44:05_PST_2021
Cuda compilation tools, release 11.4, V11.4.166
Build cuda_11.4.r11.4/compiler.30645359_0
```",Sharrrrk,12869297.0,19155.0,6,0,0,0,0
Autoware.universe install fail on Jetson Xavier platform,2022-05-09T07:54:05Z,1284821353,1166428455.0,reply,">There is an error when use following command.
rocker --nvidia --x11 --user --volume $HOME/autoware -- ghcr.io/autowarefoundation/autoware-universe:latest-arm64
Following is error log.

Having the same behavior for Q2",Sharrrrk,12869297.0,19155.0,6,0,0,0,0
Autoware.universe install fail on Jetson Xavier platform,2022-09-15T07:58:05Z,1284821353,1247724170.0,reply,"Since it is resolved in JetPack 5.0, I'm closing this issue",mitsudome-r,12869297.0,19155.0,6,0,0,0,0
Apply Autoware to the diff-drive robot,2022-04-13T07:54:35Z,1284821344,,,,shmpwk,,,0,0,0,0,0
add allow-change-held-packages option after ansible 2.13 will be released,2022-04-27T04:41:59Z,1284821334,1166428441.0,reply,"> 2022-05-23 Release

https://docs.ansible.com/ansible/devel/roadmap/ROADMAP_2_13.html

> 2022-06-21 Ansible-6.0.0 release.

https://docs.ansible.com/ansible/devel/roadmap/COLLECTIONS_6.html

> allow_change_held_packages 
boolean
added in 2.13 of ansible.builtin

https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_module.html",kenji-miyake,12706709.0,1725369.0,1,0,0,0,0
The obstacle avoidance marker is busy by default,2022-04-04T12:56:32Z,1284821328,1166428439.0,comment,"Sorry, I mistaked to post",yukkysaito,112.0,81.0,1,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-03-31T08:12:08Z,1284821322,1166428426.0,comment,@mitsudome-r @xmfcx @yukkysaito @esteve What do you think about this?,kenji-miyake,7512865.0,90.0,9,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-03-31T08:14:25Z,1284821322,1166428427.0,comment,"It seems there is no `11.6` for `libnvinfer` yet.
https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/
![image](https://user-images.githubusercontent.com/31987104/161009115-272fd47c-558f-48bf-96c9-6a30a1672d69.png)
",kenji-miyake,7512865.0,90.0,9,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-03-31T08:51:50Z,1284821322,1166428429.0,reply,"@kenji-miyake is it possible to mix the rest of CUDA 11.6 with `libnvinfer-plugin` 11.4? If not, I'd wait until the new version is released.",esteve,7512865.0,90.0,9,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-03-31T08:55:07Z,1284821322,1166428431.0,comment,"> is it possible to mix the rest of CUDA 11.6 with libnvinfer-plugin 11.4? If not, I'd wait until the new version is released.

Actually, I believe it's impossible. We have to wait for the release in any case.

Also, I'm concerned about the dependencies in https://github.com/autowarefoundation/autoware.universe.
@yukkysaito knows well about this.",kenji-miyake,7512865.0,90.0,9,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-04-05T17:58:30Z,1284821322,1166428432.0,reply,"To be sure, I am currently checking tit works properly with cuda 11.4.
After that, I will check it works with cuda11.6.",yukkysaito,7512865.0,90.0,9,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-04-15T00:49:47Z,1284821322,1166428434.0,comment,"The new version should be available in both `x86_64(amd64)` and `sbsa(arm64)`.
https://github.com/autowarefoundation/autoware/pull/154#issuecomment-1099745019

https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/
https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/sbsa/",kenji-miyake,7512865.0,90.0,9,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-04-24T12:42:31Z,1284821322,1166428436.0,comment,"I've created a helper tool to find CUDA versions.
https://github.com/kenji-miyake/find-cuda-versions

Now we can find if there are any corresponding versions to a certain CUDA version.

```sh-session
$ pip install git+https://github.com/kenji-miyake/find-cuda-versions.git
$ find-cuda-versions --cuda 11.6
[cudnn x86_64]
8.4.0.27-1+cuda11.6

[cudnn sbsa]
8.4.0.27-1+cuda11.6

[tensorrt x86_64]

[tensorrt sbsa]
```",kenji-miyake,7512865.0,90.0,9,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-06-26T05:46:43Z,1284821322,1166428437.0,reply,"This pull request has been automatically marked as stale because it has not had recent activity.
",stale[bot],7512865.0,90.0,9,0,0,0,0
Upgrade CUDA to 11.6 Update 2?,2022-06-26T07:05:03Z,1284821322,1166434664.0,comment,"Updated to 11.6 in the `humble` branch.
https://github.com/autowarefoundation/autoware.ai/blob/d2feaef806f93ceb60ae50d49ae98d904fef3e09/amd64.env#L5

But we should also consider updating to 11.7 because 11.6 isn't released to ubuntu 22.04 repo.
https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/

Currently, we use 20.04 repo with ubuntu 22.04 because 11.7 doesn't have corresponding cuDNN and TensorRT yet.",kenji-miyake,7512865.0,90.0,9,0,0,0,0
Vulkan driver fails to detect GPU,2022-04-01T06:14:01Z,1284821317,1166428412.0,reply,"1. What task are you trying to do? Because usually I don't explicitly use Vulcan in rosbag simulation
2. What is the output of `nvidia-smi` on the host environment?",IshitaTakeshi,12193811.0,255126.0,8,0,0,0,0
Vulkan driver fails to detect GPU,2022-04-01T06:42:14Z,1284821317,1166428413.0,comment,"> 1. What task are you trying to do? Because usually I don't explicitly use Vulcan in rosbag simulation
> 2. What is the output of `nvidia-smi` on the host environment?

I'm trying to start `svl` simulator. This Vulcan driver is a cross-platform GPU API released by nvidia. It was mainly used for graphics and simulation development. Most modern simulator depends on this API, such as `carla` and `svl`. 
Detailed information: [vulkan](https://developer.nvidia.com/vulkan)

`nvidia-smi` outputs the correct information about GPU.",angry-crab,12193811.0,255126.0,8,0,0,0,0
Vulkan driver fails to detect GPU,2022-04-01T06:45:23Z,1284821317,1166428415.0,reply,So are you working on the main branch? Usually I'm working on tier4/proposal so there might be misunderstanding sorry,IshitaTakeshi,12193811.0,255126.0,8,0,0,0,0
Vulkan driver fails to detect GPU,2022-04-01T08:05:20Z,1284821317,1166428417.0,comment,"> So are you working on the main branch? Usually I'm working on tier4/proposal so there might be misunderstanding sorry

Yes, I'm working with main branch. Does `tier4/proposal` branch use the same docker image? ",angry-crab,12193811.0,255126.0,8,0,0,0,0
Vulkan driver fails to detect GPU,2022-04-01T09:42:43Z,1284821317,1166428418.0,reply,Dockerfile seems the same but it copies files from the host so the Autoware code included in the docker container will be different,IshitaTakeshi,12193811.0,255126.0,8,0,0,0,0
Vulkan driver fails to detect GPU,2022-04-01T09:48:40Z,1284821317,1166428419.0,reply,But the container environment will be the same and in my environment CUDA seems to work correctly so something is wrong,IshitaTakeshi,12193811.0,255126.0,8,0,0,0,0
Vulkan driver fails to detect GPU,2022-06-08T08:58:50Z,1284821317,1166428420.0,reply,"The nvidia vulkan library needs to be registered for it to be discovered when running a vulkan program.
In Autoware.Auto we were adding the necessary file to the docker environment here: https://gitlab.com/autowarefoundation/autoware.auto/AutowareAuto/-/blob/e3e26be1ab4b822996df60f261d031d7924f20ac/tools/ade_image/Dockerfile#L100

Replicating this in the .universe environment (changing /etc/vulkan/ to /usr/share/vulkan/ to match were the other icd files are in this case)
```sh
wget https://gitlab.com/nvidia/container-images/vulkan/raw/master/nvidia_icd.json
sudo mv nvidia_icd.json /usr/share/vulkan/icd.d/
```
the vulkaninfo output changes to an error, but the actual vulkan capability works in the program I was testing.
A fast way to get vulkaninfo to work correctly is to use the ""--privileged"" flag when launching rocker/docker (and still getting the icd file), but I'm not sure if it would have an impact on actual programs using vulkan.",ambroise-arm,12193811.0,255126.0,8,0,0,0,0
Vulkan driver fails to detect GPU,2022-08-17T10:32:06Z,1284821317,1217832857.0,reply,vulkaninfo and vkcube work in :latest by following https://github.com/autowarefoundation/autoware/pull/2736#discussion_r924280351,ambroise-arm,12193811.0,255126.0,8,0,0,0,0
The lidar_centerpoint package can not download model automatically due to LIB_TORCH NOT FOUND,2022-03-18T06:08:41Z,1284821307,1166428409.0,reply,"Thank you for reporting this, but please wait for https://github.com/autowarefoundation/autoware.universe/pull/480 to be merged.",kenji-miyake,7260365.0,967.0,2,0,0,0,0
The lidar_centerpoint package can not download model automatically due to LIB_TORCH NOT FOUND,2022-04-07T00:44:46Z,1284821307,1166428410.0,reply,"@xczhanjun https://github.com/autowarefoundation/autoware.universe/pull/480 is merged, but the detected objects of lidar_centerpoint isn't published because of other problem.
Please try [the link](https://github.com/autowarefoundation/autoware.universe/issues/643#issuecomment-1090090877), to use lidar_centerpoint.",yukke42,7260365.0,967.0,2,0,0,0,0
Add NOTICE files to each repository,2022-03-12T06:08:43Z,1284821305,1166428402.0,comment,"Seeing https://github.com/Autoware-AI/autoware.ai, it seems it was in `2017` that TIER IV started to commit as ""TIER IV"".

So, I'll use `2017` for the TIER IV's copyright notation in `autoware.universe`.

```
❯ ag Copyright | ag Tier
src/drivers/awf_drivers/autoware_driveworks_interface/nodes/tensorrt_interface/tensorrt_interface_node.cpp:2: *  Copyright (c) 2017, TierIV Inc.
src/drivers/awf_drivers/autoware_driveworks_interface/include/tensorrt_interface.hpp:2: *  Copyright (c) 2018, TierIV Inc.
src/drivers/awf_drivers/autoware_driveworks_interface/nodes/gmsl_interface/gmsl_interface_node.cpp:2: *  Copyright (c) 2017, TierIV Inc.
src/drivers/awf_drivers/autoware_driveworks_interface/include/gmsl_interface.hpp:2: *  Copyright (c) 2018, TierIV Inc.
src/autoware/core_perception/points_preprocessor/nodes/compare_map_filter/compare_map_filter.cpp:2: *  Copyright (c) 2018, TierIV, Inc
src/autoware/core_planning/twist_gate/src/twist_gate.cpp:2: *  Copyright (c) 2017, Tier IV, Inc.
src/autoware/common/map_file/nodes/points_map_filter/points_map_filter.cpp:2: *  Copyright (c) 2018, TierIV, Inc
src/autoware/common/map_file/include/map_file/points_map_filter.h:2: *  Copyright (c) 2018, TierIV, Inc
src/autoware/common/map_file/nodes/points_map_filter/points_map_filter_node.cpp:2: *  Copyright (c) 2018, TierIV, Inc
src/autoware/utilities/mqtt_socket/nodes/mqtt_sender/mqtt_sender.cpp:2: *  Copyright (c) 2017, Tier IV, Inc.
src/autoware/utilities/mqtt_socket/nodes/mqtt_receiver/mqtt_receiver.cpp:2: *  Copyright (c) 2017, Tier IV, Inc.
src/autoware/utilities/vehicle_engage_panel/src/vehicle_engage_panel.h:2: * Copyright (c) 2018, TierIV Inc.
src/autoware/utilities/vehicle_engage_panel/src/vehicle_engage_panel.cpp:2: * Copyright (c) 2018, TierIV Inc.
src/autoware/visualization/state_panel/src/sim_object/flag.h:2: * Copyright (c) 2017, TierIV, Inc.
src/autoware/visualization/state_panel/src/sim_object/autoware_flag_tool.h:2: * Copyright (c) 2017, TierIV, Inc.
src/autoware/visualization/state_panel/src/sim_object/autoware_flag_tool.cpp:2: * Copyright (c) 2017, TierIV, Inc.
src/autoware/visualization/decision_maker_panel/src/decision_maker_panel.cpp:2: * Copyright (c) 2018, TierIV Inc.
```",kenji-miyake,90324.0,5360.0,5,0,0,0,0
Add NOTICE files to each repository,2022-03-12T06:29:44Z,1284821305,1166428404.0,comment,"For other repositories,
- autoware.core:
    - I won't add TIER IV's copyright yet because there is no code.
- autoware-documentation/autoware_individual_params:
    - I won't add TIER IV's copyright because there is no code.
- autoware_launch/sample_vehicle_launch/sample_sensor_kit_launch:
    - Use `2020`. (It is the timing we've published [our proposal](https://github.com/tier4/AutowareArchitectureProposal.proj/commit/aab8e6c01d7fcc9722c60abc76be1172e52a8759) and most code was modified from the proposal.)
- autoware-github-actions/autoware_common:
    - Use `2021` because I started implementing them in `2021`.

For the AWF's copyright notation, I'll use `2021` because we proposed Core/Universe in `2021`.",kenji-miyake,90324.0,5360.0,5,0,0,0,0
Add NOTICE files to each repository,2022-03-12T06:39:33Z,1284821305,1166428405.0,comment,"@xmfcx cc @mitsudome-r Could you confirm this?
We can wait for autowarefoundation/autoware.ai#2420 and https://github.com/autowarefoundation/autoware-documentation/pull/44 before merging `NOTICE` files.",kenji-miyake,90324.0,5360.0,5,0,0,0,0
Add NOTICE files to each repository,2022-03-13T05:44:47Z,1284821305,1166428407.0,comment,@xmfcx Thank you so much!,kenji-miyake,90324.0,5360.0,5,0,0,0,0
Add NOTICE files to each repository,2022-06-21T03:06:25Z,1284821305,1166428408.0,comment,Memo: The reference format we've used in https://github.com/autowarefoundation/autoware/pull/29#discussion_r792561655 was https://github.com/apache/solr/blob/0ba432371064586a900ae1e66b483f0685d4ef7f/NOTICE.txt.,kenji-miyake,90324.0,5360.0,5,0,0,0,0
The location of autoware_auto_msgs,2022-03-09T13:36:30Z,1284821301,1166428396.0,comment,@xmfcx @mitsudome-r @kenji-miyake Thoughts?,wep21,8768904.0,53.0,6,0,0,0,0
The location of autoware_auto_msgs,2022-03-09T13:39:07Z,1284821301,1166428397.0,reply,"@wep21 Let's keep them there for now. We will discuss the final messages structure as we finalize the design. And recreate the repository in `autowarefoundation` group with the updated messages.

And we will switch to using them instead in the universe repository.",xmfcx,8768904.0,53.0,6,0,0,0,0
The location of autoware_auto_msgs,2022-03-09T13:43:47Z,1284821301,1166428398.0,reply,"The messages won't be `autoware_auto_msgs` anymore, I think we should name them `autoware_msgs` and update https://index.ros.org/p/autoware_msgs/github-autoware-ai-messages/ for our use case, what do you think?

Since we will only update the `galactic` and later, old messages could stay the way they are.

`noetic` and older would belong to `autoware.ai` and `galactic` and later would belong to `autoware`

@JWhitleyWork any thoughts?",xmfcx,8768904.0,53.0,6,0,0,0,0
The location of autoware_auto_msgs,2022-03-09T14:33:42Z,1284821301,1166428399.0,reply,"I think so, too.
https://github.com/autowarefoundation/autoware.universe/issues/142
https://github.com/autowarefoundation/autoware/blob/47f8d0e15f9c327c1c45c9b726f9970e5edf2430/autoware.repos#L5

But I'll leave this issue to Fatih-san and Mitsudome-san.",kenji-miyake,8768904.0,53.0,6,0,0,0,0
The location of autoware_auto_msgs,2022-06-18T16:05:08Z,1284821301,1166428400.0,reply,"This pull request has been automatically marked as stale because it has not had recent activity.
",stale[bot],8768904.0,53.0,6,0,0,0,0
The location of autoware_auto_msgs,2022-06-19T01:24:01Z,1284821301,1166428401.0,reply,Move to https://github.com/autowarefoundation/autoware_msgs/issues/2.,kenji-miyake,8768904.0,53.0,6,0,0,0,0
Docker instructions for multiple terminal usage,2022-03-04T06:09:10Z,1284821295,1166428382.0,reply,"@angry-crab I think you can do it by this.

```sh
# Terminal 1
rocker --name autoware ghcr.io/autowarefoundation/autoware-universe:latest

# Terminal 2
docker exec -it autoware /bin/bash
```

![image](https://user-images.githubusercontent.com/31987104/156709267-c9d625c0-c81e-4d36-9583-a88d515565b2.png)
",kenji-miyake,2249112.0,1093.0,4,0,0,0,0
Docker instructions for multiple terminal usage,2022-03-04T06:14:23Z,1284821295,1166428387.0,reply,"You can send pull requests and update documents.

Around here?
- https://github.com/autowarefoundation/autoware/blob/main/docker/README.md
- https://github.com/autowarefoundation/autoware-documentation/pull/28

Or you can guide a new how-to guide page like this.
- https://github.com/autowarefoundation/autoware-documentation/pull/27",kenji-miyake,2249112.0,1093.0,4,0,0,0,0
Docker instructions for multiple terminal usage,2022-03-07T03:01:07Z,1284821295,1166428388.0,comment,"> You can send pull requests and update documents.
> 
> Around here?
> 
> * https://github.com/autowarefoundation/autoware/blob/main/docker/README.md
> * [docs: add tutorials autoware-documentation#28](https://github.com/autowarefoundation/autoware-documentation/pull/28)
> 
> Or you can guide a new how-to guide page like this.
> 
> * [docs: add advanced usage of colcon autoware-documentation#27](https://github.com/autowarefoundation/autoware-documentation/pull/27)

Thanks! I'll add it to the readme.",angry-crab,2249112.0,1093.0,4,0,0,0,0
Docker instructions for multiple terminal usage,2022-03-30T06:36:09Z,1284821295,1166428390.0,comment,Close since it it no longer needed.,angry-crab,2249112.0,1093.0,4,0,0,0,0
[Ansible] duplicated entries are written to nvidia-docker.list,2022-02-21T01:22:10Z,1284821288,1166428375.0,comment,"Probably this? https://github.com/ansible/ansible/issues/25286
Will try replacing `lineinfile` with `blockinfile` or `template`.

https://docs.ansible.com/ansible/latest/collections/ansible/builtin/lineinfile_module.html#ansible-collections-ansible-builtin-lineinfile-module
https://docs.ansible.com/ansible/latest/collections/ansible/builtin/blockinfile_module.html#ansible-collections-ansible-builtin-blockinfile-module
https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html
",kenji-miyake,28604.0,460.0,1,0,0,0,0
enable open cda workflow,2022-01-31T09:43:06Z,1284821282,1166428363.0,reply,"@xczhanjun What's `open cda`?
Could you write a bit more description so that everyone can understand?",kenji-miyake,5931.0,99.0,1,0,0,0,0
Consider how we should write copyright notices,2022-01-25T04:26:18Z,1284821275,1166428355.0,comment,"I think we can refer to the `iceoryx`'s way as well. It looks nice.
https://github.com/eclipse-iceoryx/iceoryx/blob/master/NOTICE.md
https://github.com/eclipse-iceoryx/iceoryx/blob/master/CONTRIBUTING.md#header

Also, OpenSSL looks good.
https://github.com/openssl/openssl/blob/master/CONTRIBUTING.md",kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-01-25T06:11:27Z,1284821275,1166428358.0,comment,"My proposal:

### For new files

Rule:

- Prepare `NOTICE` and use `Copyright yyyy The Autoware Contributors`.

Rationale:

- As LF says, We don't want to pay a lot of maintenance costs for updating copyright notations.

### For existing files

Rule:

- Accept the as-is style.
- We can change the copyright notation to `Copyright yyyy The Autoware Contributors`. if we can agree with the original authors to do so.

Rationale:

- Since we'll clean up the architecture for Autoware Core, we don't have to care about the existing Universe code so much.
- (I guess) We can't change the copyright notations without some agreements with the original authors.

### For all files

Rule:

- Add `SPDX-License-Identifier`.
- Will accept any other proposals in the future.

Rationale:

- SPDX is useful for automatically analyzing licenses.
- Since we are not legal professionals, there are a lot of things we don't know.",kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-01-25T06:16:32Z,1284821275,1166428360.0,comment,@xmfcx @kmiya What do think about this?,kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-01-25T08:03:31Z,1284821275,1166428361.0,comment,"> (I guess) We can't change the copyright notations without some agreements with the original authors.

For this, I think it's a good idea to agree with people who want to write their names to `NOTICE`, that ""if you want to write your name here, you have to remove your name from each Copyright notation or agree that the maintainers will remove them."", how about this?

(Seeing [here](https://github.com/llvm/llvm-project/blob/184591aeeb5a531f2315c3d7cddcd199c87ecb2c/libcxx/CREDITS.TXT), `CREDITS.TXT` might be the correct place to write contributors? :thinking: -> [This](https://infra.apache.org/licensing-howto.html#mod-notice) says `Copyright notifications which have been relocated, rather than removed, from source files must be preserved in NOTICE.` )
",kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-01-26T12:57:54Z,1284821275,1166428362.0,reply,"From looking at the Apache examples given, they all say ""Copyright yyyy The Apache Foundation"" rather than ""The Apache Contributors"".

Is there some reason why we cannot say `Copyright yyyy The Autoware Foundation` ?
",ghost,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-01-26T13:06:10Z,1284821275,1166428364.0,comment,"@LalithVipulananthan (Although I'm not sure I'm right...)

> From looking at the Apache examples given, they all say ""Copyright yyyy The Apache Foundation"" rather than ""The Apache Contributors"".

The ASF uses `Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.`.
https://www.apache.org/legal/src-headers.html

I guess why they do so is because they sign a CLA. (But I'm not sure.)

> Is there some reason why we cannot say Copyright yyyy The Autoware Foundation ?

I feel if we use `The Autoware Foundation` then it seems the AWF has the copyright.
But actually, since we don't use CLA and only use DCO instead, I think the copyright will remain with the original author, so `The Autoware Foundation` isn't correct.",kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-01-27T05:12:10Z,1284821275,1166428365.0,comment,"TSC members will talk about this issue.
https://gitlab.com/autowarefoundation/autoware-foundation/-/issues/204",kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-02-16T16:35:07Z,1284821275,1166428366.0,reply,"We have discussed in the TSC call.
@filiperinaldi will provide comments regarding the copyright notice. ",mitsudome-r,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-03-10T16:15:22Z,1284821275,1166428367.0,reply,"I spoke to one of our open source specialist and it seems what many projects do to be able to use the ""<Projects> and Contributors"" is to use a CONTRIBUTORS.md document where we simply add people's names as it goes.",filiperinaldi,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-03-11T01:33:53Z,1284821275,1166428369.0,comment,"@filiperinaldi Thank you for your information.
Did you recommend replacing the `NOTICE` file with `CONTRIBUTORS.md`? Just showing another way?",kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-03-11T15:27:30Z,1284821275,1166428371.0,comment,The PR has moved from autowarefoundation/autoware#29 to https://github.com/autowarefoundation/autoware-documentation/pull/44.,kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Consider how we should write copyright notices,2022-03-12T20:17:58Z,1284821275,1166428372.0,comment,"As https://github.com/autowarefoundation/autoware-documentation/pull/44 is merged, I'll close this issue.

However, everyone can reopen this and propose a change if necessary.",kenji-miyake,4034045.0,2545.0,12,0,0,0,0
Set up scenario testing CI,2022-02-03T14:56:39Z,1284821270,1166428354.0,reply,this is a great feature.,xczhanjun,12874434.0,1173003.0,4,0,0,0,0
Set up scenario testing CI,2022-04-04T15:15:50Z,1284821270,1166428356.0,reply,"This pull request has been automatically marked as stale because it has not had recent activity.
",stale[bot],12874434.0,1173003.0,4,0,0,0,0
Set up scenario testing CI,2022-06-18T16:05:09Z,1284821270,1166428357.0,reply,"This pull request has been automatically marked as stale because it has not had recent activity.
",stale[bot],12874434.0,1173003.0,4,0,0,0,0
Set up scenario testing CI,2022-06-19T01:20:30Z,1284821270,1166428359.0,comment,Closed by autowarefoundation/autoware#397.,kenji-miyake,12874434.0,1173003.0,4,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-01-19T05:36:41Z,1284821267,1166428321.0,reply,"- When do you confirm the commit history?
- What command do you?

Please give me a bit more concrete examples. :pray: ",kenji-miyake,3335045.0,203.0,9,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-01-19T06:28:29Z,1284821267,1166428323.0,comment,"When exploring in which commit the changes have been made to interested parts, if the commit message has many lines it makes us harder to find what we are looking for. 
Let's say someone made changes to the localization module, modified the NDT's optimization function, and I want to improve the functionality. 
If commit message was like

```
Improve NDT
* tmp 
* update
* remove a for loop
* ...
```

I can not obtain any information from there.
If every commit message was like this I cannot even find in which commit the changes I want to refer to have been made. 
",IshitaTakeshi,3335045.0,203.0,9,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-01-19T06:52:12Z,1284821267,1166428327.0,reply,"@IshitaTakeshi Again, what command do you use? And please paste it with the output like this.
Also, why do you not use `--oneline`?

```sh
❯ git log --oneline
920b874 (HEAD -> tier4/main, origin/tier4/proposal, origin/tier4/main, origin/HEAD, tier4/proposal) fix(dummy_perception): fix ns and topic (#242)
6f111e0 fix(behavior_path_planner): fix/frenet coordinate 3d (#230)
699b60e feat: use point cloud wraper in ring outlier filter (#780) (#241)
5f09a5d feat(simple_planning_simulator): add delay model of velocity and steering (#235)
f4993f3 fix(behavior_velocity_planner): fix before/after line of virtual_traffic_light (#228)
b0e4852 fix: interpolation (#791) (#218)
aa75dac fix: library path (#225)
b4eba36 fix: set control_mode false before autoware engage (#232)
784f10d fix: remove warning for compile error (#198)
52dc0f2 ci: update .yamllint.yaml (#229)
ed3253c chore: remove unnecessary depends (#227)
1657681 fix: order to create callback (#220)
```",kenji-miyake,3335045.0,203.0,9,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-01-19T07:08:55Z,1284821267,1166428329.0,comment,I used the ordinary `git log`. So then I'm going to use `git log --oneline`,IshitaTakeshi,3335045.0,203.0,9,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-01-19T07:10:21Z,1284821267,1166428331.0,comment,"This is the output. Too long to paste the whole though

```
tier4/proposal $git log 
commit 4cec60485bb376f9cc7d85448be782c2852f445a (HEAD -> tier4/proposal, origin/tier4/proposal, origin/HEAD)
Author: Kenji Miyake <31987104+kenji-miyake@users.noreply.github.com>
Date:   Tue Jan 18 16:17:52 2022 +0900

    feat: add ansible setup scripts (#8)
    
    * ci: add build CI
    
    Signed-off-by: Kenji Miyake <kenji.miyake@tier4.jp>
    
    * feat: add files for Ansible Galaxy
    
    Signed-off-by: Kenji Miyake <kenji.miyake@tier4.jp>
    
    * feat: copy ansible files from tier4's proposal
    
    Remove cache_valid_time
    
    Signed-off-by: Kenji Miyake <kenji.miyake@tier4.jp>
    
    v0.4.0
    
    Signed-off-by: mitsudome-r <ryohsuke.mitsudome@tier4.jp>
    
    copy setup
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    add ros2 ansible roles
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    ansible add ubuntu20 setup
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    ansible fix pacmod
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    temp disable cuda & tensorrt
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    ansible fix kvaser library repo
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    temporally comment out for unused modules
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    remove unused codes
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    Install osqp only once (#95)
    
    * update readme and fix osqp_vendor tag
    
    * Remove ansible osqp role
    
    fix: ansbile role
    
    Closes #140
    
    add ansible for cuda 11.1 & tensorrt 7.2.1 & cudnn 8.0.5
    
    Signed-off-by: Takamasa Horibe <horibe.takamasa@gmail.com>
    
    add script for install livox sdk
    
    Signed-off-by: kosuke murakami <kosuke.murakami@tier4.jp>
    
```",IshitaTakeshi,3335045.0,203.0,9,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-01-19T07:50:47Z,1284821267,1166428333.0,reply,"@IshitaTakeshi I see, thank you!

Then, how about using these useful tools? It helps you to explore the commit history.
- https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens
- https://marketplace.visualstudio.com/items?itemName=mhutchie.git-graph

Although these are for VSCode, there might be tools for your IDE.",kenji-miyake,3335045.0,203.0,9,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-01-19T09:43:11Z,1284821267,1166428336.0,comment,"Yeah but... It's like messing a library by ourselves and exploring a book from there. If the library is clean from the beginning we don't need to do so. And it can be realized by writing just two or three phrases when making a commit 
Why making unnecessary jobs by messing our rooms by ourselves... ",IshitaTakeshi,3335045.0,203.0,9,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-02-02T13:45:04Z,1284821267,1166428337.0,reply,"@IshitaTakeshi Could you write clear acceptance criteria for this issue, please?",kenji-miyake,3335045.0,203.0,9,0,0,0,0
[Documentation] Commit message guidelines for cleaner commit history,2022-02-26T19:57:23Z,1284821267,1166428338.0,reply,"I'll close this because there is no response and I think it's a problem of tool usage.

We use https://www.conventionalcommits.org/en/v1.0.0/ and `Squash merge` now. I'll write guideline documents about that and it's tracked in https://github.com/autowarefoundation/autoware-documentation/issues/6.",kenji-miyake,3335045.0,203.0,9,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-18T09:54:29Z,1284821261,1166428307.0,reply,"@IshitaTakeshi Please describe for what reasons you need `kvaser-interface`.
Also, is it impossible to replace it with https://github.com/autowarefoundation/ros2_socketcan?

It seems Kvaser devices supports SocketCAN.
https://www.kvaser.com/socketcan-support-for-kvaser-devices-updated/",kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-18T10:10:40Z,1284821261,1166428309.0,reply,"We have never used `ros2_socketcan` on autonomostuff vehicle, so we have to test it on the real vehicle before migrating to `ros2_socketcan`. ",wep21,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-18T10:20:16Z,1284821261,1166428311.0,reply,"Okay, then I think we should test it. If it won't work we'll import the role from here.
https://github.com/tier4/AutowareArchitectureProposal.proj/blob/474da436880f93bd59d87107bd9d83254b0cd9b3/ansible/roles/pacmod/tasks/kvaser_library.yml",kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-18T10:41:46Z,1284821261,1166428313.0,reply,"Also, we have to do a trick to use kvaser usb as socketcan interface.
```
sudo modprobe kvaser_usb
<- unplug and plug kvaser usb here
sudo ip link set can0 up type can bitrate 50000
```",wep21,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-18T10:46:29Z,1284821261,1166428315.0,reply,Thank you. I think it can be supported by some setup scripts for real vehicles.,kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-19T00:26:37Z,1284821261,1166428317.0,comment,"This is the reason to add kvaser-interface to the requirements. When launching the logging simulator it says that kvaser_interface cannot be found.

```
root@87a3663a4a81:/autoware# source install/setup.bash 
root@87a3663a4a81:/autoware# ros2 launch tier4_autoware_launch logging_simulator.launch.xml sensor_model:=aip_xx1 map_path:=/dataset/kashiwanoha/ vehicle_model:=lexus
[INFO] [launch]: All log files can be found below /root/.ros/log/2022-01-19-09-21-13-992999-87a3663a4a81-60
[INFO] [launch]: Default logging verbosity is set to INFO
Task exception was never retrieved
future: <Task finished name='Task-2' coro=<LaunchService._process_one_event() done, defined at /opt/ros/galactic/lib/python3.8/site-packages/launch/launch_service.py:226> exception=PackageNotFoundError(""package 'kvaser_interface' not found,
```",IshitaTakeshi,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-19T01:24:10Z,1284821261,1166428318.0,reply,"Why do you need `kvaser-interface` for the launch file?
Do you use a physical CAN in the simulation?",kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-19T03:54:21Z,1284821261,1166428319.0,comment,"Not sure so I grep-ed in the workspace directory and got the following

```
# find . -type f | xargs grep kvaser_interface
./src/vehicle/lexus_launch/launch/pacmod3.launch.py:            package='kvaser_interface',
./install/lexus_description/share/lexus_description/launch/pacmod3.launch.py:            package='kvaser_interface',
```

Apparently pacmod3 requires it. ",IshitaTakeshi,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-19T05:27:19Z,1284821261,1166428320.0,reply,"I know it has the dependency, but my question is, why do you have to launch the node in the simulation?",kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-19T06:06:46Z,1284821261,1166428322.0,comment,"What node do you refer to?

My current task is to improve the localization accuracy and availability so basically I don't need to launch all the nodes under the logging simulator, but for me, who doesn't know that much about the Autoware architecture, it is easier to launch the logging simulator than disabling unnecessary nodes. 

",IshitaTakeshi,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-19T06:22:28Z,1284821261,1166428324.0,reply,"> What node do you refer to?

Probably this?
https://github.com/tier4/lexus_description.iv/blob/4a3a06e297f85a737d2b5879b508843b2998038a/launch/pacmod3_with_kvaser-node-launch.py

> but for me, who doesn't know that much about the Autoware architecture,

I believe it's better that you'll get familiar with Autoware and do appropriate handling!
I guess, for example, we need to add an option of whether to launch `kvaser-interface`, to [this file](https://github.com/tier4/lexus_description.iv/blob/4a3a06e297f85a737d2b5879b508843b2998038a/launch/vehicle_interface.launch.xml).",kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-19T06:42:16Z,1284821261,1166428326.0,comment,"Okay, but at least as an OSS it should be much better the logging simulator always works fine so when merging the Dockerfile to the default branch we should disable the node depending on `kvaser-interface` (or install `kvaser-interface`), otherwise users will regard autoware as just useless. ",IshitaTakeshi,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-01-19T06:55:57Z,1284821261,1166428328.0,reply,"@IshitaTakeshi Regarding that, I believe we should consider replacing `kvaser-interface` by `ros2_socketcan`.
https://github.com/autowarefoundation/autoware.ai/issues/2417

Please understand that adding everything isn't always correct.",kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-02-02T13:48:58Z,1284821261,1166428330.0,reply,"Acceptance Criteria:

- [ ] Consider replacing `kvaser-interface` by `ros2_socketcan`.
We need to evaluate `ros2_socketcan` with Kvaser devices to do that.

Or,
- [ ] Consider removing `kvaser-interface` from `logging_simulator.launch.xml`.
Essentially, no hardware is required for the simulation.",kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-02-03T01:55:39Z,1284821261,1166428332.0,reply,"> Acceptance Criteria:
> 
> * [ ]  Consider replacing `kvaser-interface` by `ros2_socketcan`.
>   We need to evaluate `ros2_socketcan` with Kvaser devices to do that.
> 
> Or,
> 
> * [ ]  Consider removing `kvaser-interface` from `logging_simulator.launch.xml`.
>   Essentially, no hardware is required for the simulation.
Maybe we should remove `kvaser-interface` from `logging_simulator.launch.xml` and using ros2_socketcan. We can setup a fake socket can interface when doing simulation.",xczhanjun,3406573.0,998.0,16,0,0,0,0
[Docker] Autoware.universe requires kvaser-interface,2022-02-26T19:54:04Z,1284821261,1166428335.0,reply,"Since I've created https://github.com/autowarefoundation/sample_vehicle_launch that doesn't depend on `kvaser` or `pacmod`, I'll close this.",kenji-miyake,3406573.0,998.0,16,0,0,0,0
[Docker] lidar_centerpoint executable could not be built without LibTorch,2022-01-18T09:12:06Z,1284821252,1166428304.0,reply,"It's intended. Since the `libtorch` role only supports `x86` and uses TIER IV's Google Drive, I decided not to include it in this repository.
https://github.com/tier4/AutowareArchitectureProposal.proj/blob/474da436880f93bd59d87107bd9d83254b0cd9b3/ansible/roles/libtorch/tasks/main.yml#L5

Please install it from [TIER IV's proposal repository](https://github.com/tier4/AutowareArchitectureProposal.proj).

Regarding the future plan, TIER IV will try to use `TensorRT` and remove `libtorch` dependency from `lidar_centerpoint`.",kenji-miyake,543.0,543.0,1,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-01-18T09:14:34Z,1284821247,1166428289.0,reply,"@IshitaTakeshi We prepare two images `devel` and `prebuilt`. I think using `devel` image can solve your problem. Is it okay for you?

https://github.com/autowarefoundation/autoware/tree/add-docker/docker#development-image",kenji-miyake,1364260.0,2672.0,9,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-01-18T09:39:50Z,1284821247,1166428291.0,comment,For the development I think that the mount procedure should be written in README or we should add a script to realize it.,IshitaTakeshi,1364260.0,2672.0,9,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-01-18T09:52:22Z,1284821247,1166428293.0,reply,"Yes, I'll write it later. Please note that this repository is still under construction.
Or it's great if you will send a PR to update README.",kenji-miyake,1364260.0,2672.0,9,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-01-19T04:40:11Z,1284821247,1166428295.0,comment,"Still there are other updates to the docker environment and I have my personal tasks so let me show my launch command this time. 

```
rocker \
    --nvidia \
    --x11 \
    --volume $(pwd)/dataset:/dataset \
    --volume $(realpath src):/autoware \
    -- ghcr.io/autowarefoundation/autoware-universe:latest-prebuilt
```",IshitaTakeshi,1364260.0,2672.0,9,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-01-21T06:03:54Z,1284821247,1166428297.0,reply,"@IshitaTakeshi I updated the document, could you review it?
https://github.com/autowarefoundation/autoware/pull/14
https://github.com/autowarefoundation/autoware/pull/14/commits/6958e38ff15a2cea20f205d384a47c3574f75052",kenji-miyake,1364260.0,2672.0,9,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-01-21T06:17:08Z,1284821247,1166428298.0,comment,Commands look good. Can I overwrite the English text part?,IshitaTakeshi,1364260.0,2672.0,9,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-01-21T06:38:56Z,1284821247,1166428300.0,reply,"@IshitaTakeshi Actually please refrain from that, please propose changes instead. :pray: 
https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/reviewing-changes-in-pull-requests/reviewing-proposed-changes-in-a-pull-request",kenji-miyake,1364260.0,2672.0,9,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-02-02T13:45:39Z,1284821247,1166428301.0,reply,@IshitaTakeshi Is it okay for you to close this issue?,kenji-miyake,1364260.0,2672.0,9,0,0,0,0
[Docker] Edit files on host and execute on a container ,2022-02-03T03:27:42Z,1284821247,1166428302.0,comment,Yes. Thank you for commiting ,IshitaTakeshi,1364260.0,2672.0,9,0,0,0,0
Fix ARM build of scenario_simulator,2022-04-14T11:51:00Z,1284821227,1166428247.0,reply,"This pull request has been automatically marked as stale because it has not had recent activity.
",stale[bot],56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2022-05-26T09:46:22Z,1284821227,1166428249.0,reply,"@kenji-miyake what do you think of having an `embree_vendor` package and have `scenario_simulator` depend on it? If `libembree-dev` is installed on the system, that'll be used, and if not, build it.",esteve,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2022-05-26T12:05:59Z,1284821227,1166428251.0,comment,@esteve I think it's great! @hakuturu583 What do you think?,kenji-miyake,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2022-05-26T15:26:34Z,1284821227,1166428254.0,reply,"I arleady developed embree_vendor package, but it takes a lot of time.

https://github.com/OUXT-Polaris/embree_vendor",hakuturu583,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2022-05-26T15:27:31Z,1284821227,1166428256.0,reply,"And also, I have not tested this vendor package on arm CPU.",hakuturu583,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2023-09-27T10:16:52Z,1284821227,1737114533.0,reply,"Hi, any updates on this issue ?

@hakuturu583 Can we use `embree_vendor` package on arm CPU ?",oguzkaganozt,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2023-10-02T06:41:00Z,1284821227,1742474105.0,reply,"> @hakuturu583 Can we use embree_vendor package on arm CPU ?

Yes, I tested on qemu and it works.",hakuturu583,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2023-10-04T16:21:52Z,1284821227,1747242959.0,reply,"Hi @hakuturu583,
 I've tried with Scenario Simulator **master** branch and [embree_vendor](https://github.com/OUXT-Polaris/embree_vendor). It uses embree version 4.2.0 and when I try to do:
 `colcon build --cmake-args -DCMAKE_BUILD_TYPE=Release --packages-up-to simple_sensor_simulator`
 
I got following error on compilation:
`error: ‘RTCIntersectContext’ has not been declared`

I also checked with the original Embree version 4.0 changelog and it says:
`RTCIntersectContext is renamed to RTCRayQuery context and most members moved to
    new RTCIntersectArguments and RTCOccludedArguments structures.`
   
So it appears that embree version 4.x is not fit for Scenario simulator. How should I proceed do you have any suggestions ? 

Thanks in advance.",oguzkaganozt,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2023-10-05T13:51:42Z,1284821227,1748945123.0,reply,"I just checked installed embree apt package in my amd64 platform. It looks like I have version 3.12.2 installed.
May be you could try changing [this line](https://github.com/OUXT-Polaris/embree_vendor/blob/7cd96dd0a938e93a4bdc4f09089ef070f0a407ad/CMakeLists.txt#L32C13-L32C19) to `v3.12.2`.",mitsudome-r,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2023-10-05T14:54:07Z,1284821227,1749072458.0,reply,I tried building with `v3.12.2` and it requires libTBB version `2021.1.1` and is incompatible with `2021.5.0` that we have on Ubuntu22/arm64. Also tried version `v3.13.5` and it failed with ` error: unrecognized command-line option ‘-msse2’` seems like the flag incompatibility with arm64.,oguzkaganozt,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2023-10-18T20:04:53Z,1284821227,1769238920.0,reply,"I was able to build on arm with the following workaround:
1. Use Embree 3.13.5 and cherry-pick https://github.com/embree/embree/commit/82ca6b5ccb7abe0403a658a0e079926478f04cb1 as mentioned in [this issue](https://github.com/embree/embree/issues/383#issuecomment-1453490760). I've created a fork of embree_vendor with the fix so you can use the following:
```
cd autoware/src/universe/external
git clone -b v3.13.5_arm https://github.com/mitsudome-r/embree_vendor
```
2. Modify simple_sensor_simulator's dependency in package.xml to use embree_vendor instead of embree.
3. Even with the above fix, I still had errors from Eigen in openscenario_visualization package related to this [issue](https://gitlab.com/libeigen/eigen/-/issues/2326). I added this warning as exception in the compile option as a quick fix.

For 2 and 3, you can checkout my fork:
```
cd autoware/src/simulator/scenario_simulator
git remote add https://github.com/mitsudome-r/scenario_simulator_v2
git fetch mitsudome-r
git checkout arm
```
",mitsudome-r,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2023-10-19T13:52:24Z,1284821227,1771036892.0,reply,Related Issue: https://github.com/tier4/scenario_simulator_v2/issues/1094,mitsudome-r,56295164.0,7522860.0,13,0,0,0,0
Fix ARM build of scenario_simulator,2023-10-19T16:26:34Z,1284821227,1771330031.0,reply,"> I was able to build on arm with the following workaround:
> 
> 1. Use Embree 3.13.5 and cherry-pick [embree/embree@82ca6b5](https://github.com/embree/embree/commit/82ca6b5ccb7abe0403a658a0e079926478f04cb1) as mentioned in [this issue](https://github.com/embree/embree/issues/383#issuecomment-1453490760). I've created a fork of embree_vendor with the fix so you can use the following:
> 
> ```
> cd autoware/src/universe/external
> git clone -b v3.13.5_arm https://github.com/mitsudome-r/embree_vendor
> ```
> 
> 2. Modify simple_sensor_simulator's dependency in package.xml to use embree_vendor instead of embree.
> 3. Even with the above fix, I still had errors from Eigen in openscenario_visualization package related to this [issue](https://gitlab.com/libeigen/eigen/-/issues/2326). I added this warning as exception in the compile option as a quick fix.
> 
> For 2 and 3, you can checkout my fork:
> 
> ```
> cd autoware/src/simulator/scenario_simulator
> git remote add https://github.com/mitsudome-r/scenario_simulator_v2
> git fetch mitsudome-r
> git checkout arm
> ```

Thanks @mitsudome-r that solved the issue.",oguzkaganozt,56295164.0,7522860.0,13,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-14T13:32:47Z,1284821222,1166428243.0,comment,@xmfcx Have you said that you'll change the AWS machine settings in the last meeting? I don't remember well.,kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-14T13:40:52Z,1284821222,1166428244.0,reply,"> @xmfcx Have you said that you'll change the AWS machine settings in the last meeting? I don't remember well.

Yes, I'll look into it right away!",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-14T18:06:28Z,1284821222,1166428246.0,reply,"@kenji-miyake 
Here is the report:

[autowarefoundation](https://github.com/autowarefoundation) organization has a [GitHub Actions Runner](https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners) registered with a name `AutowareFoundationGithubActionsRunner`.

This runner runs on an AWS `t4g.xlarge` instance. [Amazon EC2 T4g instances are powered by Arm-based AWS Graviton2 processors.](https://aws.amazon.com/ec2/instance-types/t4/)

It has 4 vCPUs and 16GiB RAM.

This binary was installed on it: https://github.com/actions/runner/releases/download/v2.276.1/actions-runner-linux-arm64-2.276.1.tar.gz

```bash
ubuntu@ip-192-168-22-5:~$ df -h /
Filesystem      Size  Used Avail Use% Mounted on
/dev/root        29G   25G  4.4G  85% /
```

<details>
  <summary>Having fun with ncdu inside the runner</summary>
  
```
ncdu 1.14.1 ~ Use the arrow keys to navigate, press ? for help
--- / -------------------------------------------------------------------------------------------------------------------
   17.4 GiB [##########] /var
    4.5 GiB [##        ] /usr
    2.0 GiB [#         ] /snap
    1.9 GiB [#         ] /home
  273.0 MiB [          ] /opt
  191.8 MiB [          ] /boot
   69.0 MiB [          ] /root
    5.9 MiB [          ] /etc
    1.0 MiB [          ] /run
  600.0 KiB [          ] /tmp
...
```

```
--- /var ----------------------------------------------------------------------------------------------------------------
                         /..
   16.5 GiB [##########] /lib
  838.5 MiB [          ] /log
   91.6 MiB [          ] /cache
    3.8 MiB [          ] /backups
   92.0 KiB [          ] /snap
   32.0 KiB [          ] /tmp
   28.0 KiB [          ] /spool
e   4.0 KiB [          ] /opt
...
```

```
--- /var/lib ------------------------------------------------------------------------------------------------------------
                         /..
   15.4 GiB [##########] /docker
  929.7 MiB [          ] /snapd
  122.9 MiB [          ] /apt
   71.5 MiB [          ] /dpkg
    2.8 MiB [          ] /command-not-found
  872.0 KiB [          ] /fwupd
  608.0 KiB [          ] /usbutils
  532.0 KiB [          ] /systemd
...
```

```
--- /var/lib/docker/overlay2 --------------------------------------------------------------------------------------------
                         /..
    2.0 GiB [##########] /3f789e1ccb84eced273bbd5ec673d26bf2ba73badea2366fb5ce7c1e455deb3c
    1.7 GiB [########  ] /860d068134bb56e762666ace5f4f4e8776a54d2a4bd4dadaa213903dd36e1e8a
    1.6 GiB [#######   ] /961ad94a1a2d8bde97c3e7a4fd920b32dea466dee7a2e798cbd0cd9de3b9579c
    1.2 GiB [######    ] /oz9h7z6ksun9pzg6s52do34bs
    1.2 GiB [######    ] /igc3ivk7fko8yv0dy5f3ix6es
    1.1 GiB [#####     ] /acf011033a08512ba500bb9cb491c8fe2b85800fd51f5940688dacaae258b347
    1.0 GiB [####      ] /k39z3vtovy72t3rd9kul7ylts
    1.0 GiB [####      ] /ocnfwy30dy9qn4iv197j3wx32
  971.0 MiB [####      ] /ozlaq5qbqyl4vrp20vymjja8v
  764.8 MiB [###       ] /mk3870wqhylwvxem7ortmtvfm
  555.1 MiB [##        ] /75e02708a769eec5b19605086f65f8db2bad1cd2cc855134b7d7a5228e33f8ab
  379.1 MiB [#         ] /b466a752974568564c50ef30c00e5aa5c481241400098aec28cb965b4367d66e
  360.7 MiB [#         ] /7df0aabea828669c65dfc3d6c5fa1b2512eeb4beb2d7b985043a7fca7c5a90f9
  360.6 MiB [#         ] /19f37636febdd3ad4e677c761f54a18bcc406ef569a56c915a462b492a5b00d9
  170.9 MiB [          ] /8bfa3d5126374b0ff2bf1b5dbbd2b9b2c7250c85f8b0110c4e2cab8c3aee7acc
  170.9 MiB [          ] /c3ca31b9a7ce3931b2f9887e59374a97f5261c794a8f3c2c5eb0d091f30ed8e3
  121.5 MiB [          ] /28e5f0a7ef59844e7d1303e8207c0fe4f1d6b999e25ef0457e63d5634c2ee0d2
  108.3 MiB [          ] /b3e692e697ed02bc6c1f220ef9f222e6fd31f3b703f33787ea236671249ebdbe
  103.1 MiB [          ] /669a56810f2f0b641ee12f378861f98bb2e95a3feddeed03fff75a219e234ef8
   71.1 MiB [          ] /2698239224b14e3b7c4b8ae829c555b9baa308379f372d0834fe61b0b723d3f6
   71.1 MiB [          ] /98f54927abe28c6547dc7d3dc0796adfb3f2a8605b3c95fb9dbcf552f32cb071
   71.1 MiB [          ] /df580563836e90306194f98a714a4a3fa843731b35da05fe125d55e6ea714c4e
   71.1 MiB [          ] /03e58f58a62ce5c1b373555c209ad5484763751c6acad9363c85762e12d9116f
   67.2 MiB [          ] /d16b246099269bcd9dc49a24bd702f8a390070c47ddf063dd0a6b722e94f62cb
...
```
</details>

Then I ran:
```

ubuntu@ip-192-168-22-5:~$ docker images
REPOSITORY                   TAG                       IMAGE ID       CREATED        SIZE
ros                          galactic                  775c4b4329a0   7 days ago     625MB
ubuntu                       20.04                     9f4877540c73   7 days ago     65.6MB
autoware/model-zoo-tvm-cli   bleedingedge              2c1d92d7cf06   6 weeks ago    3.32GB
autoware/model-zoo-tvm-cli   bleedingedge-arm64        2c1d92d7cf06   6 weeks ago    3.32GB
autoware/model-zoo-tvm-cli   bleedingedge-cuda         051076320a77   6 weeks ago    7.1GB
autoware/model-zoo-tvm-cli   bleedingedge-cuda-arm64   051076320a77   6 weeks ago    7.1GB
moby/buildkit                buildx-stable-1           cb9b18fdb708   8 weeks ago    134MB
ros                          <none>                    d1dc7d553def   3 months ago   624MB
autoware/model-zoo-tvm-cli   <none>                    23e209b2f626   3 months ago   4GB

```

These docker images are occupying a lot of space.

They are generated by the runner probably, there are nothing related to them in the .bash_history file.

Then I've proceed to clean them a bit.

<details>
  <summary>Cleaning logs</summary>

```bash
ubuntu@ip-192-168-22-5:~$ docker image prune
WARNING! This will remove all dangling images.
Are you sure you want to continue? [y/N] y
Deleted Images:
untagged: autoware/model-zoo-tvm-cli@sha256:a7831a40332f75ae98fb62a04f75ad2db6a6fbf8fafc409d0f69e95abc41dcb9
deleted: sha256:23e209b2f626500be6d8854fd1010229fca6f51876db4c63d3fd4851a536b7c0
deleted: sha256:dbafe75a3ee1ece980197b9886402ce3e1524b29bfbc1963690305488f81a0d7
deleted: sha256:7619c374c847a8893d3c85d6dca6202a90beb171237b3451ee0b5181c5a59b75
deleted: sha256:77ff28323bd0da84f6229138b3307e1ecfde62ebde42918feb7a8b52b95d5122
deleted: sha256:77fee4372c0621a932345c0288736a71ea21caf9a383c29aa017d137e2e07bc5
deleted: sha256:08e85464003280159ce7fd6cf708da6b67223505ff318307928375684e4dee3c
deleted: sha256:df4dcf3f56b841655e03092b79a66b996bbb9335b4151f55e9a1a73c10f18d71
deleted: sha256:1f4e146407f3bb98c8b661348e00af043449d5ad10242ccedde70d711badabbb
deleted: sha256:35acadea3b5a2a96f4b2f4c74ed894b3ba914a3f4d5d3c7a229791494e49bedc
deleted: sha256:7b8728eb6a07380fce7ee9581ed43d58d7f0f3250c50a44c38c7982536236e28
deleted: sha256:c9115e738038f017bc9cbaea0a25b42921263d79199b1133b964633162b0d843
deleted: sha256:1093f8b99677a049c1627342e2632c7d060f4cd058fec56a22c52ac358887570
deleted: sha256:bed5eaa83dce8f654fd931ac6b1c4de67fef4482b3270a5d98ae901a4b48d35e
deleted: sha256:4378b6ba3aa966c9d3d45efb1c97a87a79e2ccae62acf898e20ab7712b254726
deleted: sha256:cf1297c9d105cb8049c0f02f12a3c5a1c7c679f30a1de64c5f97b4c006cdc564
deleted: sha256:7a0d5c3393a6fb45b7436dee209a214e1d7d3497b4ed11c963c0de19c2173b3d
deleted: sha256:68d7ba65f4836161cd7e568374ad6eb90a1fbdbd807691f47b55dfd85222910e
deleted: sha256:942b063c301eb3a3581299227847df70c896991a18216541c4bafb41a4263ffb
untagged: ros@sha256:65beaaee344167f62b4ff87373d84faa27e1ea73b5de15f1a59646bea87de4d2
deleted: sha256:d1dc7d553defc3476d6d036001a2ebef1c69198b71864342ba12919988328c4a
deleted: sha256:fcb03701ef491fd30f750ea7c0697219e7efb79499394da89af966fb7f973991
deleted: sha256:108a51d95fa73e3c488d196b6c0e05e502746f88fd19a9f01f417044673f5e89
deleted: sha256:30dfd34b65d0c2cdf59cce36ff380adf6e01d41441d39824cea4b1407e060169
deleted: sha256:c23e51d5095f6c9180648792b4036e4538b51eeee815628885a23ca76ed04195
deleted: sha256:77f7733c23042efa6d253941dc786e0fe7b641e7622d1ec9b215e9ef8abcd743
deleted: sha256:e52184f9949df47092392cb61725debef580d6d20cb86518da7a98b946967c8a
deleted: sha256:19553373bc3b429fbfedb19ee24f9335856b7f0ed8beea7baaed31767a784bb9
deleted: sha256:d4ebf66ca37317b8fcd9ca3450e2707674b947c5f1751f62894e6869c0120343
deleted: sha256:0d590595a73a77a32952a1ac40fc91c8a0c7b965059e22f89deaac010c951d4b
deleted: sha256:12ebadd02095a97092b2327a681c7beffc761f73c544e077967f88f8388807f4

Total reclaimed space: 4.557GB

ubuntu@ip-192-168-22-5:~$ docker images
REPOSITORY                   TAG                       IMAGE ID       CREATED       SIZE
ros                          galactic                  775c4b4329a0   7 days ago    625MB
ubuntu                       20.04                     9f4877540c73   7 days ago    65.6MB
autoware/model-zoo-tvm-cli   bleedingedge              2c1d92d7cf06   6 weeks ago   3.32GB
autoware/model-zoo-tvm-cli   bleedingedge-arm64        2c1d92d7cf06   6 weeks ago   3.32GB
autoware/model-zoo-tvm-cli   bleedingedge-cuda         051076320a77   6 weeks ago   7.1GB
autoware/model-zoo-tvm-cli   bleedingedge-cuda-arm64   051076320a77   6 weeks ago   7.1GB
moby/buildkit                buildx-stable-1           cb9b18fdb708   8 weeks ago   134MB

ubuntu@ip-192-168-22-5:~$ df -h /
Filesystem      Size  Used Avail Use% Mounted on
/dev/root        29G   20G  9.0G  70% /

```
</details>

Now we have 9.0G space left. I could remove these images too but they would get redownloaded anyway probably.

We should probably look into https://docs.github.com/en/actions/hosting-your-own-runners/autoscaling-with-self-hosted-runners for autoscaling since right now all arm jobs go into this specific runner.",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-14T18:15:10Z,1284821222,1166428250.0,reply,"Also for x86_64 jobs we are using [GitHub-hosted runners](https://docs.github.com/en/actions/using-github-hosted-runners/about-github-hosted-runners):

![chrome_2022-01-14_21-12-13](https://user-images.githubusercontent.com/10751153/149564595-be89d035-18b0-478c-ae7b-1ae14b96fe9a.png)

Hardware specification for Windows and Linux virtual machines:

2-core CPU
7 GB of RAM memory
14 GB of SSD disk space
 
And I think these machines probably won't be enough for building the Autoware and we will need to look into self-hosted ephemeral runners for these too.",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-15T04:44:41Z,1284821222,1166428253.0,comment,"@xmfcx Thank you for your detailed report!

> Now we have 9.0G space left. I could remove these images too but they would get redownloaded anyway probably.

Hmm, it's too small... :cry: 
I want at least 30GB of free space, is it possible to extend the storage size of the VM?

> Hardware specification for Windows and Linux virtual machines:

Regarding GitHub-hosted runners, I guess it's minimum requirements.
The actual storage space can be seen [here](https://github.com/autowarefoundation/autoware/runs/4777125097?check_suite_focus=true#step:3:23).

> And I think these machines probably won't be enough for building the Autoware and we will need to look into self-hosted ephemeral runners for these too.

Anyway, if there's no problem with the cost, it's nice.",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-15T11:32:41Z,1284821222,1166428255.0,reply,"> @xmfcx Thank you for your detailed report!
> 
> > Now we have 9.0G space left. I could remove these images too but they would get redownloaded anyway probably.
> 
> Hmm, it's too small... 😢 I want at least 30GB of free space, is it possible to extend the storage size of the VM?

@kenji-miyake I've increased the storage by 30GB, now we have 39GB empty space.

```bash
ubuntu@ip-192-168-22-5:~$ df -h
Filesystem       Size  Used Avail Use% Mounted on
/dev/root         58G   20G   39G  35% /
```",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-18T07:38:32Z,1284821222,1166428259.0,comment,"I confirmed that the CI is fixed in https://github.com/autowarefoundation/autoware/pull/8#issuecomment-1015132292.

Thank you @xmfcx !",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-18T17:55:27Z,1284821222,1166428263.0,comment,"@xmfcx I'm sorry but it seems we need a bit more space. :cry: 
https://github.com/autowarefoundation/autoware/actions/runs/1712036308

> You are running out of disk space. The runner will stop working when the machine runs out of disk space. Free space left: 60 MB

Seeing this result, we need 55GB+ free space? :thinking: 
https://github.com/autowarefoundation/autoware/actions/runs/1683139813
https://github.com/autowarefoundation/autoware/runs/4777125097?check_suite_focus=true#step:3:1110

> docker-build-and-push-amd64
You are running out of disk space. The runner will stop working when the machine runs out of disk space. Free space left: 36 MB

> Filesystem      Size  Used Avail Use% Mounted on
/dev/root        84G   30G   55G  35% /

I'll investigate more.",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T02:18:33Z,1284821222,1166428272.0,comment,"I measured the storage usage before/after building Autoware Docker images. It used `44GB` for `amd64`.
https://github.com/autowarefoundation/autoware/runs/4857291024?check_suite_focus=true

![image](https://user-images.githubusercontent.com/31987104/150050900-c916e293-9a2a-412b-9d3f-1841f86a6b53.png)
",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T02:24:45Z,1284821222,1166428273.0,comment,"@xmfcx Is it possible to add more 10~20GB space...?
Or if we drop building `prebuilt` images, probably the current space is enough.",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T03:05:23Z,1284821222,1166428276.0,reply,"> @xmfcx Is it possible to add more 10~20GB space...? Or if we drop building `prebuilt` images, probably the current space is enough.

We could add but I think we should first try to reduce the space we are using. This is ok for single runner but for parallel runners it'll cost too much, not scalable. In autoware.auto 30gb total space for entire machine was enough. ",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T03:51:34Z,1284821222,1166428277.0,comment,"> We could add but I think we should first try to reduce the space we are using.

What do you think we can specifically do in order to save the space?

> In autoware.auto 30gb total space for entire machine was enough.

Yes, but the current `autoware.universe` depends on CUDA, which uses additional 10GB+. :cry: ",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T07:54:20Z,1284821222,1166428279.0,reply,"We won't use cuda on CI, we should make it optional. ",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T07:57:29Z,1284821222,1166428280.0,comment,"If so, we can't check the build of some perception modules in `autoware.universe`, is that okay?
Also, could you tell me why do you think making it optional is good?",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T08:01:36Z,1284821222,1166428281.0,reply,"> If so, we can't check the build of some perception modules in `autoware.universe`, is that okay? Also, could you tell me why do you think making it optional is good?

The CI machines don't have Nvidia gpus and CUDA only works on nvidia gpus so we couldn't check them anyway.

Instances with gpus are much more expensive, we could set them to be checked with lower frequency if needed. ",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T08:04:28Z,1284821222,1166428282.0,comment,"@xmfcx 
> The CI machines don't have Nvidia gpus and CUDA only works on nvidia gpus so we couldn't check them anyway.

Yes, we can't check the runtime behavior, but I think we can check the build.

> Instances with gpus are much more expensive, we could set them to be checked with lower frequency if needed.

We don't need GPUs.",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T08:41:29Z,1284821222,1166428283.0,comment,"@xmfcx So considering that, can we increase the space or cannot in any case?",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T14:34:40Z,1284821222,1166428284.0,reply,"@kenji-miyake right now it has 60GB size, will increase it to 80GB. Since it is only a single machine, it shouldn't be a problem hopefully.",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T14:43:19Z,1284821222,1166428285.0,reply,"@kenji-miyake Increased it, current configuration:
```bash
Filesystem       Size  Used Avail Use% Mounted on
/dev/root         78G   46G   33G  59% /
```",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T15:25:56Z,1284821222,1166428286.0,comment,"Thank you! But it seems there is another issue... :cry: I'll investigate and fix it.
https://github.com/autowarefoundation/autoware/actions/runs/1714127510",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T16:01:16Z,1284821222,1166428287.0,comment,"```
root@ip-192-168-22-5:/var/lib/docker# du -sh *
1.6M    buildkit
244K    containers
26M     image
76K     network
24G     overlay2
16K     plugins
4.0K    runtimes
4.0K    swarm
6.8G    tmp
4.0K    trust
38G     volumes
```",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T16:03:12Z,1284821222,1166428290.0,reply,"> ```
> root@ip-192-168-22-5:/var/lib/docker# du -sh *
> 1.6M    buildkit
> 244K    containers
> 26M     image
> 76K     network
> 24G     overlay2
> 16K     plugins
> 4.0K    runtimes
> 4.0K    swarm
> 6.8G    tmp
> 4.0K    trust
> 38G     volumes
> ```

Yeah, I've also stated it in https://github.com/autowarefoundation/autoware.ai/issues/2412 in collapsed logs.",xmfcx,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T16:05:08Z,1284821222,1166428292.0,comment,"Oh, yes it was folded, sorry.

And after `docker system prune --all`

```
root@ip-192-168-22-5:/var/lib/docker# du -sh *
1.6M    buildkit
244K    containers
3.1M    image
76K     network
906M    overlay2
16K     plugins
4.0K    runtimes
4.0K    swarm
4.0K    tmp
4.0K    trust
24G     volumes
```",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-19T16:16:09Z,1284821222,1166428294.0,comment,"```
root@ip-192-168-22-5:/var/lib/docker# docker ps
CONTAINER ID   IMAGE                           COMMAND                  CREATED        STATUS        PORTS     NAMES
7803dfa32a78   moby/buildkit:buildx-stable-1   ""buildkitd --allow-i…""   15 hours ago   Up 15 hours             buildx_buildkit_builder-b4526839-5106-4cdc-acdd-f9b9f0621fa00
6375c66e5d44   moby/buildkit:buildx-stable-1   ""buildkitd --allow-i…""   16 hours ago   Up 16 hours             buildx_buildkit_builder-40b5c38f-e9f0-4443-9284-3a00cfa622280
ee72b8df7fe6   moby/buildkit:buildx-stable-1   ""buildkitd --allow-i…""   22 hours ago   Up 22 hours             buildx_buildkit_builder-3db86ac2-f685-4338-a80e-3115c89fb7ff0
fa5f61ca1c6e   moby/buildkit:buildx-stable-1   ""buildkitd --allow-i…""   23 hours ago   Up 23 hours             buildx_buildkit_builder-201962b3-ef56-49fc-842b-51436675fc520
0401dfb53bfd   moby/buildkit:buildx-stable-1   ""buildkitd --allow-i…""   30 hours ago   Up 30 hours             buildx_buildkit_builder-10beb027-0751-4fcd-8071-9c9050145b870
```

Since it seemed that old containers are left, I stopped all containers and ran `docker volume prune`.

After that,

```
root@ip-192-168-22-5:/var/lib/docker# df -h
Filesystem       Size  Used Avail Use% Mounted on
/dev/root         78G   10G   68G  13% /
devtmpfs         7.7G     0  7.7G   0% /dev
tmpfs            7.8G     0  7.8G   0% /dev/shm
tmpfs            1.6G 1004K  1.6G   1% /run
tmpfs            5.0M     0  5.0M   0% /run/lock
tmpfs            7.8G     0  7.8G   0% /sys/fs/cgroup
/dev/nvme0n1p15   98M  290K   98M   1% /boot/efi
/dev/loop1        30M   30M     0 100% /snap/amazon-ssm-agent/3553
/dev/loop2        22M   22M     0 100% /snap/amazon-ssm-agent/4047
/dev/loop6        89M   89M     0 100% /snap/core/11803
/dev/loop11       89M   89M     0 100% /snap/core/11996
/dev/loop7        61M   61M     0 100% /snap/lxd/21804
/dev/loop4        61M   61M     0 100% /snap/lxd/21843
/dev/loop8        58M   58M     0 100% /snap/core20/1244
/dev/loop9        49M   49M     0 100% /snap/core18/2252
/dev/loop0        58M   58M     0 100% /snap/core20/1274
/dev/loop10       49M   49M     0 100% /snap/core18/2289
tmpfs            1.6G     0  1.6G   0% /run/user/1000
```

To avoid such problems, we should try ephemeral runners as you said.",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
Storage space of ARM self-hosted runner is probably small,2022-01-20T04:40:44Z,1284821222,1166428296.0,comment,"@xmfcx Succeeded!
https://github.com/autowarefoundation/autoware/runs/4870569220?check_suite_focus=true

It used about 46GB.

![image](https://user-images.githubusercontent.com/31987104/150274785-84b256c1-b25f-49bb-8bb1-cdca5f9ab44c.png)


I'll try some more times to confirm there isn't an old and big cache left.

It seems to be cleaned up so far.
https://github.com/autowarefoundation/autoware/runs/4877651871?check_suite_focus=true

![image](https://user-images.githubusercontent.com/31987104/150275044-ed135882-c20c-4621-8e7b-3df69d585eaf.png)",kenji-miyake,1320011.0,498575.0,25,0,0,0,0
